{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch,torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "import numpy as np\n",
    "from model import Generator, iterate_minibatches, compute_loss, train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "OCTAVE_NUM = 4\n",
    "NOTE_NUM = 12\n",
    "TIME_SCALE = 128\n",
    "\n",
    "\n",
    "class LSTM_discriminator(nn.Module):\n",
    "    def __init__(self,hidden_size = 1000):\n",
    "        super(self.__class__, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.note_lstm = nn.LSTM(input_size = OCTAVE_NUM*3,hidden_size = hidden_size)\n",
    "        self.time_lstm = nn.LSTM(input_size = hidden_size,hidden_size = hidden_size)\n",
    "        self.dense = nn.Linear(hidden_size,1)\n",
    "\n",
    "    def forward(self,data):\n",
    "        # data.size() =  (batch_size, TIME_SCALE, NOTE_NUM*OCTAVE_NUM, 3)\n",
    "        # octave_data.size() =  (batch_size, TIME_SCALE, NOTE_NUM,OCTAVE_NUM*3)\n",
    "        batch_size,_,_,_ = data.size()\n",
    "        octave_data = data.view(batch_size,TIME_SCALE,NOTE_NUM,OCTAVE_NUM,3)\\\n",
    "                          .view(batch_size,TIME_SCALE,NOTE_NUM,OCTAVE_NUM*3)\n",
    "            \n",
    "        # note_lstm_input.size() = (NOTE_NUM, batch_size*TIME_SCALE,OCTAVE_NUM*3)\n",
    "        note_lstm_input = octave_data.view(batch_size*TIME_SCALE,NOTE_NUM,OCTAVE_NUM*3)\\\n",
    "                                     .transpose(0,1)\n",
    "        # note_lstm_output.size() = (NOTE_NUM,batch_size*TIME_SCALE,hidden_size)\n",
    "        note_lstm_output, _ = self.note_lstm(note_lstm_input)\n",
    "        # time_lstm_input.size() = (TIME_SCALE,batch_size,hidden_size)\n",
    "        time_lstm_input = note_lstm_output[-1].view(batch_size,TIME_SCALE,self.hidden_size)\\\n",
    "                                          .transpose(0,1)\\\n",
    "        # time_lstm_output.size() = (TIME_SCALE,batch_size,1000)\n",
    "        time_lstm_output, _  = self.time_lstm(time_lstm_input)\n",
    "        # dense_input.size() = (batch_size,1000)\n",
    "        dense_input = time_lstm_output[-1]\n",
    "        # dense_output.size() = (batch_size,1)\n",
    "        dense_output = self.dense(dense_input)\n",
    "        probs = F.sigmoid(dense_output)\n",
    "        return probs\n",
    "        \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:4\" if torch.cuda.is_available() else \"cpu\")\n",
    "# device = torch.device(\"cpu\")\n",
    "discriminator = LSTM_discriminator(hidden_size=10).to(device)\n",
    "np_data = np.random.randn(10,TIME_SCALE,NOTE_NUM*OCTAVE_NUM,3)\n",
    "data = torch.FloatTensor(np_data).to(device)\n",
    "discriminator(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTM_baseline(nn.Module):\n",
    "    def __init__(self,hidden_size = 1000):\n",
    "        super(self.__class__, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.note_lstm = nn.LSTM(input_size = OCTAVE_NUM*3,hidden_size = hidden_size)\n",
    "        self.time_lstm = nn.LSTM(input_size = hidden_size,hidden_size = hidden_size)\n",
    "        self.dense = nn.Linear(hidden_size,1)\n",
    "\n",
    "    def forward(self,data):\n",
    "        # data.size() =  (batch_size, TIME_SCALE, NOTE_NUM*OCTAVE_NUM, 3)\n",
    "        # octave_data.size() =  (batch_size, TIME_SCALE, NOTE_NUM,OCTAVE_NUM*3)\n",
    "        batch_size,_,_,_ = data.size()\n",
    "        octave_data = data.view(batch_size,TIME_SCALE,NOTE_NUM,OCTAVE_NUM,3)\\\n",
    "                          .view(batch_size,TIME_SCALE,NOTE_NUM,OCTAVE_NUM*3)\n",
    "            \n",
    "        # note_lstm_input.size() = (NOTE_NUM, batch_size*TIME_SCALE,OCTAVE_NUM*3)\n",
    "        note_lstm_input = octave_data.view(batch_size*TIME_SCALE,NOTE_NUM,OCTAVE_NUM*3)\\\n",
    "                                     .transpose(0,1)\n",
    "        # note_lstm_output.size() = (NOTE_NUM,batch_size*TIME_SCALE,hidden_size)\n",
    "        note_lstm_output, _ = self.note_lstm(note_lstm_input)\n",
    "        # time_lstm_input.size() = (TIME_SCALE,batch_size,hidden_size)\n",
    "        time_lstm_input = note_lstm_output[-1].view(batch_size,TIME_SCALE,self.hidden_size)\\\n",
    "                                          .transpose(0,1)\\\n",
    "        # time_lstm_output.size() = (TIME_SCALE,batch_size,1000)\n",
    "        time_lstm_output, _  = self.time_lstm(time_lstm_input)\n",
    "        # dense_input.size() = (batch_size,1000)\n",
    "        dense_input = time_lstm_output[-1]\n",
    "        # dense_output.size() = (batch_size,1)\n",
    "        dense_output = self.dense(dense_input)\n",
    "        probs = F.sigmoid(dense_output)\n",
    "        return probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "discriminator = LSTM_baseline(hidden_size=1000).to(device)\n",
    "np_data = np.random.randn(10,TIME_SCALE,NOTE_NUM*OCTAVE_NUM,3)\n",
    "data = torch.FloatTensor(np_data).to(device)\n",
    "discriminator(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BasicGenerator(nn.Module):\n",
    "    def __init__(self,hidden_size = 1000):\n",
    "        super(self.__class__, self).__init__()\n",
    "        self.dense_in = nn.Linear(TIME_SCALE*NOTE_NUM*OCTAVE_NUM*3,hidden_size)\n",
    "        self.dense_out = nn.Linear(hidden_size,TIME_SCALE*NOTE_NUM*OCTAVE_NUM*3)\n",
    "\n",
    "    def forward(self,data,_):\n",
    "        batch_size,_,_,_ = data.size()\n",
    "        data = data.view(batch_size,-1)\n",
    "        hid_data = self.dense_in(data)\n",
    "        out_data = self.dense_out(hid_data)\n",
    "        output = F.sigmoid(out_data.view(batch_size, TIME_SCALE, NOTE_NUM*OCTAVE_NUM, 3))\n",
    "        return output\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SequenceGenerator(nn.Module):\n",
    "    def __init__(self,hidden_size = 10):\n",
    "        super(self.__class__, self).__init__()\n",
    "        self.dense_in = nn.Linear(TIME_SCALE*NOTE_NUM*OCTAVE_NUM*3,hidden_size)\n",
    "\n",
    "    def forward(self,data,_):\n",
    "        batch_size,_,_,_ = data.size()\n",
    "        data = data.view(batch_size,-1)\n",
    "        hid_data = self.dense_in(data)\n",
    "        out_data = self.dense_out(hid_data)\n",
    "        output = F.sigmoid(out_data.view(batch_size, TIME_SCALE, NOTE_NUM*OCTAVE_NUM, 3))\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def g_loss(p_fake,sound,in_probs,eps = 1e-8):\n",
    "#     probs = sound[:,TIME_SCALE//2:,:,:2]*in_probs[:,TIME_SCALE//2:,:,:2]\\\n",
    "#             +(1-sound[:,TIME_SCALE//2:,:,:2])*(1-in_probs[:,TIME_SCALE//2:,:,:2])\n",
    "    probs = sound[:,:,:,:2]*in_probs[:,:,:,:2]\\\n",
    "            +(1-sound[:,:,:,:2])*(1-in_probs[:,:,:,:2])\n",
    "    return ((probs+eps).log().sum(dim =-1).sum(dim =-1).sum(dim =-1)*p_fake).mean()\n",
    "def d_loss(p_fake, p_true,eps = 1e-8):\n",
    "     return -((1-p_fake+eps).log().mean()-(p_true+eps).log().mean())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.utils.data\n",
    "\n",
    "def sample_sound(data_gen):\n",
    "    size = data_gen.size()\n",
    "    rand = torch.rand(*size).cuda()\n",
    "    sample = (rand<data_gen).type(torch.FloatTensor).cuda()\n",
    "    sample[:,:,:,2] = data_gen[:,:,:,2]\n",
    "    return sample\n",
    "    \n",
    "\n",
    "def train_GAN(generator,discriminator,X_loader,Y_loader,num_epochs = 3,g_lr = 0.001, d_lr = 0.001):\n",
    "    generator.train()\n",
    "    discriminator.train()\n",
    "    g_optimizer = torch.optim.Adam(generator.parameters(),     lr=g_lr, betas=(0.5, 0.999))\n",
    "    d_optimizer = torch.optim.Adam(discriminator.parameters(), lr=d_lr, betas=(0.5, 0.999))\n",
    "    d_losses = []\n",
    "    g_losses = []\n",
    "    for epoch in range(num_epochs):\n",
    "        for [x_batch,ch_batch],[y_batch] in zip(X_loader,Y_loader):\n",
    "            x_batch = x_batch.cuda()\n",
    "            ch_batch = ch_batch.cuda()\n",
    "            y_batch = y_batch.cuda()\n",
    "            # Optimize D\n",
    "\n",
    "            data_gen = generator(x_batch,ch_batch)\n",
    "            sound = sample_sound(data_gen)\n",
    "            #concat_sound = torch.cat([x_batch[:,1:TIME_SCALE//2+1,:,:],sound[:,TIME_SCALE//2:,:,:]],dim = 1)\n",
    "            loss = d_loss(discriminator(sound), discriminator(y_batch))\n",
    "            d_optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "#             print(loss.grad)\n",
    "            d_optimizer.step()\n",
    "            d_losses.append(loss.data.cpu().numpy())\n",
    "\n",
    "            # Optimize G\n",
    "            \n",
    "            data_gen = generator(x_batch,ch_batch)\n",
    "            sound = sample_sound(data_gen)\n",
    "            #concat_sound = torch.cat([x_batch[:,1:TIME_SCALE//2+1,:,:],sound[:,TIME_SCALE//2:,:,:]],dim = 1)\n",
    "            loss = g_loss(discriminator(sound.data),sound.data,data_gen)\n",
    "            g_optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "#             print(loss.grad)\n",
    "            g_optimizer.step()\n",
    "            g_losses.append(loss.data.cpu().numpy())\n",
    "    return generator,discriminator,np.array(g_losses),np.array(d_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((5727, 128, 48, 3), (2500, 128, 48, 3), (2500, 128, 48, 3), 2500)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dataset import load_all\n",
    "from constants import *\n",
    "\n",
    "styles= [['data/Bach']]\n",
    "train_data, train_labels = load_all(styles, BATCH_SIZE, TIME_SCALE)\n",
    "N = 2500\n",
    "X_tr = train_data[0][:N]\n",
    "y_tr = train_labels[0][:N]\n",
    "X_te = train_data[0][N:2*N]\n",
    "train_data[0].shape,X_te.shape,y_tr.shape,N\n",
    "#y_te = train_labels[0][-1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_loader = torch.utils.data.DataLoader(\\\n",
    "            torch.utils.data.TensorDataset(\\\n",
    "            *(torch.FloatTensor(X_tr),\n",
    "            torch.FloatTensor(y_tr))),\\\n",
    "            batch_size=50,shuffle=True)\n",
    "Y_loader = torch.utils.data.DataLoader(\\\n",
    "            torch.utils.data.TensorDataset(\\\n",
    "            torch.FloatTensor(X_te)),\\\n",
    "            batch_size=50,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/torch/nn/modules/rnn.py:38: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.1 and num_layers=1\n",
      "  \"num_layers={}\".format(dropout, num_layers))\n"
     ]
    }
   ],
   "source": [
    "# device = torch.device(\"cuda:6\" if torch.cuda.is_available() else \"cpu\")\n",
    "# device = torch.device(\"cpu\")\n",
    "generator = Generator().cuda()\n",
    "discriminator = LSTM_discriminator(hidden_size=100).cuda()\n",
    "generator,discriminator,g_losses,d_losses =\\\n",
    "                train_GAN(generator,discriminator,X_loader,Y_loader,num_epochs = 1, g_lr = 1000,d_lr=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(g_losses,label = \"Generator loss\")\n",
    "# plt.plot(d_losses,label = \"Discriminator loss\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g_losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 1/64 [00:00<00:06,  9.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating with no styles:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/workspace/MusicGeneration/project_dnn2018/generate.py:88: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  x = -np.log(1 / prob - 1)\n",
      "100%|██████████| 64/64 [00:06<00:00,  9.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing file out/samples/output/canonical_test_0.mid\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from generate import write_file, generate\n",
    "write_file('output/canonical_test', generate(generator, 4,cuda = True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
