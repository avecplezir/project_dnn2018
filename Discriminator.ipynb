{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch,torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip3 uninstall torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch==0.4.0 from http://download.pytorch.org/whl/cu90/torch-0.4.0-cp35-cp35m-linux_x86_64.whl in /usr/local/lib/python3.5/dist-packages (0.4.0)\r\n"
     ]
    }
   ],
   "source": [
    "!pip3 install http://download.pytorch.org/whl/cu90/torch-0.4.0-cp35-cp35m-linux_x86_64.whl "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "OCTAVE_NUM = 4\n",
    "NOTE_NUM = 12\n",
    "TIME_SCALE = 3\n",
    "\n",
    "class LSTM_discriminator(nn.Module):\n",
    "    def __init__(self,hidden_size = 1000):\n",
    "        super(self.__class__, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.note_lstm = nn.LSTM(input_size = OCTAVE_NUM*3,hidden_size = hidden_size)\n",
    "        self.time_lstm = nn.LSTM(input_size = hidden_size,hidden_size = hidden_size)\n",
    "        self.dense = nn.Linear(hidden_size,1)\n",
    "\n",
    "    def forward(self,data):\n",
    "        # data.size() =  (batch_size, TIME_SCALE, NOTE_NUM*OCTAVE_NUM, 3)\n",
    "        # octave_data.size() =  (batch_size, TIME_SCALE, NOTE_NUM,OCTAVE_NUM*3)\n",
    "        batch_size,_,_,_ = data.size()\n",
    "        octave_data = data.view(batch_size,TIME_SCALE,NOTE_NUM,OCTAVE_NUM,3)\\\n",
    "                          .view(batch_size,TIME_SCALE,NOTE_NUM,OCTAVE_NUM*3)\n",
    "            \n",
    "        # note_lstm_input.size() = (NOTE_NUM, batch_size*TIME_SCALE,OCTAVE_NUM*3)\n",
    "        note_lstm_input = octave_data.view(batch_size*TIME_SCALE,NOTE_NUM,OCTAVE_NUM*3)\\\n",
    "                                     .transpose(0,1)\n",
    "        # note_lstm_output.size() = (NOTE_NUM,batch_size*TIME_SCALE,hidden_size)\n",
    "        note_lstm_output, _ = self.note_lstm(note_lstm_input)\n",
    "        # time_lstm_input.size() = (TIME_SCALE,batch_size,hidden_size)\n",
    "        time_lstm_input = note_lstm_output[-1].view(batch_size,TIME_SCALE,self.hidden_size)\\\n",
    "                                          .transpose(0,1)\\\n",
    "        # time_lstm_output.size() = (TIME_SCALE,batch_size,1000)\n",
    "        time_lstm_output, _  = self.time_lstm(time_lstm_input)\n",
    "        # dense_input.size() = (batch_size,1000)\n",
    "        dense_input = time_lstm_output[-1]\n",
    "        # dense_output.size() = (batch_size,1)\n",
    "        dense_output = self.dense(dense_input)\n",
    "        probs = F.sigmoid(dense_output)\n",
    "        return probs\n",
    "        \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.5214],\n",
       "        [ 0.5192],\n",
       "        [ 0.5158],\n",
       "        [ 0.5221],\n",
       "        [ 0.5217],\n",
       "        [ 0.5185],\n",
       "        [ 0.5188],\n",
       "        [ 0.5205],\n",
       "        [ 0.5218],\n",
       "        [ 0.5231]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# device = torch.device(\"cuda:6\" if torch.cuda.is_available() else \"cpu\")\n",
    "device = torch.device(\"cpu\")\n",
    "discriminator = LSTM_discriminator(hidden_size=10).to(device)\n",
    "np_data = np.random.randn(10,TIME_SCALE,NOTE_NUM*OCTAVE_NUM,3)\n",
    "data = torch.FloatTensor(np_data).to(device)\n",
    "discriminator(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTM_baseline(nn.Module):\n",
    "    def __init__(self,hidden_size = 1000):\n",
    "        super(self.__class__, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.note_lstm = nn.LSTM(input_size = OCTAVE_NUM*3,hidden_size = hidden_size)\n",
    "        self.time_lstm = nn.LSTM(input_size = hidden_size,hidden_size = hidden_size)\n",
    "        self.dense = nn.Linear(hidden_size,1)\n",
    "\n",
    "    def forward(self,data):\n",
    "        # data.size() =  (batch_size, TIME_SCALE, NOTE_NUM*OCTAVE_NUM, 3)\n",
    "        # octave_data.size() =  (batch_size, TIME_SCALE, NOTE_NUM,OCTAVE_NUM*3)\n",
    "        batch_size,_,_,_ = data.size()\n",
    "        octave_data = data.view(batch_size,TIME_SCALE,NOTE_NUM,OCTAVE_NUM,3)\\\n",
    "                          .view(batch_size,TIME_SCALE,NOTE_NUM,OCTAVE_NUM*3)\n",
    "            \n",
    "        # note_lstm_input.size() = (NOTE_NUM, batch_size*TIME_SCALE,OCTAVE_NUM*3)\n",
    "        note_lstm_input = octave_data.view(batch_size*TIME_SCALE,NOTE_NUM,OCTAVE_NUM*3)\\\n",
    "                                     .transpose(0,1)\n",
    "        # note_lstm_output.size() = (NOTE_NUM,batch_size*TIME_SCALE,hidden_size)\n",
    "        note_lstm_output, _ = self.note_lstm(note_lstm_input)\n",
    "        # time_lstm_input.size() = (TIME_SCALE,batch_size,hidden_size)\n",
    "        time_lstm_input = note_lstm_output[-1].view(batch_size,TIME_SCALE,self.hidden_size)\\\n",
    "                                          .transpose(0,1)\\\n",
    "        # time_lstm_output.size() = (TIME_SCALE,batch_size,1000)\n",
    "        time_lstm_output, _  = self.time_lstm(time_lstm_input)\n",
    "        # dense_input.size() = (batch_size,1000)\n",
    "        dense_input = time_lstm_output[-1]\n",
    "        # dense_output.size() = (batch_size,1)\n",
    "        dense_output = self.dense(dense_input)\n",
    "        probs = F.sigmoid(dense_output)\n",
    "        return probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.5048],\n",
       "        [ 0.5047],\n",
       "        [ 0.5037],\n",
       "        [ 0.5045],\n",
       "        [ 0.5048],\n",
       "        [ 0.5045],\n",
       "        [ 0.5039],\n",
       "        [ 0.5041],\n",
       "        [ 0.5038],\n",
       "        [ 0.5048]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "discriminator = LSTM_baseline(hidden_size=1000).to(device)\n",
    "np_data = np.random.randn(10,TIME_SCALE,NOTE_NUM*OCTAVE_NUM,3)\n",
    "data = torch.FloatTensor(np_data).to(device)\n",
    "discriminator(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "    def __init__(self,hidden_size = 1000):\n",
    "        super(self.__class__, self).__init__()\n",
    "        self.dense_in = nn.Linear(TIME_SCALE*NOTE_NUM*OCTAVE_NUM*3,hidden_size)\n",
    "        self.dense_out = nn.Linear(hidden_size,TIME_SCALE*NOTE_NUM*OCTAVE_NUM*3)\n",
    "\n",
    "    def forward(self,data):\n",
    "        batch_size,_,_,_ = data.size()\n",
    "        data = data.view(batch_size,-1)\n",
    "        hid_data = self.dense_in(data)\n",
    "        out_data = self.dense_out(hid_data)\n",
    "        output = F.sigmoid(out_data.view(batch_size, TIME_SCALE, NOTE_NUM*OCTAVE_NUM, 3))\n",
    "        return output\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator = Generator().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def g_loss(p_fake,eps = 1e-8):\n",
    "    return -(p_fake+eps).log().mean()\n",
    "def d_loss(p_fake, p_true,eps = 1e-8):\n",
    "     return -((1-p_fake+eps).log().mean()-(p_true+eps).log().mean())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.utils.data\n",
    "\n",
    "def train_GAN(generator,discriminator,X_loader,Y_loader,num_epochs = 3,g_lr = 0.001, d_lr = 0.001):\n",
    "    g_optimizer = torch.optim.Adam(generator.parameters(),     lr=g_lr, betas=(0.5, 0.999))\n",
    "    d_optimizer = torch.optim.Adam(discriminator.parameters(), lr=d_lr, betas=(0.5, 0.999))\n",
    "    d_losses = []\n",
    "    g_losses = []\n",
    "    for epoch in range(num_epochs):\n",
    "        for [x_batch],[y_batch] in zip(X_loader,Y_loader):\n",
    "            x_batch = Variable(x_batch, requires_grad = True).to(device)\n",
    "            y_batch = Variable(y_batch, requires_grad = True).to(device)\n",
    "            # Optimize D\n",
    "            data_gen = generator(x_batch)\n",
    "            loss = d_loss(discriminator(data_gen), discriminator(y_batch))\n",
    "            d_optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "#             print(loss.grad)\n",
    "            d_optimizer.step()\n",
    "            d_losses.append(loss.data.cpu().numpy())\n",
    "\n",
    "            # Optimize G\n",
    "            data_gen = generator(x_batch)\n",
    "            loss = g_loss(discriminator(data_gen))\n",
    "            g_optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "#             print(loss.grad)\n",
    "            g_optimizer.step()\n",
    "            g_losses.append(loss.data.cpu().numpy())\n",
    "    return generator,discriminator,np.array(g_losses),np.array(d_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 1000\n",
    "X_loader = torch.utils.data.DataLoader(\\\n",
    "            torch.utils.data.TensorDataset(\\\n",
    "            torch.randn(N,TIME_SCALE,NOTE_NUM*OCTAVE_NUM,3)+10),\\\n",
    "            batch_size=10,shuffle=True)\n",
    "Y_loader = torch.utils.data.DataLoader(\\\n",
    "            torch.utils.data.TensorDataset(\\\n",
    "            torch.randn(N,TIME_SCALE,NOTE_NUM*OCTAVE_NUM,3)),\\\n",
    "            batch_size=10,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# device = torch.device(\"cuda:6\" if torch.cuda.is_available() else \"cpu\")\n",
    "device = torch.device(\"cpu\")\n",
    "# generator = Generator().to(device)\n",
    "# discriminator = LSTM_baseline(hidden_size=10).to(device)\n",
    "generator,discriminator,g_losses,d_losses =\\\n",
    "                train_GAN(generator,discriminator,X_loader,Y_loader,num_epochs = 1,g_lr = 0.1, d_lr = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(g_losses,label = \"Generator loss\")\n",
    "# plt.plot(d_losses,label = \"Discriminator loss\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g_losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "xx = Variable(torch.randn(1,1), requires_grad = True).to(device)\n",
    "yy = 3*xx\n",
    "zz = yy**2\n",
    "zz.backward()\n",
    "print(xx.cpu().grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
