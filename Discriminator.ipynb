{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch,torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "import numpy as np\n",
    "from model import Generator, iterate_minibatches, compute_loss, train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "OCTAVE_NUM = 4\n",
    "NOTE_NUM = 12\n",
    "TIME_SCALE = 3\n",
    "\n",
    "class LSTM_discriminator(nn.Module):\n",
    "    def __init__(self,hidden_size = 1000):\n",
    "        super(self.__class__, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.note_lstm = nn.LSTM(input_size = OCTAVE_NUM*3,hidden_size = hidden_size)\n",
    "        self.time_lstm = nn.LSTM(input_size = hidden_size,hidden_size = hidden_size)\n",
    "        self.dense = nn.Linear(hidden_size,1)\n",
    "\n",
    "    def forward(self,data):\n",
    "        # data.size() =  (batch_size, TIME_SCALE, NOTE_NUM*OCTAVE_NUM, 3)\n",
    "        # octave_data.size() =  (batch_size, TIME_SCALE, NOTE_NUM,OCTAVE_NUM*3)\n",
    "        batch_size,_,_,_ = data.size()\n",
    "        octave_data = data.view(batch_size,TIME_SCALE,NOTE_NUM,OCTAVE_NUM,3)\\\n",
    "                          .view(batch_size,TIME_SCALE,NOTE_NUM,OCTAVE_NUM*3)\n",
    "            \n",
    "        # note_lstm_input.size() = (NOTE_NUM, batch_size*TIME_SCALE,OCTAVE_NUM*3)\n",
    "        note_lstm_input = octave_data.view(batch_size*TIME_SCALE,NOTE_NUM,OCTAVE_NUM*3)\\\n",
    "                                     .transpose(0,1)\n",
    "        # note_lstm_output.size() = (NOTE_NUM,batch_size*TIME_SCALE,hidden_size)\n",
    "        note_lstm_output, _ = self.note_lstm(note_lstm_input)\n",
    "        # time_lstm_input.size() = (TIME_SCALE,batch_size,hidden_size)\n",
    "        time_lstm_input = note_lstm_output[-1].view(batch_size,TIME_SCALE,self.hidden_size)\\\n",
    "                                          .transpose(0,1)\\\n",
    "        # time_lstm_output.size() = (TIME_SCALE,batch_size,1000)\n",
    "        time_lstm_output, _  = self.time_lstm(time_lstm_input)\n",
    "        # dense_input.size() = (batch_size,1000)\n",
    "        dense_input = time_lstm_output[-1]\n",
    "        # dense_output.size() = (batch_size,1)\n",
    "        dense_output = self.dense(dense_input)\n",
    "        probs = F.sigmoid(dense_output)\n",
    "        return probs\n",
    "        \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.5125],\n",
       "        [ 0.5093],\n",
       "        [ 0.5150],\n",
       "        [ 0.5123],\n",
       "        [ 0.5143],\n",
       "        [ 0.5119],\n",
       "        [ 0.5106],\n",
       "        [ 0.5122],\n",
       "        [ 0.5161],\n",
       "        [ 0.5136]], device='cuda:6')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda:6\" if torch.cuda.is_available() else \"cpu\")\n",
    "# device = torch.device(\"cpu\")\n",
    "discriminator = LSTM_discriminator(hidden_size=10).to(device)\n",
    "np_data = np.random.randn(10,TIME_SCALE,NOTE_NUM*OCTAVE_NUM,3)\n",
    "data = torch.FloatTensor(np_data).to(device)\n",
    "discriminator(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTM_baseline(nn.Module):\n",
    "    def __init__(self,hidden_size = 1000):\n",
    "        super(self.__class__, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.note_lstm = nn.LSTM(input_size = OCTAVE_NUM*3,hidden_size = hidden_size)\n",
    "        self.time_lstm = nn.LSTM(input_size = hidden_size,hidden_size = hidden_size)\n",
    "        self.dense = nn.Linear(hidden_size,1)\n",
    "\n",
    "    def forward(self,data):\n",
    "        # data.size() =  (batch_size, TIME_SCALE, NOTE_NUM*OCTAVE_NUM, 3)\n",
    "        # octave_data.size() =  (batch_size, TIME_SCALE, NOTE_NUM,OCTAVE_NUM*3)\n",
    "        batch_size,_,_,_ = data.size()\n",
    "        octave_data = data.view(batch_size,TIME_SCALE,NOTE_NUM,OCTAVE_NUM,3)\\\n",
    "                          .view(batch_size,TIME_SCALE,NOTE_NUM,OCTAVE_NUM*3)\n",
    "            \n",
    "        # note_lstm_input.size() = (NOTE_NUM, batch_size*TIME_SCALE,OCTAVE_NUM*3)\n",
    "        note_lstm_input = octave_data.view(batch_size*TIME_SCALE,NOTE_NUM,OCTAVE_NUM*3)\\\n",
    "                                     .transpose(0,1)\n",
    "        # note_lstm_output.size() = (NOTE_NUM,batch_size*TIME_SCALE,hidden_size)\n",
    "        note_lstm_output, _ = self.note_lstm(note_lstm_input)\n",
    "        # time_lstm_input.size() = (TIME_SCALE,batch_size,hidden_size)\n",
    "        time_lstm_input = note_lstm_output[-1].view(batch_size,TIME_SCALE,self.hidden_size)\\\n",
    "                                          .transpose(0,1)\\\n",
    "        # time_lstm_output.size() = (TIME_SCALE,batch_size,1000)\n",
    "        time_lstm_output, _  = self.time_lstm(time_lstm_input)\n",
    "        # dense_input.size() = (batch_size,1000)\n",
    "        dense_input = time_lstm_output[-1]\n",
    "        # dense_output.size() = (batch_size,1)\n",
    "        dense_output = self.dense(dense_input)\n",
    "        probs = F.sigmoid(dense_output)\n",
    "        return probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.5019],\n",
       "        [ 0.5029],\n",
       "        [ 0.5029],\n",
       "        [ 0.5017],\n",
       "        [ 0.5030],\n",
       "        [ 0.5024],\n",
       "        [ 0.5023],\n",
       "        [ 0.5027],\n",
       "        [ 0.5025],\n",
       "        [ 0.5037]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "discriminator = LSTM_baseline(hidden_size=1000).to(device)\n",
    "np_data = np.random.randn(10,TIME_SCALE,NOTE_NUM*OCTAVE_NUM,3)\n",
    "data = torch.FloatTensor(np_data).to(device)\n",
    "discriminator(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BasicGenerator(nn.Module):\n",
    "    def __init__(self,hidden_size = 1000):\n",
    "        super(self.__class__, self).__init__()\n",
    "        self.dense_in = nn.Linear(TIME_SCALE*NOTE_NUM*OCTAVE_NUM*3,hidden_size)\n",
    "        self.dense_out = nn.Linear(hidden_size,TIME_SCALE*NOTE_NUM*OCTAVE_NUM*3)\n",
    "\n",
    "    def forward(self,data):\n",
    "        batch_size,_,_,_ = data.size()\n",
    "        data = data.view(batch_size,-1)\n",
    "        hid_data = self.dense_in(data)\n",
    "        out_data = self.dense_out(hid_data)\n",
    "        output = F.sigmoid(out_data.view(batch_size, TIME_SCALE, NOTE_NUM*OCTAVE_NUM, 3))\n",
    "        return output\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SequenceGenerator(nn.Module):\n",
    "    def __init__(self,seq_len):\n",
    "        super(self.__class__, self).__init__()\n",
    "        self.dense_in = nn.Linear(TIME_SCALE*NOTE_NUM*OCTAVE_NUM*3,hidden_size)\n",
    "\n",
    "    def forward(self,data):\n",
    "        batch_size,_,_,_ = data.size()\n",
    "        data = data.view(batch_size,-1)\n",
    "        hid_data = self.dense_in(data)\n",
    "        out_data = self.dense_out(hid_data)\n",
    "        output = F.sigmoid(out_data.view(batch_size, TIME_SCALE, NOTE_NUM*OCTAVE_NUM, 3))\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/torch/nn/modules/rnn.py:38: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.1 and num_layers=1\n",
      "  \"num_layers={}\".format(dropout, num_layers))\n"
     ]
    }
   ],
   "source": [
    "generator = Generator().to(device)\n",
    "# generator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def g_loss(p_fake,eps = 1e-8):\n",
    "    return -(p_fake+eps).log().mean()\n",
    "def d_loss(p_fake, p_true,eps = 1e-8):\n",
    "     return -((1-p_fake+eps).log().mean()-(p_true+eps).log().mean())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.utils.data\n",
    "\n",
    "def train_GAN(generator,discriminator,X_loader,Y_loader,num_epochs = 3,g_lr = 0.001, d_lr = 0.001):\n",
    "    g_optimizer = torch.optim.Adam(generator.parameters(),     lr=g_lr, betas=(0.5, 0.999))\n",
    "    d_optimizer = torch.optim.Adam(discriminator.parameters(), lr=d_lr, betas=(0.5, 0.999))\n",
    "    d_losses = []\n",
    "    g_losses = []\n",
    "    for epoch in range(num_epochs):\n",
    "        for [x_batch,ch_batch],[y_batch] in zip(X_loader,Y_loader):\n",
    "            x_batch = Variable(x_batch, requires_grad = True).to(device)\n",
    "            ch_batch = Variable(ch_batch, requires_grad = True).to(device)\n",
    "            y_batch = Variable(y_batch, requires_grad = True).to(device)\n",
    "            # Optimize D\n",
    "            data_gen = generator(x_batch,ch_batch)\n",
    "            loss = d_loss(discriminator(data_gen), discriminator(y_batch))\n",
    "            d_optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "#             print(loss.grad)\n",
    "            d_optimizer.step()\n",
    "            d_losses.append(loss.data.cpu().numpy())\n",
    "\n",
    "            # Optimize G\n",
    "            data_gen = generator(x_batch,ch_batch)\n",
    "            loss = g_loss(discriminator(data_gen))\n",
    "            g_optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "#             print(loss.grad)\n",
    "            g_optimizer.step()\n",
    "            g_losses.append(loss.data.cpu().numpy())\n",
    "    return generator,discriminator,np.array(g_losses),np.array(d_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 100\n",
    "X_loader = torch.utils.data.DataLoader(\\\n",
    "            torch.utils.data.TensorDataset(\\\n",
    "            *(torch.randn(N,TIME_SCALE,NOTE_NUM*OCTAVE_NUM,3)+10,\n",
    "            torch.randn(N,TIME_SCALE,NOTE_NUM*OCTAVE_NUM,3)+10)),\\\n",
    "            batch_size=10,shuffle=True)\n",
    "Y_loader = torch.utils.data.DataLoader(\\\n",
    "            torch.utils.data.TensorDataset(\\\n",
    "            torch.randn(N,TIME_SCALE,NOTE_NUM*OCTAVE_NUM,3)),\\\n",
    "            batch_size=10,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# device = torch.device(\"cuda:6\" if torch.cuda.is_available() else \"cpu\")\n",
    "device = torch.device(\"cpu\")\n",
    "# generator = Generator().to(device)\n",
    "# discriminator = LSTM_baseline(hidden_size=10).to(device)\n",
    "generator,discriminator,g_losses,d_losses =\\\n",
    "                train_GAN(generator,discriminator,X_loader,Y_loader,num_epochs = 1, g_lr = 0.1, d_lr = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYQAAAD8CAYAAAB3u9PLAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvhp/UCwAAGDFJREFUeJzt3XuUVeWd5vHvE7CkW0UNVFzcFJLOaBDxIAcw1ogEL2Dihba9xDhatiIhMUSgY8C2V8CZ6bUija2M7cLQgpgMC2kRMLZ2o6sV0YiOVVqDoETUoBbQUIK36CAXf/NHvZBDWVWn6pzCQ1nPZ62z2Pvd77vPb2+kntr73cejiMDMzOwrpS7AzMwODg4EMzMDHAhmZpY4EMzMDHAgmJlZ4kAwMzPAgWBmZokDwczMAAeCmZklnUtdQGt07949+vbtW+oyzMzalerq6ncjojxfv3YVCH379qWqqqrUZZiZtSuS3mpJP98yMjMzwIFgZmaJA8HMzIB2NodgZl+sXbt2UVtby44dO0pdirVAly5d6N27N4ccckhB4x0IZtak2tpajjjiCPr27YukUpdjzYgItm3bRm1tLf369StoH75lZGZN2rFjB926dXMYtAOS6NatW1FXcw4EM2uWw6D9KPbvyoFgZmaAA8HMDnJbtmzhBz/4AV//+tcZPHgw3/72t1m6dGnJ6lmxYgXPPvts0fs477zz2qiituNAMLODVkQwZswYhg8fzptvvkl1dTX3338/tbW1B/R9d+/e3eS2QgKhuf0dTBwIZnbQeuKJJygrK2P8+PH72o477jgmTJgAwJ49e7jxxhsZMmQIAwcO5Fe/+hVQ/0N7xIgRXHzxxZxwwglcccUVRAQA1dXVnHHGGQwePJhRo0axefNmAEaMGMHEiRPJZrPMmjWLhx9+mGHDhjFo0CDOOusstmzZwoYNG7j77ru5/fbbyWQyPP3002zYsIGRI0cycOBAzjzzTN5++20Arr76asaPH8+wYcP4+c9/3uQxbt++nTFjxjBw4EBOPfVUVq9eDcBTTz1FJpMhk8kwaNAgPvroIzZv3szw4cPJZDIMGDCAp59+uk3Ptx87NbMWueXhtbyy6cM23Wf/nl2Zdv6JTW5fu3Ytp5xySpPb586dy5FHHskLL7zAp59+SkVFBeeccw4AL730EmvXrqVnz55UVFTwu9/9jmHDhjFhwgQeeughysvLWbRoETfffDPz5s0DYOfOnfv+f2nvvfcezz33HJK45557mDFjBrfddhvjx4/n8MMP52c/+xkA559/PpWVlVRWVjJv3jx++tOfsmzZMqD+sd1nn32WTp06NXkM06ZNY9CgQSxbtownnniCq666ipqaGmbOnMldd91FRUUFf/zjH+nSpQtz5sxh1KhR3HzzzezZs4dPPvmkdSc8DweCmbUb119/Pc888wxlZWW88MILPPbYY6xevZrFixcD8MEHH7B+/XrKysoYOnQovXv3BiCTybBhwwaOOuoo1qxZw9lnnw3UX2H06NFj3/4vu+yyfcu1tbVcdtllbN68mZ07dzb5bP+qVatYsmQJAFdeeeV+VwOXXHJJs2EA8Mwzz/Dggw8CMHLkSLZt28aHH35IRUUFkydP5oorruCiiy6id+/eDBkyhGuuuYZdu3YxZswYMplMa09hsxwIZtYizf0mf6CceOKJ+35YAtx11128++67ZLNZoH6O4c4772TUqFH7jVuxYgWHHnrovvVOnTqxe/duIoITTzyRVatWNfp+hx122L7lCRMmMHnyZC644AJWrFjB9OnTW11/7v5aa+rUqXzve9/j0UcfpaKiguXLlzN8+HBWrlzJI488wtVXX83kyZO56qqrCn6PhvLOIUiaJ2mrpDU5bSdLWiXpZUkPS+rayLg+kp6U9IqktZJuyNk2XdJGSTXp9d02OyIz+9IYOXIkO3bsYPbs2fvacm+TjBo1itmzZ7Nr1y4AXnvtNT7++OMm93f88cdTV1e3LxB27drF2rVrG+37wQcf0KtXLwDuu+++fe1HHHEEH3300b710047jfvvvx+ABQsWcPrpp7fqGE8//XQWLFgA1AdZ9+7d6dq1K2+88QYnnXQSU6ZMYciQIaxbt4633nqLY445huuuu46xY8fy4osvtuq98mnJpPJ8YHSDtnuAqRFxErAUuLGRcbuBv4mI/sCpwPWS+udsvz0iMun1aOtLN7MvO0ksW7aMp556in79+jF06FAqKyu59dZbARg7diz9+/fnlFNOYcCAAfzwhz9s9omesrIyFi9ezJQpUzj55JPJZDJNPjE0ffp0LrnkEgYPHkz37t33tZ9//vksXbp036TynXfeyb333svAgQP5zW9+w6xZs1p1jNOnT6e6upqBAwcyderUfeFzxx13MGDAAAYOHMghhxzCueeey4oVKzj55JMZNGgQixYt4oYbbsiz99bR3pn3ZjtJfYF/jYgBaf0D4KiICEl9gOXpB39z+3gI+KeIeFzSdOCPETGzNcVms9nwF+SYfXFeffVVvvWtb5W6DGuFxv7OJFVHRDbf2EIfO10LXJiWLwH6NNc5Bcog4Pmc5p9IWp1uSR1dYB1mZtZGCg2Ea4AfS6oGjgB2NtVR0uHAg8DEiNj7zNps4BtABtgM3NbM+HGSqiRV1dXVFViumZnlU1AgRMS6iDgnIgYDC4E3Gusn6RDqw2BBRCzJGb8lIvZExGfAPwNDm3mvORGRjYhseXne74g2szbWktvKdnAo9u+qoECQ9LX051eAvwPubqSPgLnAqxHxjw229chZ/UtgDWZ20OnSpQvbtm1zKLQDe78PoUuXLgXvI+/nECQtBEYA3SXVAtOAwyVdn7osAe5NfXsC90TEd4EK4ErgZUk1qe/fpieKZkjKAAFsAH5Y8BGY2QHTu3dvamtr8e3a9mHvN6YVqkVPGR0s/JSRmVnrHeinjMzM7EvGgWBmZoADwczMEgeCmZkBDgQzM0scCGZmBjgQzMwscSCYmRngQDAzs8SBYGZmgAPBzMwSB4KZmQEOBDMzSxwIZmYGOBDMzCxxIJiZGeBAMDOzxIFgZmZACwNB0jxJWyWtyWk7WdIqSS9LelhS1ybGjpb0e0mvS5qa095P0vOpfZGksuIPx8zMCtXSK4T5wOgGbfcAUyPiJGApcGPDQZI6AXcB5wL9gcsl9U+bbwVuj4i/AN4Drm119WZm1mZaFAgRsRLY3qD5vwAr0/LjwF81MnQo8HpEvBkRO4H7gQslCRgJLE797gPGtLJ2MzNrQ8XMIawFLkzLlwB9GunTC3gnZ702tXUD3o+I3Q3azcysRIoJhGuAH0uqBo4AdrZNSfuTNE5SlaSqurq6A/EWZmZGEYEQEesi4pyIGAwsBN5opNtG9r9y6J3atgFHSercoL2x95kTEdmIyJaXlxdarpmZ5VFwIEj6WvrzK8DfAXc30u0F4JvpiaIy4PvAbyMigCeBi1O/SuChQmsxM7PitfSx04XAKuB4SbWSrqX+iaHXgHXAJuDe1LenpEcB0hzBT4DlwKvAv0TE2rTbKcBkSa9TP6cwt+0Oy8zMWkv1v6y3D9lsNqqqqkpdhplZuyKpOiKy+fr5k8pmZgY4EMzMLHEgmJkZ4EAwM7PEgWBmZoADwczMEgeCmZkBDgQzM0scCGZmBjgQzMwscSCYmRngQDAzs8SBYGZmgAPBzMwSB4KZmQEOBDMzSxwIZmYGOBDMzCzJGwiS5knaKmlNTltG0nOSaiRVSRrayLjvpO17XzskjUnb5kv6Q862TNselpmZtVZLrhDmA6MbtM0AbomIDPCLtL6fiHgyIjKpz0jgE+CxnC437t0eETUFVW9mZm0mbyBExEpge8NmoGtaPhLYlGc3FwP/FhGftLpCMzP7QhQ6hzAR+AdJ7wAzgZvy9P8+sLBB299LWi3pdkmHFliHmZm1kUID4UfApIjoA0wC5jbVUVIP4CRgeU7zTcAJwBDgq8CUZsaPS/MUVXV1dQWWa2Zm+RQaCJXAkrT8APC5SeUclwJLI2LX3oaI2Bz1PgXubW58RMyJiGxEZMvLywss18zM8ik0EDYBZ6TlkcD6ZvpeToPbRemqAUkCxgBrGhlnZmZfoM75OkhaCIwAukuqBaYB1wGzJHUGdgDjUt8sMD4ixqb1vkAf4KkGu10gqRwQUAOMb4NjMTOzIigiSl1Di2Wz2aiqqip1GWZm7Yqk6ojI5uvnTyqbmRngQDAzs8SBYGZmgAPBzMwSB4KZmQEOBDMzSxwIZmYGOBDMzCxxIJiZGeBAMDOzxIFgZmaAA8HMzBIHgpmZAQ4EMzNLHAhmZgY4EMzMLHEgmJkZ4EAwM7OkRYEgaZ6krZLW5LRlJD0nqUZSlaShTYzdk/rUSPptTns/Sc9Lel3SIkllxR+OmZkVqqVXCPOB0Q3aZgC3REQG+EVab8z/i4hMel2Q034rcHtE/AXwHnBty8s2M7O21qJAiIiVwPaGzUDXtHwksKmlbypJwEhgcWq6DxjT0vFmZtb2OhcxdiKwXNJM6oPltCb6dZFUBewGfhkRy4BuwPsRsTv1qQV6FVGLmZkVqZhJ5R8BkyKiDzAJmNtEv+MiIgv8ALhD0jda8yaSxqU5iqq6uroiyjUzs+YUEwiVwJK0/ADQ6KRyRGxMf74JrAAGAduAoyTtvULpDWxsYvyciMhGRLa8vLyIcs3MrDnFBMIm4Iy0PBJY37CDpKMlHZqWuwMVwCsREcCTwMWpayXwUBG1mJlZkVo0hyBpITAC6C6pFpgGXAfMSr/l7wDGpb5ZYHxEjAW+BfxK0mfUh88vI+KVtNspwP2S/ifwEk3fcjIzsy+A6n9Zbx+y2WxUVVWVugwzs3ZFUnWay22WP6lsZmaAA8HMzJJiPofQbtzy8Fpe2fRhqcswMytY/55dmXb+iQf0PXyFYGZmQAe5QjjQqWpm9mXgKwQzMwMcCGZmljgQzMwMcCCYmVniQDAzM8CBYGZmiQPBzMwAB4KZmSUOBDMzAxwIZmaWOBDMzAxwIJiZWeJAMDMzoAWBIGmepK2S1uS0ZSQ9J6lGUpWkoY2My0haJWmtpNWSLsvZNl/SH9L4GkmZtjskMzMrREuuEOYDoxu0zQBuiYgM8Iu03tAnwFURcWIaf4eko3K23xgRmfSqaX3pZmbWlvJ+H0JErJTUt2Ez0DUtHwlsamTcaznLmyRtBcqB9wst1szMDpxC5xAmAv8g6R1gJnBTc53TLaUy4I2c5r9Pt5Jul3RoM2PHpdtSVXV1dQWWa2Zm+RQaCD8CJkVEH2ASMLepjpJ6AL8B/joiPkvNNwEnAEOArwJTmhofEXMiIhsR2fLy8gLLNTOzfAoNhEpgSVp+APjcpDKApK7AI8DNEfHc3vaI2Bz1PgXubWq8mZl9cQoNhE3AGWl5JLC+YQdJZcBS4NcRsbjBth7pTwFjgDUNx5uZ2Rcr76SypIXACKC7pFpgGnAdMEtSZ2AHMC71zQLjI2IscCkwHOgm6eq0u6vTE0ULJJUDAmqA8W15UGZm1nqKiFLX0GLZbDaqqqpKXYaZWbsiqToisvn6+ZPKZmYGOBDMzCxxIJiZGeBAMDOzxIFgZmaAA8HMzBIHgpmZAQ4EMzNLHAhmZgY4EMzMLHEgmJkZ4EAwM7PEgWBmZoADwczMEgeCmZkBDgQzM0scCGZmBjgQzMwsaVEgSJonaaukNTltGUnPSaqRVCVpaBNjKyWtT6/KnPbBkl6W9Lqk/yVJxR+OmZkVqqVXCPOB0Q3aZgC3REQG+EVa34+krwLTgGHAUGCapKPT5tnAdcA306vh/s3M7AvUokCIiJXA9obNQNe0fCSwqZGho4DHI2J7RLwHPA6MltQD6BoRz0VEAL8GxhRyAGZm1jY6FzF2IrBc0kzqg+W0Rvr0At7JWa9Nbb3ScsP2z5E0DhgHcOyxxxZRrpmZNaeYSeUfAZMiog8wCZjbNiXtLyLmREQ2IrLl5eUH4i3MzIziAqESWJKWH6B+jqChjUCfnPXeqW1jWm7YbmZmJVJMIGwCzkjLI4H1jfRZDpwj6eg0mXwOsDwiNgMfSjo1PV10FfBQEbWYmVmRWjSHIGkhMALoLqmW+ieHrgNmSeoM7CDd55eUBcZHxNiI2C7pfwAvpF3994jYOzn9Y+qfXvoz4N/Sy8zMSkT1D/m0D9lsNqqqqkpdhplZuyKpOiKy+fr5k8pmZgY4EMzMLHEgmJkZ4EAwM7PEgWBmZoADwczMEgeCmZkBDgQzM0scCGZmBjgQzMwscSCYmRngQDAzs8SBYGZmgAPBzMwSB4KZmQEOBDMzSxwIZmYGtCAQJM2TtFXSmpy2RZJq0muDpJpGxh2f06dG0oeSJqZt0yVtzNn23bY9LDMza62WfKfyfOCfgF/vbYiIy/YuS7oN+KDhoIj4PZBJfToBG4GlOV1uj4iZBVVtZmZtLm8gRMRKSX0b2yZJwKXAyDy7ORN4IyLeam2BZmb2xSh2DuF0YEtErM/T7/vAwgZtP5G0Ot2SOrrIOszMrEjFBsLlfP4H/X4klQEXAA/kNM8GvkH9LaXNwG3NjB8nqUpSVV1dXZHlmplZUwoOBEmdgYuARXm6ngu8GBFb9jZExJaI2BMRnwH/DAxtanBEzImIbERky8vLCy3XzMzyKOYK4SxgXUTU5un3uasIST1yVv8SWIOZmZVUSx47XQisAo6XVCvp2rTpc/MCknpKejRn/TDgbGBJg93OkPSypNXAd4BJRRyDmZm1gZY8ZXR5E+1XN9K2CfhuzvrHQLdG+l3ZqirNzOyA8yeVzcwMcCCYmVniQDAzM8CBYGZmiQPBzMwAB4KZmSUOBDMzAxwIZmaWOBDMzAxwIJiZWeJAMDMzwIFgZmaJA8HMzAAHgpmZJQ4EMzMDHAhmZpY4EMzMDHAgmJlZkvcrNCXNA84DtkbEgNS2CDg+dTkKeD8iMo2M3QB8BOwBdkdENrV/FVgE9AU2AJdGxHtFHouZmRWhJVcI84HRuQ0RcVlEZFIIPAgsaWb8d1LfbE7bVOA/IuKbwH+kdTMzK6G8gRARK4HtjW2TJOBSYGEr3/dC4L60fB8wppXjzcysjRU7h3A6sCUi1jexPYDHJFVLGpfTfkxEbE7L/wkcU2QdZmZWpLxzCHlcTvNXB/81IjZK+hrwuKR16Ypjn4gISdHUDlKQjAM49thjiyzXzMyaUvAVgqTOwEXUTw43KiI2pj+3AkuBoWnTFkk90n56AFub2ceciMhGRLa8vLzQcs3MLI9ibhmdBayLiNrGNko6TNIRe5eBc4A1afNvgcq0XAk8VEQdZmbWBvIGgqSFwCrgeEm1kq5Nm75Pg9tFknpKejStHgM8I+n/Av8HeCQi/j1t+yVwtqT11AfLL4s/FDMzK4Yimrx9f9DJZrNRVVVV6jLMzNoVSdUNHv1vlD+pbGZmgAPBzMwSB4KZmQEOBDMzSxwIZmYGtLOnjCTVAW8VOLw78G4bltPe+Xz8ic/F/nw+9vdlOB/HRUTeT/a2q0AohqSqljx21VH4fPyJz8X+fD7215HOh28ZmZkZ4EAwM7OkIwXCnFIXcJDx+fgTn4v9+Xzsr8Ocjw4zh2BmZs3rSFcIZmbWjA4RCJJGS/q9pNclddjvb5bUR9KTkl6RtFbSDaWu6WAgqZOklyT9a6lrKTVJR0laLGmdpFclfbvUNZWKpEnp38kaSQsldSl1TQfalz4QJHUC7gLOBfoDl0vqX9qqSmY38DcR0R84Fbi+A5+LXDcAr5a6iIPELODfI+IE4GQ66HmR1Av4KZCNiAFAJ+r/l/9fal/6QKD+W9pej4g3I2IncD9wYYlrKomI2BwRL6blj6j/x96rtFWVlqTewPeAe0pdS6lJOhIYDswFiIidEfF+aasqqc7An6Vvh/xzYFOJ6zngOkIg9ALeyVmvpYP/EASQ1BcYBDxf2kpK7g7g58BnpS7kINAPqAPuTbfQ7knfdtjhpK//nQm8DWwGPoiIx0pb1YHXEQLBGpB0OPAgMDEiPix1PaUi6Txga0RUl7qWg0Rn4BRgdkQMAj4GOuScm6Sjqb+T0A/oCRwm6b+VtqoDryMEwkagT85679TWIUk6hPowWBARS0pdT4lVABdI2kD9rcSRkv53aUsqqVqgNiL2XjUupj4gOqKzgD9ERF1E7AKWAKeVuKYDriMEwgvANyX1k1RG/cTQb0tcU0lIEvX3h1+NiH8sdT2lFhE3RUTviOhL/X8XT0TEl/63wKZExH8C70g6PjWdCbxSwpJK6W3gVEl/nv7dnEkHmGDvXOoCDrSI2C3pJ8By6p8UmBcRa0tcVqlUAFcCL0uqSW1/GxGPlrAmO7hMABakX57eBP66xPWUREQ8L2kx8CL1T+e9RAf4xLI/qWxmZkDHuGVkZmYt4EAwMzPAgWBmZokDwczMAAeCmZklDgQzMwMcCGZmljgQzMwMgP8PQJceFHs88DQAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(g_losses,label = \"Generator loss\")\n",
    "# plt.plot(d_losses,label = \"Discriminator loss\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([18.420671, 18.420677, 18.42068 , 18.42068 , 18.42068 , 18.42068 ,\n",
       "       18.42068 , 18.420681, 18.420681, 18.420681], dtype=float32)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g_losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([18.420681, 18.420681, 18.420681, 18.420681, 18.420681, 18.420681,\n",
       "       18.420681, 18.420681, 18.420681, 18.420681], dtype=float32)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g_losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
