{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from keras.callbacks import ModelCheckpoint, LambdaCallback\n",
    "from keras.callbacks import EarlyStopping, TensorBoard\n",
    "import argparse\n",
    "import midi\n",
    "import os\n",
    "\n",
    "from constants import *\n",
    "from dataset import load_all\n",
    "from generate import write_file, generate\n",
    "from play_music_util import play_music\n",
    "\n",
    "import pygame\n",
    "import base64\n",
    "\n",
    "from playsound import playsound"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from keras.layers import Input, LSTM, Dense, Dropout, Lambda, Reshape, Permute\n",
    "from keras.layers import TimeDistributed, RepeatVector, Conv1D, Activation\n",
    "from keras.layers import Embedding, Flatten, dot, concatenate \n",
    "from keras.layers.merge import Concatenate, Add, Multiply\n",
    "from keras.models import Model\n",
    "import keras.backend as K\n",
    "from keras import losses\n",
    "from keras.utils import multi_gpu_model\n",
    "from "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['data/test']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "styles[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data\n"
     ]
    }
   ],
   "source": [
    "print('Loading data')\n",
    "train_data, train_labels = load_all(styles, BATCH_SIZE, SEQ_LEN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10, 128, 48, 3)\n",
      "(10, 128, 48, 3)\n",
      "(10, 128, 16)\n"
     ]
    }
   ],
   "source": [
    "for i in range(3):\n",
    "    print(train_data[i].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Layer' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-12db9b13e265>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Documents/project_dnn2018/model.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    277\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0matt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    278\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 279\u001b[0;31m \u001b[0;32mclass\u001b[0m \u001b[0mnormalize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mLayer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    280\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    281\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0minit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'Layer' is not defined"
     ]
    }
   ],
   "source": [
    "from model import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def primary_loss(y_true, y_pred):\n",
    "    maj_row = ~np.array([1,0,1,0,1,1,0,1,0,1,0,1])\n",
    "    min_row = ~np.array([1,0,1,1,0,1,0,1,1,0,1,0])\n",
    "    maj_mask = np.array([np.roll(maj_row,i) for i in range(12)])\n",
    "    min_mask = np.array([np.roll(min_row,i) for i in range(12)])\n",
    "    ton_mask = np.vstack((maj_mask,min_mask))\n",
    "    ton_mask = K.constant(ton_mask)\n",
    "    # 3 separate loss calculations based on if note is played or not\n",
    "    played = y_true[:, :, :, 0]\n",
    "    harmony = K.sum(K.reshape(played,(-1,SEQ_LEN,OCTAVE,NUM_OCTAVES)), axis = -1)\n",
    "    #print('harmony', harmony.shape)\n",
    "    #print('ton_mask', ton_mask.shape)\n",
    "#     harmony_dot = K.dot([harmony, ton_mask], (-1, -1))\n",
    "#     harmony_dot = tf.matmul(harmony, ton_mask, transpose_b = True)\n",
    "    harmony_reshape = K.reshape(harmony, (-1, 12))\n",
    "    #print('harmony_reshape', harmony_reshape)\n",
    "    harmony_dot = tf.matmul(harmony_reshape,ton_mask , transpose_b=True)\n",
    "    #print(harmony_dot.shape)\n",
    "    harmony_loss = K.min(harmony_dot, axis=-1)\n",
    "    #print('harmony_loss', harmony_loss.shape)\n",
    "    played = y_true[:, :, :, 0]\n",
    "    \n",
    "#     bce_note = losses.binary_crossentropy(y_true[:, -1, :, 0],  y_pred[:, -1, :, 0])\n",
    "#     bce_replay = losses.binary_crossentropy(y_true[:, -1, :, 1], tf.multiply(played, y_pred[:, -1, :, 1]) + tf.multiply(1 - played, y_true[:, -1, :, 1]))\n",
    "#     mse = losses.mean_squared_error(y_true[:, -1, :, 2], tf.multiply(played, y_pred[:, -1, :, 2]) + tf.multiply(1 - played, y_true[:, -1, :, 2]))\n",
    "\n",
    "    bce_note = losses.binary_crossentropy(y_true[:, :, :, 0],  y_pred[:, :, :, 0])\n",
    "    bce_replay = losses.binary_crossentropy(y_true[:, :, :, 1], tf.multiply(played, y_pred[:, :, :, 1]) + tf.multiply(1 - played, y_true[:, :, :, 1]))\n",
    "    mse = losses.mean_squared_error(y_true[:, :, :, 2], tf.multiply(played, y_pred[:, :, :, 2]) + tf.multiply(1 - played, y_true[:, :, :, 2]))\n",
    "    har_mse = losses.mean_squared_error(harmony_loss, 0)\n",
    "    \n",
    "    return bce_note + bce_replay + mse + har_mse/10\n",
    "\n",
    "\n",
    "def pitch_pos_in_f(time_steps):\n",
    "    \"\"\"\n",
    "    Returns a constant containing pitch position of each note\n",
    "    \"\"\"\n",
    "    def f(x):\n",
    "        note_ranges = tf.range(NUM_NOTES, dtype='float32') / NUM_NOTES\n",
    "        repeated_ranges = tf.tile(note_ranges, [tf.shape(x)[0] * time_steps])\n",
    "        return tf.reshape(repeated_ranges, [tf.shape(x)[0], time_steps, NUM_NOTES, 1])\n",
    "    return f\n",
    "\n",
    "def pitch_class_in_f(time_steps):\n",
    "    \"\"\"\n",
    "    Returns a constant containing pitch class of each note\n",
    "    \"\"\"\n",
    "    def f(x):\n",
    "        pitch_class_matrix = np.array([one_hot(n % OCTAVE, OCTAVE) for n in range(NUM_NOTES)])\n",
    "        pitch_class_matrix = tf.constant(pitch_class_matrix, dtype='float32')\n",
    "        pitch_class_matrix = tf.reshape(pitch_class_matrix, [1, 1, NUM_NOTES, OCTAVE])\n",
    "        return tf.tile(pitch_class_matrix, [tf.shape(x)[0], time_steps, 1, 1])\n",
    "    return f\n",
    "\n",
    "def pitch_bins_f(time_steps):\n",
    "    def f(x):\n",
    "        bins = tf.reduce_sum([x[:, :, i::OCTAVE, 0] for i in range(OCTAVE)], axis=3)\n",
    "        bins = tf.tile(bins, [NUM_OCTAVES, 1, 1])\n",
    "        bins = tf.reshape(bins, [tf.shape(x)[0], time_steps, NUM_NOTES, 1])\n",
    "        return bins\n",
    "    return f\n",
    "\n",
    "def build_models(time_steps=SEQ_LEN, input_dropout=0.2, dropout=0.5):\n",
    "    notes_in = Input((time_steps, NUM_NOTES, NOTE_UNITS))\n",
    "    beat_in = Input((time_steps, NOTES_PER_BAR))\n",
    "    # Target input for conditioning\n",
    "    chosen_in = Input((time_steps, NUM_NOTES, NOTE_UNITS))\n",
    "\n",
    "    # Dropout inputs\n",
    "    notes = Dropout(input_dropout)(notes_in)\n",
    "    beat = Dropout(input_dropout)(beat_in)\n",
    "    chosen = Dropout(input_dropout)(chosen_in)\n",
    "\n",
    "    \"\"\" Time axis \"\"\"\n",
    "    time_out = time_axis(dropout)(notes, beat)\n",
    "\n",
    "    \"\"\" Note Axis & Prediction Layer \"\"\"\n",
    "    naxis = note_axis(dropout)\n",
    "    notes_out = naxis(time_out, chosen)\n",
    "\n",
    "    model = Model([notes_in, chosen_in, beat_in], [notes_out])\n",
    "\n",
    "    if len(K.tensorflow_backend._get_available_gpus())>=2:\n",
    "        model = multi_gpu_model(model)\n",
    "\n",
    "    model.compile(optimizer='nadam', loss=[primary_loss])\n",
    "\n",
    "    \"\"\" Generation Models \"\"\"\n",
    "    time_model = Model([notes_in, beat_in], [time_out])\n",
    "\n",
    "    note_features = Input((1, NUM_NOTES, TIME_AXIS_UNITS), name='note_features')\n",
    "    chosen_gen_in = Input((1, NUM_NOTES, NOTE_UNITS), name='chosen_gen_in')\n",
    " \n",
    "    # Dropout inputs\n",
    "    chosen_gen = Dropout(input_dropout)(chosen_gen_in)\n",
    "    \n",
    "    note_gen_out = naxis(note_features, chosen_gen)\n",
    "    \n",
    "    note_model = Model([note_features, chosen_gen_in], note_gen_out)\n",
    "\n",
    "    return model, time_model, note_model\n",
    "\n",
    "\n",
    "def build_models_with_attention(time_steps=SEQ_LEN, input_dropout=0.2, dropout=0.5):\n",
    "    #print(SEQ_LEN)\n",
    "    notes_in = Input((time_steps, NUM_NOTES, NOTE_UNITS))\n",
    "    beat_in = Input((time_steps, NOTES_PER_BAR))\n",
    "    # Target input for conditioning\n",
    "    chosen_in = Input((time_steps, NUM_NOTES, NOTE_UNITS))\n",
    "\n",
    "    # Dropout inputs\n",
    "    notes = Dropout(input_dropout)(notes_in)\n",
    "    beat = Dropout(input_dropout)(beat_in)\n",
    "    chosen = Dropout(input_dropout)(chosen_in)\n",
    "\n",
    "    \"\"\" Time axis \"\"\"\n",
    "    time_out = time_axis(dropout)(notes, beat)\n",
    "    #print('time_out', time_out.shape)\n",
    "\n",
    "    \"\"\" Note Axis & Prediction Layer \"\"\"\n",
    "    naxis = note_axis_attention(dropout)\n",
    "    notes_out = naxis(time_out)\n",
    "    \n",
    "    model = Model([notes_in, chosen_in, beat_in], [notes_out])\n",
    "\n",
    "    if len(K.tensorflow_backend._get_available_gpus())>=2:\n",
    "        model = multi_gpu_model(model)\n",
    "\n",
    "    model.compile(optimizer='nadam', loss=[primary_loss])\n",
    "    \n",
    "    \"\"\" Generation Models \"\"\"\n",
    "    time_model = Model([notes_in, beat_in], [time_out])\n",
    "\n",
    "    note_features = Input((1, NUM_NOTES, TIME_AXIS_UNITS), name='note_features')\n",
    "    chosen_gen_in = Input((1, NUM_NOTES, NOTE_UNITS), name='chosen_gen_in')\n",
    "   \n",
    "    # Dropout inputs\n",
    "    chosen_gen = Dropout(input_dropout)(chosen_gen_in)\n",
    "    \n",
    "    #print('NUM_NOTES', NUM_NOTES)\n",
    "    note_gen_out = naxis(note_features)\n",
    "    \n",
    "    note_model = Model([note_features, chosen_gen_in], note_gen_out)\n",
    "\n",
    "    return model, time_model, note_model\n",
    "\n",
    "def note_axis_attention(dropout):\n",
    "    note_dense_att = Dense(2, activation='sigmoid', name='note_dense_att')\n",
    "    volume_dense_att = Dense(1, name='volume_dense_att')\n",
    "\n",
    "    def f(x):\n",
    "        x = attention_layer(x, x, True, DENSE_SIZE, N_HEADS, PROJECTION_DIM)\n",
    "        #print('x_att', x.shape)\n",
    "        x = Dropout(dropout)(x)\n",
    "        #print('x_drop', x.get_shape)\n",
    "        #print('the end')\n",
    "        #print('dense_vol', v.shape)\n",
    "  \n",
    "        return Concatenate(axis=-1)([note_dense_att(x), volume_dense_att(x)])\n",
    "    \n",
    "    return f\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def time_axis(dropout):\n",
    "    def f(notes, beat):\n",
    "        time_steps = int(notes.get_shape()[1])\n",
    "\n",
    "        # TODO: Experiment with when to apply conv\n",
    "        note_octave = TimeDistributed(Conv1D(OCTAVE_UNITS, 2 * OCTAVE, padding='same'))(notes)\n",
    "        note_octave = Activation('tanh')(note_octave)\n",
    "        note_octave = Dropout(dropout)(note_octave)\n",
    "\n",
    "        # Create features for every single note.\n",
    "        note_features = Concatenate()([\n",
    "            Lambda(pitch_pos_in_f(time_steps))(notes),\n",
    "            Lambda(pitch_class_in_f(time_steps))(notes),\n",
    "            Lambda(pitch_bins_f(time_steps))(notes),\n",
    "            note_octave,\n",
    "            TimeDistributed(RepeatVector(NUM_NOTES))(beat)\n",
    "        ])\n",
    "\n",
    "        x = note_features\n",
    "        if self_attention: \n",
    "            note_features = attention_layer(note_features, note_features, \n",
    "                           True, DENSE_SIZE = 94, N_HEADS = 2, PROJECTION_DIM = 47)\n",
    "  \n",
    "        # [batch, notes, time, features]\n",
    "        x = Permute((2, 1, 3))(x)\n",
    "\n",
    "        # Apply LSTMs\n",
    "        for l in range(TIME_AXIS_LAYERS):\n",
    "\n",
    "            x = TimeDistributed(LSTM(TIME_AXIS_UNITS, return_sequences=True))(x)\n",
    "            x = Dropout(dropout)(x)\n",
    "\n",
    "        # [batch, time, notes, features]\n",
    "        return Permute((2, 1, 3))(x)\n",
    "    return f\n",
    "\n",
    "def note_axis(dropout):\n",
    "    lstm_layer_cache = {}\n",
    "    note_dense = Dense(2, activation='sigmoid', name='note_dense')\n",
    "    volume_dense = Dense(1, name='volume_dense')\n",
    "\n",
    "    def f(x, chosen):\n",
    "        time_steps = int(x.get_shape()[1])\n",
    "        \n",
    "        if MASK:\n",
    "            #print('x', x.shape)\n",
    "            x_att = Permute((2,1,3))(x)\n",
    "            #print('x_att', x_att.shape)\n",
    "            x_att = Reshape((time_steps*NUM_NOTES, TIME_AXIS_UNITS))(x_att)\n",
    "            #print('x_att', x_att.shape)\n",
    "            x_att = attention_layer(x_att, x_att, True, DENSE_SIZE, N_HEADS, PROJECTION_DIM)\n",
    "            x_att = Reshape((NUM_NOTES, time_steps, TIME_AXIS_UNITS))(x_att)\n",
    "            x = Permute((2,1,3))(x_att)\n",
    "        \n",
    "        \n",
    "        if self_attention: attention_layer(x, x, True, DENSE_SIZE, N_HEADS, PROJECTION_DIM)\n",
    "\n",
    "\n",
    "        # Shift target one note to the left.\n",
    "        shift_chosen = Lambda(lambda x: tf.pad(x[:, :, :-1, :], [[0, 0], [0, 0], [1, 0], [0, 0]]))(chosen)\n",
    "\n",
    "        # [batch, time, notes, features + 1]\n",
    "        #print('x', x.shape)\n",
    "        #print('shift_chosen', shift_chosen.shape)\n",
    "        x = Concatenate(axis=3)([x, shift_chosen])\n",
    "\n",
    "\n",
    "        for l in range(NOTE_AXIS_LAYERS):\n",
    "            if l not in lstm_layer_cache:\n",
    "                lstm_layer_cache[l] = LSTM(NOTE_AXIS_UNITS, return_sequences=True)\n",
    "\n",
    "            x = TimeDistributed(lstm_layer_cache[l])(x)\n",
    "            x = Dropout(dropout)(x)\n",
    "            \n",
    "        #print('x', x.shape)  \n",
    "        #print('nx', note_dense(x).shape)\n",
    "        \n",
    "        return Concatenate()([note_dense(x), volume_dense(x)])\n",
    "    return f\n",
    "\n",
    "\n",
    "def OneHeadAttention(a_drop, q_drop, PROJECTION_DIM, drop_ratio=0.5,):\n",
    "        \n",
    "    a_proj = Dense(PROJECTION_DIM, use_bias=False, kernel_initializer='glorot_normal')(a_drop)\n",
    "    q_proj = Dense(PROJECTION_DIM, use_bias=False, kernel_initializer='glorot_normal')(q_drop)\n",
    "    v_proj = Dense(PROJECTION_DIM, use_bias=False, kernel_initializer='glorot_normal')(a_drop)\n",
    "    \n",
    "    a_proj = Dropout(drop_ratio)(a_proj)\n",
    "    q_proj = Dropout(drop_ratio)(q_proj)\n",
    "    v_proj = Dropout(drop_ratio)(v_proj)\n",
    "    #print('a_proj', a_proj.shape)\n",
    "    \n",
    "    #n = Dense(2)(v_proj)\n",
    "    #print('dense_note', n.shape)\n",
    "  \n",
    "    att_input = Lambda(lambda x: tf.matmul(x[0],x[1], transpose_b=True))([q_proj, a_proj])\n",
    "    #print('att_input', att_input.shape)\n",
    "    if MASK:\n",
    "        time_steps = int(att_input.get_shape()[1])//NUM_NOTES\n",
    "        #print('time_steps', time_steps)\n",
    "        #print('att_input', att_input.shape)\n",
    "        att_input = Reshape((NUM_NOTES, time_steps, time_steps*NUM_NOTES))(att_input)\n",
    "        #print('att_input_reshape', att_input.shape)\n",
    "        time_mask = []\n",
    "        for i in range(time_steps):\n",
    "            time_mask.append(Lambda(lambda x: tf.pad(x[:, :, i:i+1, 0:(i+1)*NUM_NOTES], \n",
    "                [[0, 0], [0, 0],[0, 0],  [0, NUM_NOTES*time_steps-(i+1)*NUM_NOTES]]))(att_input))\n",
    "        \n",
    "        if time_steps>1:\n",
    "            att_input = Concatenate(axis=2)(time_mask)\n",
    "        #print('att_input_pad', att_input.shape)\n",
    "        att_input = Reshape((time_steps*NUM_NOTES, time_steps*NUM_NOTES))(att_input)\n",
    "\n",
    "    att_weights = Activation('softmax')(att_input)\n",
    "    v_new = Lambda(lambda x: tf.matmul(x[0],x[1]))([att_weights, v_proj])\n",
    "    #tf.matmul(att_weights, v_proj)\n",
    "    #print('v_new', v_new.get_shape)\n",
    "     \n",
    "    v_new = Multiply()([q_proj, v_new])\n",
    "    #print('end onehed')\n",
    "    \n",
    "    return v_new\n",
    "\n",
    "def MultyHeadAttention(a_drop, q_drop, DENSE_SIZE, N_HEADS, PROJECTION_DIM):\n",
    "\n",
    "    Attention_heads = []\n",
    "    for i in range(N_HEADS):\n",
    "        Attention_heads.append(OneHeadAttention(a_drop, q_drop, PROJECTION_DIM))\n",
    "        \n",
    "    BigHead = concatenate(Attention_heads, axis=-1)\n",
    "    #print('BigHead', BigHead.shape)   \n",
    "\n",
    "    attention_output = Dense(DENSE_SIZE, use_bias=False)(BigHead)\n",
    "    #print('attention_output', attention_output.shape)\n",
    "\n",
    "           \n",
    "    return attention_output\n",
    "    \n",
    "def attention_layer(a_drop, q_drop, FF, DENSE_SIZE, N_HEADS, PROJECTION_DIM):\n",
    "    \n",
    "    #print('a_drop', a_drop.shape)\n",
    "    res = MultyHeadAttention(a_drop, q_drop, DENSE_SIZE, N_HEADS, PROJECTION_DIM)\n",
    "    #print('res', res.shape)\n",
    "        \n",
    "    att = Add()([a_drop, res])\n",
    "    #att = normalize()(att)    \n",
    " \n",
    "    #Feed Forward\n",
    "    if FF:\n",
    "        att_ff = Dense(DENSE_SIZE*4, activation = 'relu')(att)\n",
    "        att_ff = Dense(DENSE_SIZE)(att_ff)   \n",
    "        att_ff = Dropout(0.1)(att_ff)\n",
    "        att = Add()([att, att_ff])\n",
    "        #att = normalize()(att_add) \n",
    "    \n",
    "    return att\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MASK = True\n",
    "# self_attention = True\n",
    "# attention_in_note = False\n",
    "# models = build_models(time_steps=SEQ_LEN, \n",
    "#                                      input_dropout=0.2, dropout=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# With Attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /anaconda3/lib/python3.6/site-packages/tensorflow/python/util/deprecation.py:497: calling conv1d (from tensorflow.python.ops.nn_ops) with data_format=NHWC is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "`NHWC` for data_format is deprecated, use `NWC` instead\n"
     ]
    }
   ],
   "source": [
    "MASK = False\n",
    "self_attention = True\n",
    "attention_in_note = False\n",
    "models = build_models_with_attention(time_steps=SEQ_LEN, \n",
    "                                     input_dropout=0.2, dropout=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training\n",
      "Train on 9 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      "9/9 [==============================] - 14s 2s/step - loss: 0.9202 - val_loss: 1.8041\n",
      "Epoch 2/2\n",
      "9/9 [==============================] - 13s 1s/step - loss: 0.9299 - val_loss: 1.7528\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1c355d0940>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cbs = [\n",
    "    ModelCheckpoint(os.path.join(OUT_DIR, 'model_self_test.h5'), monitor='loss', save_best_only=True, save_weights_only=True),\n",
    "    EarlyStopping(monitor='loss', patience=5),\n",
    "    TensorBoard(log_dir='out/logs', histogram_freq=1)\n",
    "]\n",
    "\n",
    "print('Training')\n",
    "models[0].fit(train_data, train_labels, validation_split=0.05,\n",
    "              epochs=2, callbacks=cbs, batch_size=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/64 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating with no styles:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 64/64 [00:18<00:00,  3.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing file out/samples/output/test_self_0.mid\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "models = build_models_with_attention(time_steps=SEQ_LEN, \n",
    "                                     input_dropout=0.2, dropout=0.5)\n",
    "models[0].load_weights(os.path.join(OUT_DIR, 'model_self_test.h5'))\n",
    "write_file('output/test_self', generate(models, 4, Attention = True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Music file out/samples/output/test_self_0.mid loaded!\n"
     ]
    }
   ],
   "source": [
    "midi_file = 'out/samples/output/test_self_0.mid'\n",
    "play_music(midi_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Canonical with full attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "MASK = False\n",
    "self_attention = True\n",
    "attention_in_note = True\n",
    "models = build_models(input_dropout=0.2, dropout=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training\n",
      "Train on 9 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      "9/9 [==============================] - 11s 1s/step - loss: 0.9921 - val_loss: 1.8624\n",
      "Epoch 2/2\n",
      "9/9 [==============================] - 11s 1s/step - loss: 0.9890 - val_loss: 1.8626\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1c42543320>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cbs = [\n",
    "    ModelCheckpoint(os.path.join(OUT_DIR, 'model_matrix_self.h5'), monitor='loss', save_best_only=True, save_weights_only=True),\n",
    "    EarlyStopping(monitor='loss', patience=5),\n",
    "    #TensorBoard(log_dir='out/logs', histogram_freq=1)\n",
    "]\n",
    "\n",
    "print('Training')\n",
    "models[0].fit(train_data, train_labels, validation_split=0.05,\n",
    "              epochs=2, callbacks=cbs, batch_size=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/64 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating with no styles:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 64/64 [00:52<00:00,  1.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing file out/samples/output/test_overall_att_0.mid\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "models = build_models()\n",
    "models[0].load_weights(os.path.join(OUT_DIR, 'model_matrix_self.h5'))\n",
    "write_file('output/test_overall_att', generate(models, 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Music file out/samples/output/test_overall_att_0.mid loaded!\n"
     ]
    }
   ],
   "source": [
    "midi_file = 'out/samples/output/test_overall_att_0.mid'\n",
    "play_music(midi_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Canonical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "MASK = False\n",
    "self_attention = False\n",
    "attention_in_note = False\n",
    "models = build_models()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training\n",
      "Train on 9 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      "9/9 [==============================] - 15s 2s/step - loss: 1.1476 - val_loss: 1.8936\n",
      "Epoch 2/2\n",
      "9/9 [==============================] - 11s 1s/step - loss: 0.9959 - val_loss: 1.8699\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1c4b257630>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cbs = [\n",
    "    ModelCheckpoint(os.path.join(OUT_DIR, 'model_canonical.h5'), monitor='loss', save_best_only=True, save_weights_only=True),\n",
    "    EarlyStopping(monitor='loss', patience=5),\n",
    "    #TensorBoard(log_dir='out/logs', histogram_freq=1)\n",
    "]\n",
    "\n",
    "print('Training')\n",
    "models[0].fit(train_data, train_labels, validation_split=0.05,\n",
    "              epochs=2, callbacks=cbs, batch_size=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/64 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating with no styles:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 64/64 [00:55<00:00,  1.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing file out/samples/output/canonical_test_0.mid\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "models = build_models()\n",
    "models[0].load_weights(os.path.join(OUT_DIR, 'model_canonical.h5'))\n",
    "write_file('output/canonical_test', generate(models, 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Music file out/samples/output/canonical_test_0.mid loaded!\n"
     ]
    }
   ],
   "source": [
    "midi_file = 'out/samples/output/canonical_test_0.mid'\n",
    "play_music(midi_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing keras function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "fpath = os.path.join(SAMPLES_DIR, 'encode_decoded_song' + '_' + str(i) + '.mid')\n",
    "pattern = midi.read_midifile('data/Bach1/Toccata & Fuga in F-Dur, BWV 540.mid')\n",
    "result = midi_decode(pattern)\n",
    "mf = midi_encode(unclamp_midi(clamp_midi(result)))\n",
    "midi.write_midifile(fpath, mf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[[1. 1. 1. 1.]\n",
      "   [1. 1. 1. 1.]]\n",
      "\n",
      "  [[1. 0. 0. 0.]\n",
      "   [0. 1. 0. 0.]]]]\n",
      "A (1, 2, 2, 4)\n",
      "time_steps 2\n",
      "A [[[1. 1. 1. 1.]\n",
      "  [1. 0. 0. 0.]]]\n",
      "x0 (1, 2, 1, 4)\n",
      "x0 [[[[1. 1. 0. 0.]]\n",
      "\n",
      "  [[1. 0. 0. 0.]]]]\n",
      "x1 (1, 2, 1, 4)\n",
      "x1  [[[[1. 1. 1. 1.]]\n",
      "\n",
      "  [[0. 1. 0. 0.]]]]\n",
      "x (1, 2, 2, 4)\n",
      "x  [[[[1. 1. 0. 0.]\n",
      "   [1. 1. 1. 1.]]\n",
      "\n",
      "  [[1. 0. 0. 0.]\n",
      "   [0. 1. 0. 0.]]]]\n"
     ]
    }
   ],
   "source": [
    "A = np.array([[np.ones((2,4)), np.eye(4)[:2]]])\n",
    "A = K.variable(A)\n",
    "print(K.eval(A))\n",
    "print('A', A.shape)\n",
    "# x = Dense(4, kernel_initializer='Ones')(A)\\\n",
    "#print('slice x', K.eval(A[:, :, :-1, :]))\n",
    "\n",
    "time_steps = int(A.get_shape()[2])\n",
    "note_dim = int(A.get_shape()[1])\n",
    "\n",
    "print('time_steps', time_steps)\n",
    "print('A', K.eval(A[:, :, 0, :]))\n",
    "\n",
    "time_mask = []\n",
    "for i in range(time_steps):\n",
    "    time_mask.append(Lambda(lambda x: tf.pad(x[:, :, i:i+1, 0:(i+1)*note_dim], \n",
    "        [[0, 0], [0, 0],[0, 0],  [0, note_dim*time_steps-(i+1)*note_dim]]))(A))\n",
    "# x = Lambda(lambda x: tf.pad(x[:, :, :-1, :], \n",
    "#                         [[0, 0], [0, 0], [1, 0], [0, 0]]))(A)\n",
    "\n",
    "\n",
    "print('x0', time_mask[0].shape)\n",
    "print('x0', K.eval(time_mask[0]))\n",
    "\n",
    "print('x1', time_mask[1].shape)\n",
    "print('x1 ', K.eval(time_mask[1]))\n",
    "\n",
    "x = Concatenate(axis=2)(time_mask)\n",
    "\n",
    "print('x', x.shape)\n",
    "print('x ', K.eval(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# models[0].save_weights(os.path.join(OUT_DIR, 'raw_model.h5'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# models = build_models()\n",
    "# models[0].load_weights(MODEL_FILE)\n",
    "# write_file('output2', generate(models, 4, styles))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# import tensorflow as tf\n",
    "# from keras.layers import Input, LSTM, Dense, Dropout, Lambda, Reshape, Permute\n",
    "# from keras.layers import TimeDistributed, RepeatVector, Conv1D, Activation\n",
    "# from keras.layers import Embedding, Flatten, dot, concatenate \n",
    "# from keras.layers.merge import Concatenate, Add, Multiply\n",
    "# from keras.models import Model\n",
    "# import keras.backend as K\n",
    "# from keras import losses\n",
    "\n",
    "# from util import *\n",
    "# from constants import *\n",
    "\n",
    "# from keras.utils import multi_gpu_model\n",
    "\n",
    "# def primary_loss(y_true, y_pred):\n",
    "#     # 3 separate loss calculations based on if note is played or not\n",
    "#     played = y_true[:, :, :, 0]\n",
    "#     harmony = K.sum(K.reshape(played,(-1,128,12,4)), axis = -1)\n",
    "#     bce_note = losses.binary_crossentropy(y_true[:, :, :, 0], y_pred[:, :, :, 0])\n",
    "#     bce_replay = losses.binary_crossentropy(y_true[:, :, :, 1], tf.multiply(played, y_pred[:, :, :, 1]) + tf.multiply(1 - played, y_true[:, :, :, 1]))\n",
    "#     mse = losses.mean_squared_error(y_true[:, :, :, 2], tf.multiply(played, y_pred[:, :, :, 2]) + tf.multiply(1 - played, y_true[:, :, :, 2]))\n",
    "#     return bce_note + bce_replay + mse\n",
    "\n",
    "# def pitch_pos_in_f(time_steps):\n",
    "#     \"\"\"\n",
    "#     Returns a constant containing pitch position of each note\n",
    "#     \"\"\"\n",
    "#     def f(x):\n",
    "#         note_ranges = tf.range(NUM_NOTES, dtype='float32') / NUM_NOTES\n",
    "#         repeated_ranges = tf.tile(note_ranges, [tf.shape(x)[0] * time_steps])\n",
    "#         return tf.reshape(repeated_ranges, [tf.shape(x)[0], time_steps, NUM_NOTES, 1])\n",
    "#     return f\n",
    "\n",
    "# def pitch_class_in_f(time_steps):\n",
    "#     \"\"\"\n",
    "#     Returns a constant containing pitch class of each note\n",
    "#     \"\"\"\n",
    "#     def f(x):\n",
    "#         pitch_class_matrix = np.array([one_hot(n % OCTAVE, OCTAVE) for n in range(NUM_NOTES)])\n",
    "#         pitch_class_matrix = tf.constant(pitch_class_matrix, dtype='float32')\n",
    "#         pitch_class_matrix = tf.reshape(pitch_class_matrix, [1, 1, NUM_NOTES, OCTAVE])\n",
    "#         return tf.tile(pitch_class_matrix, [tf.shape(x)[0], time_steps, 1, 1])\n",
    "#     return f\n",
    "\n",
    "# def pitch_bins_f(time_steps):\n",
    "#     def f(x):\n",
    "#         bins = tf.reduce_sum([x[:, :, i::OCTAVE, 0] for i in range(OCTAVE)], axis=3)\n",
    "#         bins = tf.tile(bins, [NUM_OCTAVES, 1, 1])\n",
    "#         bins = tf.reshape(bins, [tf.shape(x)[0], time_steps, NUM_NOTES, 1])\n",
    "#         return bins\n",
    "#     return f\n",
    "\n",
    "# def time_axis(dropout):\n",
    "#     def f(notes, beat):\n",
    "#         time_steps = int(notes.get_shape()[1])\n",
    "\n",
    "#         # TODO: Experiment with when to apply conv\n",
    "#         note_octave = TimeDistributed(Conv1D(OCTAVE_UNITS, 2 * OCTAVE, padding='same'))(notes)\n",
    "#         note_octave = Activation('tanh')(note_octave)\n",
    "#         note_octave = Dropout(dropout)(note_octave)\n",
    "\n",
    "#         # Create features for every single note.\n",
    "#         note_features = Concatenate()([\n",
    "#             Lambda(pitch_pos_in_f(time_steps))(notes),\n",
    "#             Lambda(pitch_class_in_f(time_steps))(notes),\n",
    "#             Lambda(pitch_bins_f(time_steps))(notes),\n",
    "#             note_octave,\n",
    "#             TimeDistributed(RepeatVector(NUM_NOTES))(beat)\n",
    "#         ])\n",
    "\n",
    "#         x = note_features\n",
    "#         # [batch, notes, time, features]\n",
    "#         x = Permute((2, 1, 3))(x)\n",
    "\n",
    "#         # Apply LSTMs\n",
    "#         for l in range(TIME_AXIS_LAYERS):\n",
    "\n",
    "#             x = TimeDistributed(LSTM(TIME_AXIS_UNITS, return_sequences=True))(x)\n",
    "#             x = Dropout(dropout)(x)\n",
    "\n",
    "#         # [batch, time, notes, features]\n",
    "#         return Permute((2, 1, 3))(x)\n",
    "#     return f\n",
    "\n",
    "# def note_axis(dropout):\n",
    "#     lstm_layer_cache = {}\n",
    "#     note_dense = Dense(2, activation='sigmoid', name='note_dense')\n",
    "#     volume_dense = Dense(1, name='volume_dense')\n",
    "\n",
    "#     def f(x, chosen):\n",
    "#         time_steps = int(x.get_shape()[1])\n",
    "\n",
    "#         # Shift target one note to the left.\n",
    "#         shift_chosen = Lambda(lambda x: tf.pad(x[:, :, :-1, :], [[0, 0], [0, 0], [1, 0], [0, 0]]))(chosen)\n",
    "\n",
    "#         # [batch, time, notes, features + 1]\n",
    "#         x = Concatenate(axis=3)([x, shift_chosen])\n",
    "\n",
    "\n",
    "#         for l in range(NOTE_AXIS_LAYERS):\n",
    "#             if l not in lstm_layer_cache:\n",
    "#                 lstm_layer_cache[l] = LSTM(NOTE_AXIS_UNITS, return_sequences=True)\n",
    "\n",
    "#             x = TimeDistributed(lstm_layer_cache[l])(x)\n",
    "#             x = Dropout(dropout)(x)\n",
    "            \n",
    "#         #print('x', x.shape)  \n",
    "#         #print('nx', note_dense(x).shape)\n",
    "        \n",
    "#         return Concatenate()([note_dense(x), volume_dense(x)])\n",
    "#     return f\n",
    "\n",
    "# def build_models(time_steps=SEQ_LEN, input_dropout=0.2, dropout=0.5):\n",
    "#     notes_in = Input((time_steps, NUM_NOTES, NOTE_UNITS))\n",
    "#     beat_in = Input((time_steps, NOTES_PER_BAR))\n",
    "#     # Target input for conditioning\n",
    "#     chosen_in = Input((time_steps, NUM_NOTES, NOTE_UNITS))\n",
    "\n",
    "#     # Dropout inputs\n",
    "#     notes = Dropout(input_dropout)(notes_in)\n",
    "#     beat = Dropout(input_dropout)(beat_in)\n",
    "#     chosen = Dropout(input_dropout)(chosen_in)\n",
    "\n",
    "#     \"\"\" Time axis \"\"\"\n",
    "#     time_out = time_axis(dropout)(notes, beat)\n",
    "\n",
    "#     \"\"\" Note Axis & Prediction Layer \"\"\"\n",
    "#     naxis = note_axis(dropout)\n",
    "#     notes_out = naxis(time_out, chosen)\n",
    "\n",
    "#     model = Model([notes_in, chosen_in, beat_in], [notes_out])\n",
    "\n",
    "#     if len(K.tensorflow_backend._get_available_gpus())>=2:\n",
    "#         model = multi_gpu_model(model)\n",
    "\n",
    "#     model.compile(optimizer='nadam', loss=[primary_loss])\n",
    "\n",
    "#     \"\"\" Generation Models \"\"\"\n",
    "#     time_model = Model([notes_in, beat_in], [time_out])\n",
    "\n",
    "#     note_features = Input((1, NUM_NOTES, TIME_AXIS_UNITS), name='note_features')\n",
    "#     chosen_gen_in = Input((1, NUM_NOTES, NOTE_UNITS), name='chosen_gen_in')\n",
    "#     style_gen_in = Input((1, NUM_STYLES), name='style_in')\n",
    "\n",
    "#     # Dropout inputs\n",
    "#     chosen_gen = Dropout(input_dropout)(chosen_gen_in)\n",
    "    \n",
    "#     note_gen_out = naxis(note_features, chosen_gen)\n",
    "    \n",
    "#     note_model = Model([note_features, chosen_gen_in], note_gen_out)\n",
    "\n",
    "#     return model, time_model, note_model\n",
    "\n",
    "\n",
    "# def build_models_with_attention(time_steps=SEQ_LEN, input_dropout=0.2, dropout=0.5):\n",
    "#     notes_in = Input((time_steps, NUM_NOTES, NOTE_UNITS))\n",
    "#     beat_in = Input((time_steps, NOTES_PER_BAR))\n",
    "#     # Target input for conditioning\n",
    "#     chosen_in = Input((time_steps, NUM_NOTES, NOTE_UNITS))\n",
    "\n",
    "#     # Dropout inputs\n",
    "#     notes = Dropout(input_dropout)(notes_in)\n",
    "#     beat = Dropout(input_dropout)(beat_in)\n",
    "#     chosen = Dropout(input_dropout)(chosen_in)\n",
    "\n",
    "#     \"\"\" Time axis \"\"\"\n",
    "#     time_out = time_axis(dropout)(notes, beat)\n",
    "#     #print('time_out', time_out.shape)\n",
    "\n",
    "#     \"\"\" Note Axis & Prediction Layer \"\"\"\n",
    "#     naxis = note_axis_attention(dropout)\n",
    "#     notes_out = naxis(time_out)\n",
    "    \n",
    "#     model = Model([notes_in, chosen_in, beat_in], [notes_out])\n",
    "\n",
    "#     if len(K.tensorflow_backend._get_available_gpus())>=2:\n",
    "#         model = multi_gpu_model(model)\n",
    "\n",
    "#     model.compile(optimizer='nadam', loss=[primary_loss])\n",
    "    \n",
    "#     \"\"\" Generation Models \"\"\"\n",
    "#     time_model = Model([notes_in, beat_in], [time_out])\n",
    "\n",
    "#     note_features = Input((1, NUM_NOTES, TIME_AXIS_UNITS), name='note_features')\n",
    "#     chosen_gen_in = Input((1, NUM_NOTES, NOTE_UNITS), name='chosen_gen_in')\n",
    "   \n",
    "#     # Dropout inputs\n",
    "#     chosen_gen = Dropout(input_dropout)(chosen_gen_in)\n",
    "    \n",
    "#     #print('NUM_NOTES', NUM_NOTES)\n",
    "#     note_gen_out = naxis(note_features)\n",
    "    \n",
    "#     note_model = Model([note_features, chosen_gen_in], note_gen_out)\n",
    "\n",
    "#     return model, time_model, note_model\n",
    "\n",
    "# def note_axis_attention(dropout):\n",
    "#     note_dense_att = Dense(2, activation='sigmoid', name='note_dense_att')\n",
    "#     volume_dense_att = Dense(1, name='volume_dense_att')\n",
    "\n",
    "#     def f(x):\n",
    "#         x = attention_layer(x, x, True)\n",
    "#         #print('x_att', x.shape)\n",
    "#         x = Dropout(dropout)(x)\n",
    "#         #print('x_drop', x.get_shape)\n",
    "\n",
    "#         v = volume_dense_att(x)\n",
    "        \n",
    "#         #print('the end')\n",
    "#         #print('dense_vol', v.shape)\n",
    "  \n",
    "#         return Concatenate(axis=-1)([note_dense_att(x), volume_dense_att(x)])\n",
    "    \n",
    "#     return f\n",
    "\n",
    "# def OneHeadAttention(a_drop, q_drop, drop_ratio=0.5):\n",
    "        \n",
    "#     a_proj = Dense(PROJECTION_DIM, use_bias=False, kernel_initializer='glorot_normal')(a_drop)\n",
    "#     q_proj = Dense(PROJECTION_DIM, use_bias=False, kernel_initializer='glorot_normal')(q_drop)\n",
    "#     v_proj = Dense(PROJECTION_DIM, use_bias=False, kernel_initializer='glorot_normal')(a_drop)\n",
    "    \n",
    "#     a_proj = Dropout(drop_ratio)(a_proj)\n",
    "#     q_proj = Dropout(drop_ratio)(q_proj)\n",
    "#     v_proj = Dropout(drop_ratio)(v_proj)\n",
    "#     #print('a_proj', a_proj.shape)\n",
    "    \n",
    "#     #n = Dense(2)(v_proj)\n",
    "#     #print('dense_note', n.shape)\n",
    " \n",
    "    \n",
    "#     att_input = Lambda(lambda x: tf.matmul(x[0],x[1], transpose_b=True))([q_proj, a_proj])\n",
    "#     #print('att_input', att_input.shape)\n",
    "\n",
    "\n",
    "#     att_weights = Activation('softmax')(att_input)\n",
    "#     v_new = Lambda(lambda x: tf.matmul(x[0],x[1]))([att_weights, v_proj])\n",
    "#     #tf.matmul(att_weights, v_proj)\n",
    "#     #print('v_new', v_new.get_shape)\n",
    "     \n",
    "#     v_new = Multiply()([q_proj, v_new])\n",
    "    \n",
    "#     return v_new\n",
    "\n",
    "# def MultyHeadAttention(a_drop, q_drop):\n",
    "\n",
    "#     Attention_heads = []\n",
    "#     for i in range(N_HEADS):\n",
    "#         Attention_heads.append(OneHeadAttention(a_drop, q_drop))\n",
    "        \n",
    "#     BigHead = concatenate(Attention_heads, axis=-1)\n",
    "#     #print('BigHead', BigHead.shape)   \n",
    "\n",
    "#     attention_output = Dense(DENSE_SIZE, use_bias=False)(BigHead)\n",
    "#     #print('attention_output', attention_output.shape)\n",
    "\n",
    "           \n",
    "#     return attention_output\n",
    "    \n",
    "# def attention_layer(a_drop, q_drop, FF):\n",
    "    \n",
    "#     #print('a_drop', a_drop.shape)\n",
    "#     res = MultyHeadAttention(a_drop, q_drop)\n",
    "#     #print('res', res.shape)\n",
    "        \n",
    "#     att = Add()([a_drop, res])\n",
    "#     #att = normalize()(att)    \n",
    " \n",
    "#     #Feed Forward\n",
    "#     if FF:\n",
    "#         att_ff = Dense(DENSE_SIZE*4, activation = 'relu')(att)\n",
    "#         att_ff = Dense(DENSE_SIZE)(att_ff)   \n",
    "#         att_ff = Dropout(0.1)(att_ff)\n",
    "#         att_add = Add()([att, att_ff])\n",
    "#         #att = normalize()(att_add) \n",
    "    \n",
    "#     return att\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compute_beat(3, 16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "128"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SEQ_LEN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = deque([np.zeros((2, 3)) for _ in range(2)], maxlen=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "deque([array([[0., 0., 0.],\n",
       "              [0., 0., 0.]]), array([[0., 0., 0.],\n",
       "              [0., 0., 0.]])])"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "d.append(np.ones((2,3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "deque([array([[1., 1., 1.],\n",
       "              [1., 1., 1.]]), array([[1., 1., 1.],\n",
       "              [1., 1., 1.]])])"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NOTES_PER_BAR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# for i, result in enumerate(generate(models, 4, styles)):\n",
    "# #     print(i)\n",
    "# #     print(np.array(result).shape)\n",
    "# #     print(unclamp_midi(result).shape)\n",
    "# #     print(midi_encode(unclamp_midi(result)))\n",
    "#     break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = MusicGeneration(styles[0])\n",
    "a = g.build_time_inputs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tuple"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(128, 48, 3)\n",
      "(128, 16)\n",
      "(128, 1)\n"
     ]
    }
   ],
   "source": [
    "for i in a:\n",
    "    print(i.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(a[0]==0).any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(a[1]==0).any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 128, 48, 3)\n",
      "(1, 128, 16)\n",
      "(1, 128, 1)\n"
     ]
    }
   ],
   "source": [
    "for i in process_inputs([a]):\n",
    "    print(i.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 1, 48, 256)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models[1].predict(process_inputs([a]))[:, -1:, :].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 48, 256)"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "note_features = models[1].predict(process_inputs([a]))[:, -1:, :]\n",
    "note_features[0, : ,: , :].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 48, 256)\n",
      "(1, 48, 3)\n",
      "(1, 1)\n"
     ]
    }
   ],
   "source": [
    "b = g.build_note_inputs(note_features[0, : ,: , :])\n",
    "for i in b:\n",
    "    print(i.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 1, 48, 256)\n",
      "(1, 1, 48, 3)\n",
      "(1, 1, 1)\n"
     ]
    }
   ],
   "source": [
    "for i in process_inputs([b]):\n",
    "    print(i.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 1, 48, 3)"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pr = np.array(models[2].predict(process_inputs([b])))\n",
    "pr.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "pr2 = pr[0][-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.0836291"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pr2[2, -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "prob = apply_temperature(pr2[2, :-1], g.temperature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.49578953, 0.4675863 ], dtype=float32)"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "g.choose(pr[0][-1], 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
