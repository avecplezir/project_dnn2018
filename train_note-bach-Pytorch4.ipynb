{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import midi\n",
    "import os\n",
    "\n",
    "from constants import *\n",
    "from dataset import load_all\n",
    "from generate import write_file, generate\n",
    "from play_music_util import play_music\n",
    "\n",
    "import pygame\n",
    "import base64\n",
    "\n",
    "# from playsound import playsound\n",
    "import numpy as np\n",
    "import copy "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import time\n",
    "from IPython import display\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from torch import optim\n",
    "%matplotlib inline\n",
    "\n",
    "import torch, torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['data/Bach']"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "styles = [['data/Bach']]\n",
    "styles[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data\n"
     ]
    }
   ],
   "source": [
    "print('Loading data')\n",
    "X, y = load_all(styles, BATCH_SIZE, SEQ_LEN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((5727, 128, 48, 3), (5727, 128, 48, 3))"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from model import Generator, iterate_minibatches, compute_loss, train, time_axis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Generator(\n",
       "  (time_ax): time_axis(\n",
       "    (attention_layer): MultiHeadAttention(\n",
       "      (attention): ScaledDotProductAttention(\n",
       "        (dropout): Dropout(p=0.1)\n",
       "      )\n",
       "      (proj): Linear(in_features=234, out_features=78, bias=True)\n",
       "      (dropout): Dropout(p=0.1)\n",
       "    )\n",
       "    (FF): PositionwiseFeedForward(\n",
       "      (w_1): Linear(in_features=78, out_features=312, bias=True)\n",
       "      (w_2): Linear(in_features=312, out_features=78, bias=True)\n",
       "      (dropout): Dropout(p=0.1)\n",
       "    )\n",
       "    (time_lstm): LSTM(78, 256, num_layers=2, batch_first=True, dropout=0.1)\n",
       "    (dropout): Dropout(p=0.2)\n",
       "    (generate_features): feature_generation(\n",
       "      (padding): ZeroPad2d(padding=(11, 12, 0, 0), value=0)\n",
       "      (conv): Conv1d(3, 64, kernel_size=(24,), stride=(1,))\n",
       "    )\n",
       "  )\n",
       "  (note_ax): note_axis(\n",
       "    (note_lstm): LSTM(259, 128, num_layers=2, batch_first=True, dropout=0.1)\n",
       "    (dropout): Dropout(p=0.2)\n",
       "    (logits): Linear(in_features=158, out_features=3, bias=True)\n",
       "  )\n",
       "  (overall_information): track_feature(\n",
       "    (overall_information): Conv2d(3, 20, kernel_size=(32, 48), stride=(16, 16))\n",
       "    (l): Linear(in_features=140, out_features=30, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generator = Generator()\n",
    "generator.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "print(generator.note_ax.temperature)\n",
    "print(generator.note_ax.apply_T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X[:,:,:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_tr = X[:-1]\n",
    "X_te = X[-1:]\n",
    "y_tr = y[:-1]\n",
    "y_te = y[-1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((69, 128, 48, 3), (1, 128, 48, 3))"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_tr.shape, X_te.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "355it [00:32, 10.94it/s]"
     ]
    }
   ],
   "source": [
    "generator, epoch_history = train(generator, X_tr, X_te, y_tr, y_te, \n",
    "                                 batchsize=5, n_epochs = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generator = Generator()\n",
    "# generator.cuda()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save/load the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from model import Generator, iterate_minibatches, compute_loss, train\n",
    "# torch.save(generator.state_dict(), os.path.join(OUT_DIR, 'model_test'))\n",
    "# torch.save(generator.state_dict(), os.path.join(OUT_DIR, 'model_track_featured'))\n",
    "# torch.save(generator.state_dict(), os.path.join(OUT_DIR, 'model_canonical_attention'))\n",
    "# the_model = Generator()\n",
    "# generator = Generator()\n",
    "# generator.load_state_dict(torch.load(os.path.join(OUT_DIR, 'model_canonical_attention')))\n",
    "# generator.load_state_dict(torch.load(os.path.join(OUT_DIR, 'generator_rl')))\n",
    "# generator.load_state_dict(torch.load(os.path.join(OUT_DIR, 'model_track_featured')))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def generate_sample(generator,batch_size):\n",
    "#     sound = torch.zeros(batch_size,SEQ_LEN,OCTAVE*NUM_OCTAVES,3).cuda()\n",
    "#     print(sound.shape)\n",
    "#     generator.note_ax.to_train = False\n",
    "#     time_model, note_model, track_feature_model = generator.time_ax, generator.note_ax, generator.overall_information\n",
    "#     for t in range(SEQ_LEN):\n",
    "#         note_features = time_model(sound.data)\n",
    "#         note_features = note_features[:, -1:, :]\n",
    "# #         print('note_features', note_features.shape)\n",
    "#         track_features = track_feature_model(sound.data)      \n",
    "#         current_sound,prob = note_model(note_features, None, track_features)\n",
    "#     generator.note_ax.to_train = True\n",
    "#     return prob ,current_sound"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate_sample(generator, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generator.note_ax.temperature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(the_model)\n",
    "# for i in list(the_model.note_ax.note_lstm.parameters()):\n",
    "#     print(i.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Canonical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1/256 [00:00<00:45,  5.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating with no styles:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:25<00:00, 10.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing file out/samples/output/canonical_test_0.mid\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "generator.cuda()\n",
    "generator.eval()\n",
    "write_file('output/canonical_test', generate(generator, 16, to_train=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 2/128 [00:00<00:09, 12.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating with no styles:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 128/128 [00:05<00:00, 23.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing file out/samples/output/canonical_test1_0.mid\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "write_file('output/canonical_test1', generate(generator, 8, to_train=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# midi_file = 'out/samples/output/canonical_test_0.mid'\n",
    "# play_music(midi_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
