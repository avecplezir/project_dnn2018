{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import argparse\n",
    "import midi\n",
    "import os\n",
    "\n",
    "from constants import *\n",
    "from dataset import load_all\n",
    "from generate import write_file, generate\n",
    "from play_music_util import play_music\n",
    "\n",
    "import pygame\n",
    "import base64\n",
    "\n",
    "# from playsound import playsound\n",
    "import numpy as np\n",
    "import copy "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import time\n",
    "from IPython import display\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from torch import optim\n",
    "%matplotlib inline\n",
    "\n",
    "import torch, torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['data/test']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "styles = [['data/test']]\n",
    "styles[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data\n"
     ]
    }
   ],
   "source": [
    "print('Loading data')\n",
    "train_data, train_labels = load_all(styles, BATCH_SIZE, SEQ_LEN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(70, 128, 48, 3)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from model import Generator, iterate_minibatches, compute_loss, train, time_axis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Generator(\n",
       "  (dropout): Dropout(p=0.3)\n",
       "  (time_ax): time_axis(\n",
       "    (attention_layer): MultiHeadAttention(\n",
       "      (attention): ScaledDotProductAttention(\n",
       "        (dropout): Dropout(p=0.1)\n",
       "      )\n",
       "      (proj): Linear(in_features=234, out_features=78, bias=True)\n",
       "      (dropout): Dropout(p=0.1)\n",
       "    )\n",
       "    (FF): PositionwiseFeedForward(\n",
       "      (w_1): Linear(in_features=78, out_features=312, bias=True)\n",
       "      (w_2): Linear(in_features=312, out_features=78, bias=True)\n",
       "      (dropout): Dropout(p=0.1)\n",
       "    )\n",
       "    (time_lstm): LSTM(78, 256, num_layers=2, batch_first=True, dropout=0.1)\n",
       "    (dropout): Dropout(p=0.5, inplace)\n",
       "    (generate_features): feature_generation(\n",
       "      (padding): ZeroPad2d(padding=(11, 12, 0, 0), value=0)\n",
       "      (conv): Conv1d(3, 64, kernel_size=(24,), stride=(1,))\n",
       "    )\n",
       "  )\n",
       "  (note_ax): note_axis(\n",
       "    (note_lstm): LSTM(259, 128, num_layers=2, batch_first=True, dropout=0.1)\n",
       "    (dropout): Dropout(p=0.2, inplace)\n",
       "    (logits): Linear(in_features=138, out_features=3, bias=True)\n",
       "  )\n",
       "  (overall_information): track_feature(\n",
       "    (overall_information): Conv2d(3, 10, kernel_size=(32, 48), stride=(16, 16))\n",
       "    (l): Linear(in_features=70, out_features=10, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generator = Generator()\n",
    "generator.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "print(generator.note_ax.temperature)\n",
    "print(generator.note_ax.apply_T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_tr = train_data[0][:-1]\n",
    "X_te = train_data[0][-1:]\n",
    "y_tr = train_labels[0][:-1]\n",
    "y_te = train_labels[0][-1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((69, 128, 48, 3), (1, 128, 48, 3))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_tr.shape, X_te.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generator, epoch_history = train(generator, X_tr, X_te, y_tr, y_te, \n",
    "#                                  batchsize=3, n_epochs = 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generator.eval"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save/load the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from model import Generator, iterate_minibatches, compute_loss, train\n",
    "# torch.save(generator.state_dict(), os.path.join(OUT_DIR, 'model_test'))\n",
    "# torch.save(generator.state_dict(), os.path.join(OUT_DIR, 'model_track_featured'))\n",
    "# torch.save(generator.state_dict(), os.path.join(OUT_DIR, 'model_canonical_attention_without_mul'))\n",
    "# the_model = Generator()\n",
    "# generator = Generator()\n",
    "# generator.load_state_dict(torch.load(os.path.join(OUT_DIR, 'model_canonical_attention')))\n",
    "# generator.load_state_dict(torch.load(os.path.join(OUT_DIR, 'generator_rl')))\n",
    "generator.load_state_dict(torch.load(os.path.join(OUT_DIR, 'model_track_featured')))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generator.note_ax.temperature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(the_model)\n",
    "# for i in list(the_model.note_ax.note_lstm.parameters()):\n",
    "#     print(i.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Canonical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/256 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating with no styles:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 256/256 [00:11<00:00, 21.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing file out/samples/output/canonical_test_0.mid\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "generator.cuda()\n",
    "generator.eval()\n",
    "write_file('output/canonical_test', generate(generator, 16, to_train=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 1/128 [00:00<00:13,  9.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating with no styles:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 128/128 [00:05<00:00, 25.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing file out/samples/output/canonical_test1_0.mid\n"
     ]
    }
   ],
   "source": [
    "write_file('output/canonical_test1', generate(generator, 8, to_train=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# midi_file = 'out/samples/output/canonical_test_0.mid'\n",
    "# play_music(midi_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
