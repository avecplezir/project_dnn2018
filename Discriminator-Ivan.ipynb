{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch,torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "import numpy as np\n",
    "from model import Generator, iterate_minibatches, compute_loss, train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "OCTAVE_NUM = 4\n",
    "NOTE_NUM = 12\n",
    "TIME_SCALE = 128\n",
    "\n",
    "\n",
    "class LSTM_discriminator(nn.Module):\n",
    "    def __init__(self,hidden_size = 1000,last_dim = 3):\n",
    "        super(self.__class__, self).__init__()\n",
    "        self.last_dim = last_dim\n",
    "        self.hidden_size = hidden_size\n",
    "        self.note_lstm = nn.LSTM(input_size = OCTAVE_NUM*last_dim,hidden_size = hidden_size)\n",
    "        self.time_lstm = nn.LSTM(input_size = hidden_size,hidden_size = hidden_size)\n",
    "        self.dense = nn.Linear(hidden_size,1)\n",
    "\n",
    "    def forward(self,data):\n",
    "        # data.size() =  (batch_size, TIME_SCALE, NOTE_NUM*OCTAVE_NUM, last_dim)\n",
    "        # octave_data.size() =  (batch_size, TIME_SCALE, NOTE_NUM,OCTAVE_NUM*last_dim)\n",
    "        batch_size,_,_,_ = data.size()\n",
    "        octave_data = data.view(batch_size,TIME_SCALE,NOTE_NUM,OCTAVE_NUM,self.last_dim)\\\n",
    "                          .view(batch_size,TIME_SCALE,NOTE_NUM,OCTAVE_NUM*self.last_dim)\n",
    "            \n",
    "        # note_lstm_input.size() = (NOTE_NUM, batch_size*TIME_SCALE,OCTAVE_NUM*last_dim)\n",
    "        note_lstm_input = octave_data.view(batch_size*TIME_SCALE,NOTE_NUM,OCTAVE_NUM*self.last_dim)\\\n",
    "                                     .transpose(0,1)\n",
    "        # note_lstm_output.size() = (NOTE_NUM,batch_size*TIME_SCALE,hidden_size)\n",
    "        note_lstm_output, _ = self.note_lstm(note_lstm_input)\n",
    "        # time_lstm_input.size() = (TIME_SCALE,batch_size,hidden_size)\n",
    "        time_lstm_input = note_lstm_output[-1].view(batch_size,TIME_SCALE,self.hidden_size)\\\n",
    "                                          .transpose(0,1)\\\n",
    "        # time_lstm_output.size() = (TIME_SCALE,batch_size,1000)\n",
    "        time_lstm_output, _  = self.time_lstm(time_lstm_input)\n",
    "        # dense_input.size() = (batch_size,1000)\n",
    "        dense_input = time_lstm_output[-1]\n",
    "        # dense_output.size() = (batch_size,1)\n",
    "        dense_output = self.dense(dense_input)\n",
    "        probs = F.sigmoid(dense_output)\n",
    "        return probs\n",
    "        \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# device = torch.device(\"cuda:4\" if torch.cuda.is_available() else \"cpu\")\n",
    "# # device = torch.device(\"cpu\")\n",
    "# discriminator = LSTM_discriminator(hidden_size=10).to(device)\n",
    "# np_data = np.random.randn(10,TIME_SCALE,NOTE_NUM*OCTAVE_NUM,3)\n",
    "# data = torch.FloatTensor(np_data).to(device)\n",
    "# discriminator(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTM_baseline(nn.Module):\n",
    "    def __init__(self,hidden_size = 1000):\n",
    "        super(self.__class__, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.note_lstm = nn.LSTM(input_size = OCTAVE_NUM*3,hidden_size = hidden_size)\n",
    "        self.time_lstm = nn.LSTM(input_size = hidden_size,hidden_size = hidden_size)\n",
    "        self.dense = nn.Linear(hidden_size,1)\n",
    "\n",
    "    def forward(self,data,_):\n",
    "        # data.size() =  (batch_size, TIME_SCALE, NOTE_NUM*OCTAVE_NUM, 3)\n",
    "        # octave_data.size() =  (batch_size, TIME_SCALE, NOTE_NUM,OCTAVE_NUM*3)\n",
    "        batch_size,_,_,_ = data.size()\n",
    "        octave_data = data.view(batch_size,TIME_SCALE,NOTE_NUM,OCTAVE_NUM,3)\\\n",
    "                          .view(batch_size,TIME_SCALE,NOTE_NUM,OCTAVE_NUM*3)\n",
    "            \n",
    "        # note_lstm_input.size() = (NOTE_NUM, batch_size*TIME_SCALE,OCTAVE_NUM*3)\n",
    "        note_lstm_input = octave_data.view(batch_size*TIME_SCALE,NOTE_NUM,OCTAVE_NUM*3)\\\n",
    "                                     .transpose(0,1)\n",
    "        # note_lstm_output.size() = (NOTE_NUM,batch_size*TIME_SCALE,hidden_size)\n",
    "        note_lstm_output, _ = self.note_lstm(note_lstm_input)\n",
    "        # time_lstm_input.size() = (TIME_SCALE,batch_size,hidden_size)\n",
    "        time_lstm_input = note_lstm_output[-1].view(batch_size,TIME_SCALE,self.hidden_size)\\\n",
    "                                          .transpose(0,1)\\\n",
    "        # time_lstm_output.size() = (TIME_SCALE,batch_size,1000)\n",
    "        time_lstm_output, _  = self.time_lstm(time_lstm_input)\n",
    "        # dense_input.size() = (batch_size,1000)\n",
    "        dense_input = time_lstm_output[-1]\n",
    "        # dense_output.size() = (batch_size,1)\n",
    "        dense_output = self.dense(dense_input)\n",
    "        probs = F.sigmoid(dense_output)\n",
    "        return probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# discriminator = LSTM_baseline(hidden_size=1000).to(device)\n",
    "# np_data = np.random.randn(10,TIME_SCALE,NOTE_NUM*OCTAVE_NUM,3)\n",
    "# data = torch.FloatTensor(np_data).to(device)\n",
    "# discriminator(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BasicGenerator(nn.Module):\n",
    "    def __init__(self,hidden_size = 1000):\n",
    "        super(self.__class__, self).__init__()\n",
    "        self.dense_in = nn.Linear(TIME_SCALE*NOTE_NUM*OCTAVE_NUM*3,hidden_size)\n",
    "        self.dense_out = nn.Linear(hidden_size,TIME_SCALE*NOTE_NUM*OCTAVE_NUM*3)\n",
    "\n",
    "    def forward(self,data,_):\n",
    "        batch_size,_,_,_ = data.size()\n",
    "        data = data.view(batch_size,-1)\n",
    "        hid_data = self.dense_in(data)\n",
    "        out_data = self.dense_out(hid_data)\n",
    "        output = F.sigmoid(out_data.view(batch_size, TIME_SCALE, NOTE_NUM*OCTAVE_NUM, 3))\n",
    "        return output\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BasicDiscriminator(nn.Module):\n",
    "    def __init__(self,hidden_size = 1000):\n",
    "        super(self.__class__, self).__init__()\n",
    "        self.dense_in = nn.Linear(TIME_SCALE*NOTE_NUM*OCTAVE_NUM*3,hidden_size)\n",
    "        self.dense_out = nn.Linear(hidden_size,1)\n",
    "\n",
    "    def forward(self,data):\n",
    "        batch_size,_,_,_ = data.size()\n",
    "        data = data.view(batch_size,-1)\n",
    "        hid_data = self.dense_in(data)\n",
    "        out_data = self.dense_out(hid_data)\n",
    "        output = F.sigmoid(out_data)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def g_loss(p_fake,sound,in_probs,baseline_pred,eps = 1e-8):\n",
    "#     probs = sound[:,TIME_SCALE//2:,:,:2]*in_probs[:,TIME_SCALE//2:,:,:2]\\\n",
    "#             +(1-sound[:,TIME_SCALE//2:,:,:2])*(1-in_probs[:,TIME_SCALE//2:,:,:2])\n",
    "    probs = sound[:,:,:,:2]*in_probs[:,:,:,:2]\\\n",
    "            +(1-sound[:,:,:,:2])*(1-in_probs[:,:,:,:2])\n",
    "    print(p_fake.mean(),probs.mean())\n",
    "    return -((probs+eps).log().sum(dim =-1).sum(dim =-1).sum(dim =-1)*(p_fake-baseline_pred)).mean()-(in_probs[:,:,:,2].mean()-1)\n",
    "#     return -(p_fake+eps).log().mean()\n",
    "def d_loss(p_fake, p_true,eps = 1e-8):\n",
    "     return -((1-p_fake+eps).log().mean()-(p_true+eps).log().mean())\n",
    "    \n",
    "def bl_loss(bl_pred,real_reward):\n",
    "    return (bl_pred-real_reward).pow(2).mean()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.utils.data\n",
    "\n",
    "def sample_sound(data_gen):\n",
    "    size = data_gen.size()\n",
    "    rand = torch.rand(*size).cuda()\n",
    "    sample = (rand<data_gen).type(torch.FloatTensor).cuda()\n",
    "#     sample[:,:,:,2] = data_gen[:,:,:,2]\n",
    "    sample[:,:,:,2] = 1\n",
    "    return sample\n",
    "    \n",
    "\n",
    "def train_GAN(generator,discriminator,baseline,X_loader,Y_loader,num_epochs = 3,g_lr = 0.001, d_lr = 0.001,bl_lr = 0.001):\n",
    "    generator.train()\n",
    "    discriminator.train()\n",
    "    g_optimizer = torch.optim.Adam(generator.parameters(),     lr=g_lr)#, betas=(0.5, 0.999))\n",
    "    d_optimizer = torch.optim.Adam(discriminator.parameters(), lr=d_lr)#, betas=(0.5, 0.999))\n",
    "    bl_optimizer = torch.optim.Adam(baseline.parameters(), lr=bl_lr)\n",
    "    \n",
    "    d_losses = []\n",
    "    g_losses = []\n",
    "    bl_losses = []\n",
    "    for epoch in range(num_epochs):\n",
    "        for [x_batch,ch_batch],[y_batch] in zip(X_loader,Y_loader):\n",
    "            x_batch = x_batch.cuda()\n",
    "            ch_batch = ch_batch.cuda()\n",
    "            y_batch = y_batch.cuda()\n",
    "            x_batch[:,:,:,2] = 1\n",
    "            ch_batch[:,:,:,2] = 1\n",
    "            y_batch[:,:,:,2] = 1\n",
    "            # Optimize D\n",
    "\n",
    "            data_gen = generator(x_batch,ch_batch)\n",
    "            sound = sample_sound(data_gen).data\n",
    "            #concat_sound = torch.cat([x_batch[:,1:TIME_SCALE//2+1,:,:],sound[:,TIME_SCALE//2:,:,:]],dim = 1)\n",
    "            loss = d_loss(discriminator(sound), discriminator(y_batch))\n",
    "            d_optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "#             print(loss.grad)\n",
    "            d_optimizer.step()\n",
    "            d_losses.append(loss.data.cpu().numpy())\n",
    "        \n",
    "            # Optimize BL\n",
    "            data_gen = generator(x_batch,ch_batch)\n",
    "            sound = sample_sound(data_gen).data\n",
    "            loss = bl_loss(baseline(x_batch,ch_batch),discriminator(sound))\n",
    "            bl_optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            bl_optimizer.step()\n",
    "            bl_losses.append(loss.data.cpu().numpy())\n",
    "            \n",
    "            # Optimize G\n",
    "            \n",
    "            data_gen = generator(x_batch,ch_batch)\n",
    "            sound = sample_sound(data_gen).data\n",
    "            #concat_sound = torch.cat([x_batch[:,1:TIME_SCALE//2+1,:,:],sound[:,TIME_SCALE//2:,:,:]],dim = 1)\n",
    "            loss = g_loss(discriminator(sound),sound,data_gen,baseline(x_batch,ch_batch))#,sound.data,data_gen)\n",
    "            g_optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "#             print(loss.grad)\n",
    "            g_optimizer.step()\n",
    "            g_losses.append(loss.data.cpu().numpy())\n",
    "    return generator,discriminator,baseline,np.array(g_losses),np.array(d_losses),np.array(bl_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((5727, 128, 48, 3), (2500, 128, 48, 3), (2500, 128, 48, 3), 2500)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dataset import load_all\n",
    "from constants import *\n",
    "\n",
    "styles= [['data/Bach']]\n",
    "train_data, train_labels = load_all(styles, BATCH_SIZE, TIME_SCALE)\n",
    "N = 2500\n",
    "X_tr = train_data[0][:N]\n",
    "y_tr = train_labels[0][:N]\n",
    "X_te = train_data[0][N:2*N]\n",
    "train_data[0].shape,X_te.shape,y_tr.shape,N\n",
    "#y_te = train_labels[0][-1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_loader = torch.utils.data.DataLoader(\\\n",
    "            torch.utils.data.TensorDataset(\\\n",
    "            *(torch.FloatTensor(X_tr),\n",
    "            torch.FloatTensor(y_tr))),\\\n",
    "            batch_size=10,shuffle=True)\n",
    "\n",
    "Y_loader = torch.utils.data.DataLoader(\\\n",
    "            torch.utils.data.TensorDataset(\\\n",
    "            torch.FloatTensor(X_te)),\\\n",
    "            batch_size=10,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import gc\n",
    "# with torch.cuda.device(GPU):\n",
    "#     torch.cuda.empty_cache()\n",
    "#     gc.collect() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "size mismatch, m1: [10 x 36864], m2: [18432 x 1000] at /opt/conda/conda-bld/pytorch_1525812548180/work/aten/src/THC/generic/THCTensorMathBlas.cu:249",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-38-5afbd7df4b7d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mdiscriminator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBasicDiscriminator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0mgenerator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdiscriminator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbaseline\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mg_losses\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0md_losses\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbl_losses\u001b[0m \u001b[0;34m=\u001b[0m                    \u001b[0mtrain_GAN2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgenerator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdiscriminator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbaseline\u001b[0m\u001b[0;34m,\u001b[0m                            \u001b[0mX_loader\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mY_loader\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnum_epochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mg_lr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m1e-2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0md_lr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m1e-2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbl_lr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m1e-3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-31-58fe09901faf>\u001b[0m in \u001b[0;36mtrain_GAN2\u001b[0;34m(generator, discriminator, baseline, X_loader, Y_loader, num_epochs, g_lr, d_lr, bl_lr)\u001b[0m\n\u001b[1;32m     28\u001b[0m             \u001b[0mfalse_example\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msound\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mx_batch\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m             \u001b[0mtrue_example\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0my_batch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mx_batch\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0md_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdiscriminator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfalse_example\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdiscriminator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrue_example\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m             \u001b[0md_optimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m             \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/miniconda/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    489\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    490\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 491\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    492\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    493\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-23-ece5b06b29c8>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m         \u001b[0mhid_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdense_in\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m         \u001b[0mout_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdense_out\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhid_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msigmoid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/miniconda/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    489\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    490\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 491\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    492\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    493\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/miniconda/lib/python3.6/site-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 55\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     56\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/miniconda/lib/python3.6/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mlinear\u001b[0;34m(input, weight, bias)\u001b[0m\n\u001b[1;32m    990\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mbias\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    991\u001b[0m         \u001b[0;31m# fused op is marginally faster\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 992\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maddmm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    993\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    994\u001b[0m     \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: size mismatch, m1: [10 x 36864], m2: [18432 x 1000] at /opt/conda/conda-bld/pytorch_1525812548180/work/aten/src/THC/generic/THCTensorMathBlas.cu:249"
     ]
    }
   ],
   "source": [
    "# GPU = 2\n",
    "# with torch.cuda.device(GPU):\n",
    "\n",
    "# device = torch.device(\"cuda:6\" if torch.cuda.is_available() else \"cpu\")\n",
    "# device = torch.device(\"cpu\")\n",
    "generator = Generator().cuda()\n",
    "discriminator = LSTM_discriminator(hidden_size=100,last_dim=6).cuda()\n",
    "# generator = BasicGenerator().cuda()\n",
    "baseline = LSTM_baseline(hidden_size=10).cuda()\n",
    "discriminator = BasicDiscriminator().cuda()\n",
    "    \n",
    "generator,discriminator,baseline,g_losses,d_losses,bl_losses =\\\n",
    "                    train_GAN2(generator,discriminator,baseline,\\\n",
    "                            X_loader,Y_loader,num_epochs = 2, g_lr = 1*1e-2,d_lr=1*1e-2, bl_lr = 1*1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(g_losses,label = \"Generator loss\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "plt.plot(d_losses,label = \"Discriminator loss\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "plt.plot(bl_losses,label = \"Baseline loss\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([18.420675, 18.420675, 18.420675, 18.420675, 18.420675, 18.420675,\n",
       "       18.420675, 18.420675, 18.420675, 18.420675, 18.420675, 18.420675,\n",
       "       18.420675, 18.420675, 18.420675, 18.420675, 18.420675, 18.420675,\n",
       "       18.420675, 18.420675, 18.420675, 18.420675, 18.420675, 18.420675,\n",
       "       18.420675, 18.420675, 18.420675, 18.420675, 18.420675, 18.420675,\n",
       "       18.420675, 18.420675, 18.420675, 18.420675, 18.420675, 18.420675,\n",
       "       18.420675, 18.420675, 18.420675, 18.420675, 18.420675, 18.420675,\n",
       "       18.420675, 18.420675, 18.420675, 18.420675, 18.420675, 18.420675,\n",
       "       18.420675, 18.420675], dtype=float32)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g_losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 1/64 [00:00<00:07,  8.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating with no styles:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 64/64 [00:08<00:00,  7.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing file out/samples/output/canonical_test_0.mid\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from generate import write_file, generate\n",
    "# import gc\n",
    "# torch.cuda.empty_cache()\n",
    "# gc.collect() \n",
    "\n",
    "with torch.cuda.device(GPU):\n",
    "    write_file('output/canonical_test', generate(generator, 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.utils.data\n",
    "\n",
    "    \n",
    "\n",
    "def train_GAN2(generator,discriminator,baseline,X_loader,Y_loader,num_epochs = 3,g_lr = 0.001, d_lr = 0.001,bl_lr = 0.001):\n",
    "    generator.train()\n",
    "    discriminator.train()\n",
    "    g_optimizer = torch.optim.Adam(generator.parameters(),     lr=g_lr)#, betas=(0.5, 0.999))\n",
    "    d_optimizer = torch.optim.Adam(discriminator.parameters(), lr=d_lr,weight_decay = 1)#, betas=(0.5, 0.999))\n",
    "    bl_optimizer = torch.optim.Adam(baseline.parameters(), lr=bl_lr)\n",
    "    \n",
    "    d_losses = []\n",
    "    g_losses = []\n",
    "    bl_losses = []\n",
    "    for epoch in range(num_epochs):\n",
    "        for [x_batch,ch_batch],[y_batch] in zip(X_loader,Y_loader):\n",
    "            x_batch = x_batch.cuda()\n",
    "            ch_batch = ch_batch.cuda()\n",
    "            y_batch = y_batch.cuda()\n",
    "            x_batch[:,:,:,2] = 1\n",
    "            ch_batch[:,:,:,2] = 1\n",
    "            y_batch[:,:,:,2] = 1\n",
    "            # Optimize D\n",
    "\n",
    "            data_gen = generator(x_batch,ch_batch)\n",
    "            sound = sample_sound(data_gen).data\n",
    "            #concat_sound = torch.cat([x_batch[:,1:TIME_SCALE//2+1,:,:],sound[:,TIME_SCALE//2:,:,:]],dim = 1)\n",
    "            false_example = torch.cat([sound,x_batch],dim = -1)\n",
    "            true_example = torch.cat([y_batch,x_batch],dim = -1)\n",
    "            loss = d_loss(discriminator(false_example), discriminator(true_example))\n",
    "            d_optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "#             print(loss.grad)\n",
    "            d_optimizer.step()\n",
    "            d_losses.append(loss.data.cpu().numpy())\n",
    "        \n",
    "            # Optimize BL\n",
    "            data_gen = generator(x_batch,ch_batch)\n",
    "            sound = sample_sound(data_gen).data\n",
    "            false_example = torch.cat([sound,x_batch],dim = -1)\n",
    "            loss = bl_loss(baseline(x_batch,ch_batch),discriminator(false_example))\n",
    "            bl_optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            bl_optimizer.step()\n",
    "            bl_losses.append(loss.data.cpu().numpy())\n",
    "            \n",
    "            # Optimize G\n",
    "            \n",
    "            data_gen = generator(x_batch,ch_batch)\n",
    "            sound = sample_sound(data_gen).data\n",
    "            #concat_sound = torch.cat([x_batch[:,1:TIME_SCALE//2+1,:,:],sound[:,TIME_SCALE//2:,:,:]],dim = 1)\n",
    "            false_example = torch.cat([sound,x_batch],dim = -1)\n",
    "            loss = g_loss(discriminator(false_example),sound,data_gen,baseline(x_batch,ch_batch))#,sound.data,data_gen)\n",
    "            g_optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "#             print(loss.grad)\n",
    "            g_optimizer.step()\n",
    "            g_losses.append(loss.data.cpu().numpy())\n",
    "    return generator,discriminator,baseline,np.array(g_losses),np.array(d_losses),np.array(bl_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
