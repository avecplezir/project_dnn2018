{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from keras.callbacks import ModelCheckpoint, LambdaCallback\n",
    "from keras.callbacks import EarlyStopping, TensorBoard\n",
    "import argparse\n",
    "import midi\n",
    "import os\n",
    "\n",
    "from constants import *\n",
    "from dataset import load_all\n",
    "from generate import write_file, generate\n",
    "from play_music_util import play_music\n",
    "\n",
    "import pygame\n",
    "import base64\n",
    "\n",
    "from playsound import playsound"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from keras.layers import Input, LSTM, Dense, Dropout, Lambda, Reshape, Permute\n",
    "from keras.layers import TimeDistributed, RepeatVector, Conv1D, Activation\n",
    "from keras.layers import Embedding, Flatten, dot, concatenate \n",
    "from keras.layers.merge import Concatenate, Add, Multiply\n",
    "from keras.models import Model\n",
    "import keras.backend as K\n",
    "from keras import losses\n",
    "from keras.utils import multi_gpu_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['data/test']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "styles[0]\n",
    "# styles[0] = 'data/test'\n",
    "# styles[0] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data\n"
     ]
    }
   ],
   "source": [
    "print('Loading data')\n",
    "train_data, train_labels = load_all(styles, BATCH_SIZE, SEQ_LEN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 128, 48, 3)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10, 128, 48, 3)\n",
      "(10, 128, 48, 3)\n",
      "(10, 128, 16)\n"
     ]
    }
   ],
   "source": [
    "for i in range(3):\n",
    "    print(train_data[i].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_labels[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch, torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32, 48, 3)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " BATCH_SIZE, NUM_NOTES, NOTE_UNITS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "cuda = False\n",
    "\n",
    "def iterate_minibatches(train_data, train_labels, batchsize):\n",
    "    indices = np.random.permutation(np.arange(len(train_labels)))\n",
    "    for start in range(0, len(indices), batchsize):\n",
    "        ix = indices[start: start + batchsize]\n",
    "        \n",
    "        if cuda:      \n",
    "            yield  Variable(torch.FloatTensor(train_data[ix])).cuda(), Variable(torch.FloatTensor(train_labels[ix])).cuda()\n",
    "        else:\n",
    "            yield Variable(torch.FloatTensor(train_data[ix])), Variable(torch.FloatTensor(train_labels[ix]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Pytorch implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class time_axis(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(self.__class__, self).__init__() \n",
    "        self.n_layers = 1\n",
    "        self.hidden_size = TIME_AXIS_UNITS\n",
    "        self.input_size = NOTE_UNITS\n",
    "        \n",
    "\n",
    "        self.time_lstm = nn.LSTM(self.input_size, self.hidden_size, self.n_layers, dropout=0.1, \n",
    "                                 batch_first=True, )\n",
    "        self.dropout = nn.Dropout(p=0.2, inplace=True)\n",
    "        \n",
    "    def forward(self, notes):\n",
    "        \n",
    "        \"\"\"\n",
    "        arg:\n",
    "            notes - (batch, time_seq, note_seq, note_features)\n",
    "        \n",
    "        out: \n",
    "            (batch, time_seq, note_seq, hidden_features)\n",
    "            \n",
    "        \"\"\"\n",
    "        \n",
    "        lstm_out = []        \n",
    "        for i in range(notes.shape[2]):\n",
    "            \n",
    "            out, hidden = self.time_lstm(notes[:, :, i,:]) \n",
    "            \n",
    "            lstm_out.append(out[:, :, None, :])\n",
    "\n",
    "        \n",
    "        \n",
    "        time_output = torch.cat(lstm_out, dim=2)\n",
    "#         self.dropout(time_output)\n",
    "        \n",
    "        return time_output        \n",
    "    \n",
    "class note_axis(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(self.__class__, self).__init__()   \n",
    "        \n",
    "        self.n_layers = 2\n",
    "        self.hidden_size = NOTE_AXIS_UNITS\n",
    "        # number of time features plus number of previous higher note in the same time momemt\n",
    "        self.input_size = TIME_AXIS_UNITS + NOTE_UNITS\n",
    "        \n",
    "        # maybe it is better to make two lstm and make the second one bideractional \n",
    "        self.note_lstm = nn.LSTM(self.input_size, self.hidden_size, self.n_layers, dropout=0.1, \n",
    "                                 batch_first=True, )\n",
    "        \n",
    "        self.dropout = nn.Dropout(p=0.2, inplace=True)\n",
    "        \n",
    "        self.logits = nn.Linear(self.hidden_size, NOTE_UNITS) \n",
    "        \n",
    "    def forward(self, notes, chosen):\n",
    "        \"\"\"\n",
    "        arg:\n",
    "            notes - (batch, time_seq, note_seq, time_hidden_features)\n",
    "        \n",
    "        out: \n",
    "            (batch, time_seq, note_seq, next_notes_features)\n",
    "            \n",
    "        \"\"\"\n",
    "                \n",
    "        # Shift target one note to the left.\n",
    "        shift_chosen = nn.ZeroPad2d((0, 0, 1, 0))(chosen[:, :, :-1, :])            \n",
    "        note_input = torch.cat([notes, shift_chosen], dim=-1)\n",
    "\n",
    "        \n",
    "        lstm_out = []\n",
    "        for i in range(notes.shape[1]):\n",
    "            \n",
    "            out, hidden = self.note_lstm(note_input[:, i, :,:]) \n",
    "            lstm_out.append(out[:, None, :, :])\n",
    "              \n",
    "        time_output = torch.cat(lstm_out, dim=1)\n",
    "#         self.dropout(time_output)\n",
    "\n",
    "        logits = self.logits(time_output) \n",
    "        next_notes = nn.Sigmoid()(logits)\n",
    "        \n",
    "        return next_notes \n",
    "    \n",
    "class Generator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(self.__class__, self).__init__()        \n",
    "        \n",
    "        self.time_ax = time_axis() \n",
    "        self.note_ax = note_axis()\n",
    "        \n",
    "    def forward(self, notes, chosen):\n",
    "        \n",
    "        note_ax_output = self.time_ax(notes)\n",
    "        output = self.note_ax(note_ax_output, chosen)\n",
    "        \n",
    "        return output   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion_bce_play = nn.BCELoss()  \n",
    "criterion_bce_replay = nn.BCELoss() \n",
    "criterion_mse = nn.MSELoss()  \n",
    "\n",
    "def compute_loss(y_pred, y_true):\n",
    "    \n",
    "    played = y_true[:, :, :, 0]\n",
    "    \n",
    "    bce_note = criterion_bce_play(y_pred[:, :, :, 0], y_true[:, :, :, 0])\n",
    "\n",
    "    replay = played*y_pred[:, :, :, 1] + (1 - played)*y_true[:, :, :, 1]\n",
    "    \n",
    "    bce_replay = criterion_bce_replay(replay, y_true[:, :, :, 1])\n",
    "    \n",
    "    volume = played*y_pred[:, :, :, 2] + (1 - played)*y_true[:, :, :, 2]\n",
    "    mse = criterion_mse(volume, y_true[:, :, :, 2] )\n",
    "    \n",
    "    return bce_note + bce_replay + mse\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Variable containing:\n",
       " 0.6974\n",
       "[torch.FloatTensor of size 1]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compute_loss(output, chosen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator = Generator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 128, 48, 3)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_tr = train_data[0][:-1]\n",
    "X_te = train_data[0][-1:]\n",
    "y_tr = train_labels[0][:-1]\n",
    "y_te = train_labels[0][-1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((9, 128, 48, 3), (1, 128, 48, 3))"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_tr.shape, X_te.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import time\n",
    "from IPython import display\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3 of 3 took 76.842s\n",
      "current train loss: 0.3965347210566203\n",
      "current val loss: 0.23487414419651031\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11b6eb748>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished!\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "from torch import optim\n",
    "\n",
    "def train(X_tr, X_te, y_tr, y_te, batchsize=3, n_epochs = 3):\n",
    "    \n",
    "    n_epochs = 3\n",
    "    batchsize = 3\n",
    "    optimizer = optim.Adam(generator.parameters())\n",
    "    n_train_batches = math.ceil(len(X_tr)/batchsize)\n",
    "    n_validation_batches = math.ceil(len(X_te)/batchsize)\n",
    "\n",
    "    epoch_history = {'train_loss':[], 'val_loss':[]}\n",
    "\n",
    "    for epoch in range(n_epochs):\n",
    "\n",
    "        start_time = time.time()\n",
    "\n",
    "        train_loss = 0\n",
    "        generator.train(True)    \n",
    "        for X, y in tqdm(iterate_minibatches(X_tr, y_tr, batchsize)):\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            pred = generator(X, y)\n",
    "            loss = compute_loss(pred, y)        \n",
    "            loss.backward()\n",
    "\n",
    "            optimizer.step()\n",
    "\n",
    "            train_loss += loss.cpu().data.numpy()[0]\n",
    "\n",
    "        train_loss /= n_train_batches\n",
    "        epoch_history['train_loss'].append(train_loss)\n",
    "    #     print('train_loss', train_loss)\n",
    "\n",
    "        generator.train(False)\n",
    "        val_loss = 0\n",
    "        for X, y in tqdm(iterate_minibatches(X_te, y_te, batchsize)):\n",
    "            pred = generator(X, y)\n",
    "            loss = compute_loss(pred, y) \n",
    "\n",
    "            val_loss += loss.cpu().data.numpy()[0]\n",
    "\n",
    "        val_loss /= n_validation_batches\n",
    "        epoch_history['val_loss'].append(val_loss)\n",
    "    #     print('val_loss', val_loss)\n",
    "\n",
    "        # Visualize\n",
    "        display.clear_output(wait=True)\n",
    "        plt.figure(figsize=(16, 6))\n",
    "        # Then we print the results for this epoch:\n",
    "        print(\"Epoch {} of {} took {:.3f}s\".format(\n",
    "            epoch + 1, n_epochs, time.time() - start_time)) \n",
    "        print('current train loss: {}'.format(epoch_history['train_loss'][-1]))\n",
    "        print('current val loss: {}'.format(epoch_history['val_loss'][-1]))\n",
    "\n",
    "        plt.title(\"losses\")\n",
    "        plt.xlabel(\"#epoch\")\n",
    "        plt.ylabel(\"loss\")\n",
    "        plt.plot(epoch_history['train_loss'], 'b', label = 'train_loss')\n",
    "        plt.plot(epoch_history['val_loss'], 'g', label = 'val_loss')\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "\n",
    "    print(\"Finished!\")\n",
    "    \n",
    "    return epoch_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(time_axis(\n",
       "   (time_lstm): LSTM(3, 256, batch_first=True, dropout=0.1)\n",
       "   (dropout): Dropout(p=0.2, inplace)\n",
       " ), note_axis(\n",
       "   (note_lstm): LSTM(259, 128, num_layers=2, batch_first=True, dropout=0.1)\n",
       "   (dropout): Dropout(p=0.2, inplace)\n",
       "   (logits): Linear(in_features=128, out_features=3)\n",
       " ))"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generator.time_ax, generator.note_ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Generator(\n",
       "  (time_ax): time_axis(\n",
       "    (time_lstm): LSTM(3, 256, batch_first=True, dropout=0.1)\n",
       "    (dropout): Dropout(p=0.2, inplace)\n",
       "  )\n",
       "  (note_ax): note_axis(\n",
       "    (note_lstm): LSTM(259, 128, num_layers=2, batch_first=True, dropout=0.1)\n",
       "    (dropout): Dropout(p=0.2, inplace)\n",
       "    (logits): Linear(in_features=128, out_features=3)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generator.train(False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.save(generator.state_dict(), os.path.join(OUT_DIR, 'model_canonical'))\n",
    "the_model = Generator()\n",
    "the_model.load_state_dict(torch.load(os.path.join(OUT_DIR, 'model_canonical')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dummy_time_features : torch.Size([10, 128, 48, 3])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(Variable containing:\n",
       "  0.4009\n",
       "  0.4684\n",
       "  0.5171\n",
       " [torch.FloatTensor of size 3], Variable containing:\n",
       "  0.4034\n",
       "  0.4694\n",
       "  0.5169\n",
       " [torch.FloatTensor of size 3])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dummy_note = Variable(torch.Tensor(train_data[0]))\n",
    "chosen = Variable(torch.Tensor(train_data[1]))\n",
    "\n",
    "# output = generator.forward(dummy_note, chosen)\n",
    "output = the_model.forward(dummy_note, chosen)\n",
    "\n",
    "print('dummy_time_features :', output.shape)\n",
    "output[0][0][3], output2[0][0][3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Canonical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/64 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating with no styles:\n",
      "ins (1, 128, 48, 3)\n",
      "note_features torch.Size([1, 128, 48, 256])\n",
      "note_features torch.Size([1, 1, 48, 256])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  2%|▏         | 1/64 [00:01<01:37,  1.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ins (1, 128, 48, 3)\n",
      "note_features torch.Size([1, 128, 48, 256])\n",
      "note_features torch.Size([1, 1, 48, 256])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  3%|▎         | 2/64 [00:03<01:41,  1.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "ins (1, 128, 48, 3)\n",
      "note_features torch.Size([1, 128, 48, 256])\n",
      "note_features torch.Size([1, 1, 48, 256])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  5%|▍         | 3/64 [00:04<01:37,  1.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "ins (1, 128, 48, 3)\n",
      "note_features torch.Size([1, 128, 48, 256])\n",
      "note_features torch.Size([1, 1, 48, 256])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  6%|▋         | 4/64 [00:06<01:34,  1.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "ins (1, 128, 48, 3)\n",
      "note_features torch.Size([1, 128, 48, 256])\n",
      "note_features torch.Size([1, 1, 48, 256])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  8%|▊         | 5/64 [00:08<01:34,  1.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "ins (1, 128, 48, 3)\n",
      "note_features torch.Size([1, 128, 48, 256])\n",
      "note_features torch.Size([1, 1, 48, 256])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  9%|▉         | 6/64 [00:13<02:09,  2.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "ins (1, 128, 48, 3)\n",
      "note_features torch.Size([1, 128, 48, 256])\n",
      "note_features torch.Size([1, 1, 48, 256])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 11%|█         | 7/64 [00:14<01:59,  2.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "ins (1, 128, 48, 3)\n",
      "note_features torch.Size([1, 128, 48, 256])\n",
      "note_features torch.Size([1, 1, 48, 256])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 12%|█▎        | 8/64 [00:15<01:51,  1.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "ins (1, 128, 48, 3)\n",
      "note_features torch.Size([1, 128, 48, 256])\n",
      "note_features torch.Size([1, 1, 48, 256])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 14%|█▍        | 9/64 [00:17<01:44,  1.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "ins (1, 128, 48, 3)\n",
      "note_features torch.Size([1, 128, 48, 256])\n",
      "note_features torch.Size([1, 1, 48, 256])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 16%|█▌        | 10/64 [00:18<01:39,  1.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predictions torch.Size([1, 1, 48, 3])\n",
      "ins (1, 128, 48, 3)\n",
      "note_features torch.Size([1, 128, 48, 256])\n",
      "note_features torch.Size([1, 1, 48, 256])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 17%|█▋        | 11/64 [00:20<01:36,  1.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "ins (1, 128, 48, 3)\n",
      "note_features torch.Size([1, 128, 48, 256])\n",
      "note_features torch.Size([1, 1, 48, 256])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 19%|█▉        | 12/64 [00:21<01:33,  1.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "ins (1, 128, 48, 3)\n",
      "note_features torch.Size([1, 128, 48, 256])\n",
      "note_features torch.Size([1, 1, 48, 256])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 20%|██        | 13/64 [00:23<01:31,  1.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "ins (1, 128, 48, 3)\n",
      "note_features torch.Size([1, 128, 48, 256])\n",
      "note_features torch.Size([1, 1, 48, 256])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 22%|██▏       | 14/64 [00:24<01:28,  1.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "ins (1, 128, 48, 3)\n",
      "note_features torch.Size([1, 128, 48, 256])\n",
      "note_features torch.Size([1, 1, 48, 256])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 23%|██▎       | 15/64 [00:26<01:25,  1.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "ins (1, 128, 48, 3)\n",
      "note_features torch.Size([1, 128, 48, 256])\n",
      "note_features torch.Size([1, 1, 48, 256])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 25%|██▌       | 16/64 [00:27<01:22,  1.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "ins (1, 128, 48, 3)\n",
      "note_features torch.Size([1, 128, 48, 256])\n",
      "note_features torch.Size([1, 1, 48, 256])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 27%|██▋       | 17/64 [00:28<01:19,  1.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "ins (1, 128, 48, 3)\n",
      "note_features torch.Size([1, 128, 48, 256])\n",
      "note_features torch.Size([1, 1, 48, 256])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 28%|██▊       | 18/64 [00:29<01:16,  1.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "ins (1, 128, 48, 3)\n",
      "note_features torch.Size([1, 128, 48, 256])\n",
      "note_features torch.Size([1, 1, 48, 256])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 30%|██▉       | 19/64 [00:31<01:13,  1.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "ins (1, 128, 48, 3)\n",
      "note_features torch.Size([1, 128, 48, 256])\n",
      "note_features torch.Size([1, 1, 48, 256])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 31%|███▏      | 20/64 [00:32<01:11,  1.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "ins (1, 128, 48, 3)\n",
      "note_features torch.Size([1, 128, 48, 256])\n",
      "note_features torch.Size([1, 1, 48, 256])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 33%|███▎      | 21/64 [00:33<01:08,  1.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "ins (1, 128, 48, 3)\n",
      "note_features torch.Size([1, 128, 48, 256])\n",
      "note_features torch.Size([1, 1, 48, 256])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 34%|███▍      | 22/64 [00:34<01:06,  1.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "ins (1, 128, 48, 3)\n",
      "note_features torch.Size([1, 128, 48, 256])\n",
      "note_features torch.Size([1, 1, 48, 256])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 36%|███▌      | 23/64 [00:36<01:04,  1.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "ins (1, 128, 48, 3)\n",
      "note_features torch.Size([1, 128, 48, 256])\n",
      "note_features torch.Size([1, 1, 48, 256])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 38%|███▊      | 24/64 [00:37<01:02,  1.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "ins (1, 128, 48, 3)\n",
      "note_features torch.Size([1, 128, 48, 256])\n",
      "note_features torch.Size([1, 1, 48, 256])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 39%|███▉      | 25/64 [00:38<01:00,  1.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "ins (1, 128, 48, 3)\n",
      "note_features torch.Size([1, 128, 48, 256])\n",
      "note_features torch.Size([1, 1, 48, 256])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 41%|████      | 26/64 [00:39<00:58,  1.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "ins (1, 128, 48, 3)\n",
      "note_features torch.Size([1, 128, 48, 256])\n",
      "note_features torch.Size([1, 1, 48, 256])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 42%|████▏     | 27/64 [00:41<00:56,  1.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "ins (1, 128, 48, 3)\n",
      "note_features torch.Size([1, 128, 48, 256])\n",
      "note_features torch.Size([1, 1, 48, 256])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 44%|████▍     | 28/64 [00:42<00:54,  1.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "ins (1, 128, 48, 3)\n",
      "note_features torch.Size([1, 128, 48, 256])\n",
      "note_features torch.Size([1, 1, 48, 256])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 45%|████▌     | 29/64 [00:43<00:52,  1.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "ins (1, 128, 48, 3)\n",
      "note_features torch.Size([1, 128, 48, 256])\n",
      "note_features torch.Size([1, 1, 48, 256])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 47%|████▋     | 30/64 [00:45<00:51,  1.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "ins (1, 128, 48, 3)\n",
      "note_features torch.Size([1, 128, 48, 256])\n",
      "note_features torch.Size([1, 1, 48, 256])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 48%|████▊     | 31/64 [00:46<00:49,  1.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "ins (1, 128, 48, 3)\n",
      "note_features torch.Size([1, 128, 48, 256])\n",
      "note_features torch.Size([1, 1, 48, 256])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 50%|█████     | 32/64 [00:48<00:48,  1.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "ins (1, 128, 48, 3)\n",
      "note_features torch.Size([1, 128, 48, 256])\n",
      "note_features torch.Size([1, 1, 48, 256])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 52%|█████▏    | 33/64 [00:50<00:47,  1.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "ins (1, 128, 48, 3)\n",
      "note_features torch.Size([1, 128, 48, 256])\n",
      "note_features torch.Size([1, 1, 48, 256])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 53%|█████▎    | 34/64 [00:51<00:45,  1.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "ins (1, 128, 48, 3)\n",
      "note_features torch.Size([1, 128, 48, 256])\n",
      "note_features torch.Size([1, 1, 48, 256])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 55%|█████▍    | 35/64 [00:53<00:44,  1.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "ins (1, 128, 48, 3)\n",
      "note_features torch.Size([1, 128, 48, 256])\n",
      "note_features torch.Size([1, 1, 48, 256])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 56%|█████▋    | 36/64 [00:54<00:42,  1.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "ins (1, 128, 48, 3)\n",
      "note_features torch.Size([1, 128, 48, 256])\n",
      "note_features torch.Size([1, 1, 48, 256])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 58%|█████▊    | 37/64 [00:56<00:41,  1.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "ins (1, 128, 48, 3)\n",
      "note_features torch.Size([1, 128, 48, 256])\n",
      "note_features torch.Size([1, 1, 48, 256])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 59%|█████▉    | 38/64 [00:57<00:39,  1.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predictions torch.Size([1, 1, 48, 3])\n",
      "ins (1, 128, 48, 3)\n",
      "note_features torch.Size([1, 128, 48, 256])\n",
      "note_features torch.Size([1, 1, 48, 256])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 61%|██████    | 39/64 [00:59<00:38,  1.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "ins (1, 128, 48, 3)\n",
      "note_features torch.Size([1, 128, 48, 256])\n",
      "note_features torch.Size([1, 1, 48, 256])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 62%|██████▎   | 40/64 [01:00<00:36,  1.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "ins (1, 128, 48, 3)\n",
      "note_features torch.Size([1, 128, 48, 256])\n",
      "note_features torch.Size([1, 1, 48, 256])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 64%|██████▍   | 41/64 [01:01<00:34,  1.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "ins (1, 128, 48, 3)\n",
      "note_features torch.Size([1, 128, 48, 256])\n",
      "note_features torch.Size([1, 1, 48, 256])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 66%|██████▌   | 42/64 [01:03<00:33,  1.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "ins (1, 128, 48, 3)\n",
      "note_features torch.Size([1, 128, 48, 256])\n",
      "note_features torch.Size([1, 1, 48, 256])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 67%|██████▋   | 43/64 [01:04<00:31,  1.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "ins (1, 128, 48, 3)\n",
      "note_features torch.Size([1, 128, 48, 256])\n",
      "note_features torch.Size([1, 1, 48, 256])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 69%|██████▉   | 44/64 [01:05<00:29,  1.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "ins (1, 128, 48, 3)\n",
      "note_features torch.Size([1, 128, 48, 256])\n",
      "note_features torch.Size([1, 1, 48, 256])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 70%|███████   | 45/64 [01:07<00:28,  1.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "ins (1, 128, 48, 3)\n",
      "note_features torch.Size([1, 128, 48, 256])\n",
      "note_features torch.Size([1, 1, 48, 256])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 72%|███████▏  | 46/64 [01:08<00:26,  1.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "ins (1, 128, 48, 3)\n",
      "note_features torch.Size([1, 128, 48, 256])\n",
      "note_features torch.Size([1, 1, 48, 256])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 73%|███████▎  | 47/64 [01:09<00:25,  1.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "ins (1, 128, 48, 3)\n",
      "note_features torch.Size([1, 128, 48, 256])\n",
      "note_features torch.Size([1, 1, 48, 256])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 75%|███████▌  | 48/64 [01:10<00:23,  1.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "ins (1, 128, 48, 3)\n",
      "note_features torch.Size([1, 128, 48, 256])\n",
      "note_features torch.Size([1, 1, 48, 256])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 77%|███████▋  | 49/64 [01:12<00:22,  1.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "ins (1, 128, 48, 3)\n",
      "note_features torch.Size([1, 128, 48, 256])\n",
      "note_features torch.Size([1, 1, 48, 256])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 78%|███████▊  | 50/64 [01:13<00:20,  1.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "ins (1, 128, 48, 3)\n",
      "note_features torch.Size([1, 128, 48, 256])\n",
      "note_features torch.Size([1, 1, 48, 256])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 80%|███████▉  | 51/64 [01:15<00:19,  1.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predictions torch.Size([1, 1, 48, 3])\n",
      "ins (1, 128, 48, 3)\n",
      "note_features torch.Size([1, 128, 48, 256])\n",
      "note_features torch.Size([1, 1, 48, 256])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 81%|████████▏ | 52/64 [01:17<00:17,  1.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "ins (1, 128, 48, 3)\n",
      "note_features torch.Size([1, 128, 48, 256])\n",
      "note_features torch.Size([1, 1, 48, 256])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 83%|████████▎ | 53/64 [01:18<00:16,  1.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "ins (1, 128, 48, 3)\n",
      "note_features torch.Size([1, 128, 48, 256])\n",
      "note_features torch.Size([1, 1, 48, 256])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 84%|████████▍ | 54/64 [01:20<00:14,  1.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predictions torch.Size([1, 1, 48, 3])\n",
      "ins (1, 128, 48, 3)\n",
      "note_features torch.Size([1, 128, 48, 256])\n",
      "note_features torch.Size([1, 1, 48, 256])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 86%|████████▌ | 55/64 [01:21<00:13,  1.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "ins (1, 128, 48, 3)\n",
      "note_features torch.Size([1, 128, 48, 256])\n",
      "note_features torch.Size([1, 1, 48, 256])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 88%|████████▊ | 56/64 [01:23<00:11,  1.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "ins (1, 128, 48, 3)\n",
      "note_features torch.Size([1, 128, 48, 256])\n",
      "note_features torch.Size([1, 1, 48, 256])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 89%|████████▉ | 57/64 [01:25<00:10,  1.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "ins (1, 128, 48, 3)\n",
      "note_features torch.Size([1, 128, 48, 256])\n",
      "note_features torch.Size([1, 1, 48, 256])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 91%|█████████ | 58/64 [01:26<00:08,  1.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "ins (1, 128, 48, 3)\n",
      "note_features torch.Size([1, 128, 48, 256])\n",
      "note_features torch.Size([1, 1, 48, 256])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 92%|█████████▏| 59/64 [01:28<00:07,  1.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "ins (1, 128, 48, 3)\n",
      "note_features torch.Size([1, 128, 48, 256])\n",
      "note_features torch.Size([1, 1, 48, 256])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 94%|█████████▍| 60/64 [01:30<00:06,  1.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "ins (1, 128, 48, 3)\n",
      "note_features torch.Size([1, 128, 48, 256])\n",
      "note_features torch.Size([1, 1, 48, 256])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 95%|█████████▌| 61/64 [01:31<00:04,  1.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predictions torch.Size([1, 1, 48, 3])\n",
      "ins (1, 128, 48, 3)\n",
      "note_features torch.Size([1, 128, 48, 256])\n",
      "note_features torch.Size([1, 1, 48, 256])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 97%|█████████▋| 62/64 [01:33<00:03,  1.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "ins (1, 128, 48, 3)\n",
      "note_features torch.Size([1, 128, 48, 256])\n",
      "note_features torch.Size([1, 1, 48, 256])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 98%|█████████▊| 63/64 [01:34<00:01,  1.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "ins (1, 128, 48, 3)\n",
      "note_features torch.Size([1, 128, 48, 256])\n",
      "note_features torch.Size([1, 1, 48, 256])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "100%|██████████| 64/64 [01:36<00:00,  1.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "current_note torch.Size([1, 1, 48, 3])\n",
      "predictions torch.Size([1, 1, 48, 3])\n",
      "Writing file out/samples/output/canonical_test_0.mid\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "write_file('output/canonical_test', generate(the_model, 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Music file out/samples/output/canonical_test_0.mid loaded!\n"
     ]
    }
   ],
   "source": [
    "midi_file = 'out/samples/output/canonical_test_0.mid'\n",
    "play_music(midi_file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
