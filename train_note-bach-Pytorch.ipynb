{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from keras.callbacks import ModelCheckpoint, LambdaCallback\n",
    "from keras.callbacks import EarlyStopping, TensorBoard\n",
    "import argparse\n",
    "import midi\n",
    "import os\n",
    "\n",
    "from constants import *\n",
    "from dataset import load_all\n",
    "from generate import write_file, generate\n",
    "from play_music_util import play_music\n",
    "\n",
    "import pygame\n",
    "import base64\n",
    "\n",
    "from playsound import playsound"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from keras.layers import Input, LSTM, Dense, Dropout, Lambda, Reshape, Permute\n",
    "from keras.layers import TimeDistributed, RepeatVector, Conv1D, Activation\n",
    "from keras.layers import Embedding, Flatten, dot, concatenate \n",
    "from keras.layers.merge import Concatenate, Add, Multiply\n",
    "from keras.models import Model\n",
    "import keras.backend as K\n",
    "from keras import losses\n",
    "from keras.utils import multi_gpu_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['data/test']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "styles[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data\n"
     ]
    }
   ],
   "source": [
    "print('Loading data')\n",
    "train_data, train_labels = load_all(styles, BATCH_SIZE, SEQ_LEN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 128, 48, 3)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10, 128, 48, 3)\n",
      "(10, 128, 48, 3)\n",
      "(10, 128, 16)\n"
     ]
    }
   ],
   "source": [
    "for i in range(3):\n",
    "    print(train_data[i].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_labels[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from model import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch, torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32, 48, 3)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " BATCH_SIZE, NUM_NOTES, NOTE_UNITS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "cuda = False\n",
    "\n",
    "def iterate_minibatches(train_data, train_labels, batchsize):\n",
    "    indices = np.random.permutation(np.arange(len(train_labels)))\n",
    "    for start in range(0, len(indices), batchsize):\n",
    "        ix = indices[start: start + batchsize]\n",
    "        \n",
    "        if cuda:      \n",
    "            yield  Variable(torch.FloatTensor(train_data[ix])).cuda(), Variable(torch.FloatTensor(train_labels[ix])).cuda()\n",
    "        else:\n",
    "            yield Variable(torch.FloatTensor(train_data[ix])), Variable(torch.FloatTensor(train_labels[ix]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Pytorch implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "class time_axis(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(self.__class__, self).__init__() \n",
    "        self.n_layers = 1\n",
    "        self.hidden_size = TIME_AXIS_UNITS\n",
    "        self.input_size = NOTE_UNITS\n",
    "        \n",
    "\n",
    "        self.time_lstm = nn.LSTM(self.input_size, self.hidden_size, self.n_layers, dropout=0.1, \n",
    "                                 batch_first=True, )\n",
    "        self.dropout = nn.Dropout(p=0.2, inplace=True)\n",
    "        \n",
    "    def forward(self, notes):\n",
    "        \n",
    "        \"\"\"\n",
    "        arg:\n",
    "            notes - (batch, time_seq, note_seq, note_features)\n",
    "        \n",
    "        out: \n",
    "            (batch, time_seq, note_seq, hidden_features)\n",
    "            \n",
    "        \"\"\"\n",
    "        \n",
    "        lstm_out = []\n",
    "#         i_hidden = self.init_hidden()\n",
    "        \n",
    "#         print('notes.shape[2] : ', notes.shape[2])\n",
    "        \n",
    "        for i in range(notes.shape[2]):\n",
    "            \n",
    "            out, hidden = self.time_lstm(notes[:, :, i,:]) \n",
    "            \n",
    "#             print('out', out.shape)\n",
    "            \n",
    "            lstm_out.append(out[:, :, None, :])\n",
    "            \n",
    "#             print('out2', out[:, :, None, :].shape)\n",
    "        \n",
    "        \n",
    "        time_output = torch.cat(lstm_out, dim=2)\n",
    "#         self.dropout(time_output)\n",
    "#         print('time_output', time_output.shape)\n",
    "        \n",
    "        return time_output        \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dummy_note = Variable(torch.Tensor(train_data[0]).view(train_data[0].shape[:-2]\n",
    "#                       +(train_data[0].shape[-2]*train_data[0].shape[-1],)))\n",
    "# dummy_note.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_data[0].shape[:-1]+(train_data[0].shape[-2]*train_data[0].shape[-1], )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dummy_note:  torch.Size([10, 128, 48, 3])\n",
      "dummy_time_features : torch.Size([10, 128, 48, 256])\n"
     ]
    }
   ],
   "source": [
    "dummy_note = Variable(torch.Tensor(train_data[0]))\n",
    "print('dummy_note: ', dummy_note.shape)\n",
    "ta = time_axis()\n",
    "\n",
    "# dummy_time_features = ta.forward(dummy_note)\n",
    "dummy_time_features = generator.time_ax(dummy_note)\n",
    "\n",
    "print('dummy_time_features :', dummy_time_features.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 128, 48, 256])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dummy_time_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "class note_axis(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(self.__class__, self).__init__()   \n",
    "        \n",
    "        self.n_layers = 2\n",
    "        self.hidden_size = NOTE_AXIS_UNITS\n",
    "        # number of time features plus number of previous higher note in the same time momemt\n",
    "        self.input_size = TIME_AXIS_UNITS + NOTE_UNITS\n",
    "        \n",
    "        # maybe it is better to make two lstm and make the second one bideractional \n",
    "        self.note_lstm = nn.LSTM(self.input_size, self.hidden_size, self.n_layers, dropout=0.1, \n",
    "                                 batch_first=True, )\n",
    "        \n",
    "        self.dropout = nn.Dropout(p=0.2, inplace=True)\n",
    "        \n",
    "        self.logits = nn.Linear(self.hidden_size, NOTE_UNITS) \n",
    "        \n",
    "    def forward(self, notes, chosen):\n",
    "        \"\"\"\n",
    "        arg:\n",
    "            notes - (batch, time_seq, note_seq, time_hidden_features)\n",
    "        \n",
    "        out: \n",
    "            (batch, time_seq, note_seq, next_notes_features)\n",
    "            \n",
    "        \"\"\"\n",
    "                \n",
    "        # Shift target one note to the left.\n",
    "        shift_chosen = nn.ZeroPad2d((0, 0, 1, 0))(chosen[:, :, :-1, :])\n",
    "#         print('shift_chosen: ', shift_chosen.shape)\n",
    "        \n",
    "#         print('notes: ', notes.shape)\n",
    "              \n",
    "        note_input = torch.cat([notes, shift_chosen], dim=-1)\n",
    "        \n",
    "#         print('notes.shape[2] : ', note_input.shape)\n",
    "        \n",
    "        lstm_out = []\n",
    "        for i in range(notes.shape[1]):\n",
    "            \n",
    "            out, hidden = self.note_lstm(note_input[:, i, :,:]) \n",
    "            \n",
    "#             print('out', out.shape)\n",
    "            \n",
    "            lstm_out.append(out[:, None, :, :])\n",
    "        \n",
    "        \n",
    "        time_output = torch.cat(lstm_out, dim=1)\n",
    "#         self.dropout(time_output)\n",
    "\n",
    "        logits = self.logits(time_output) \n",
    "        next_notes = nn.Sigmoid()(logits)\n",
    "            \n",
    "#         print('logits', logits.shape)\n",
    "        \n",
    "        return next_notes   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dummy_time_features : torch.Size([10, 128, 48, 3])\n"
     ]
    }
   ],
   "source": [
    "chosen = Variable(torch.Tensor(train_data[1]))\n",
    "na = note_axis()\n",
    "\n",
    "next_notes_features = na.forward(dummy_time_features, chosen)\n",
    "\n",
    "print('dummy_time_features :', next_notes_features.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(self.__class__, self).__init__()        \n",
    "        \n",
    "        self.time_ax = time_axis() \n",
    "        self.note_ax = note_axis()\n",
    "        \n",
    "    def forward(self, notes, chosen):\n",
    "        \n",
    "        note_ax_output = self.time_ax(notes)\n",
    "        output = self.note_ax(note_ax_output, chosen)\n",
    "        \n",
    "        return output        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dummy_time_features : torch.Size([10, 128, 48, 3])\n"
     ]
    }
   ],
   "source": [
    "dummy_note = Variable(torch.Tensor(train_data[0]))\n",
    "chosen = Variable(torch.Tensor(train_data[1]))\n",
    "\n",
    "generator = Generator()\n",
    "\n",
    "output = generator.forward(dummy_note, chosen)\n",
    "output2 = the_model.forward(dummy_note, chosen)\n",
    "\n",
    "print('dummy_time_features :', output.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Variable containing:\n",
       " 0.4928  0.5027  0.4898\n",
       " 0.4950  0.5018  0.4917\n",
       " 0.4965  0.5014  0.4923\n",
       " 0.4968  0.5007  0.4928\n",
       " 0.4972  0.5009  0.4931\n",
       " 0.4974  0.5009  0.4931\n",
       " 0.4973  0.5007  0.4928\n",
       " 0.4972  0.5008  0.4934\n",
       " 0.4971  0.5015  0.4931\n",
       " 0.4976  0.5012  0.4931\n",
       " 0.4974  0.5008  0.4934\n",
       " 0.4978  0.5012  0.4934\n",
       " 0.4974  0.5010  0.4932\n",
       " 0.4972  0.5005  0.4939\n",
       " 0.4974  0.5008  0.4934\n",
       " 0.4976  0.5010  0.4927\n",
       " 0.4977  0.5004  0.4932\n",
       " 0.4975  0.5005  0.4932\n",
       " 0.4976  0.5004  0.4934\n",
       " 0.4975  0.5001  0.4936\n",
       " 0.4974  0.5005  0.4936\n",
       " 0.4974  0.5005  0.4936\n",
       " 0.4972  0.5007  0.4934\n",
       " 0.4973  0.5013  0.4930\n",
       " 0.4975  0.5010  0.4917\n",
       " 0.4974  0.5008  0.4926\n",
       " 0.4971  0.5010  0.4931\n",
       " 0.4977  0.5006  0.4933\n",
       " 0.4970  0.5008  0.4935\n",
       " 0.4975  0.5013  0.4932\n",
       " 0.4973  0.5013  0.4935\n",
       " 0.4973  0.5012  0.4932\n",
       " 0.4973  0.5011  0.4934\n",
       " 0.4978  0.5010  0.4932\n",
       " 0.4976  0.5008  0.4934\n",
       " 0.4977  0.5007  0.4927\n",
       " 0.4975  0.5008  0.4929\n",
       " 0.4973  0.5011  0.4930\n",
       " 0.4971  0.5013  0.4927\n",
       " 0.4972  0.5010  0.4931\n",
       " 0.4976  0.5008  0.4931\n",
       " 0.4972  0.5006  0.4932\n",
       " 0.4972  0.5011  0.4923\n",
       " 0.4970  0.5016  0.4930\n",
       " 0.4969  0.5011  0.4936\n",
       " 0.4972  0.5008  0.4936\n",
       " 0.4969  0.5009  0.4938\n",
       " 0.4972  0.5005  0.4936\n",
       "[torch.FloatTensor of size 48x3]"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Variable containing:\n",
       " 0.3952  0.4475  0.5165\n",
       " 0.1897  0.3380  0.5307\n",
       " 0.0645  0.2216  0.5541\n",
       " 0.0294  0.1574  0.5696\n",
       " 0.0199  0.1276  0.5845\n",
       " 0.0182  0.1198  0.5884\n",
       " 0.0164  0.1154  0.5859\n",
       " 0.0161  0.1159  0.5842\n",
       " 0.0156  0.1135  0.5924\n",
       " 0.0157  0.1109  0.5817\n",
       " 0.0157  0.1134  0.5926\n",
       " 0.0165  0.1150  0.5898\n",
       " 0.0158  0.1132  0.5845\n",
       " 0.0155  0.1115  0.5887\n",
       " 0.0153  0.1122  0.5867\n",
       " 0.0159  0.1130  0.5819\n",
       " 0.0162  0.1148  0.5842\n",
       " 0.0153  0.1105  0.5879\n",
       " 0.0152  0.1103  0.5922\n",
       " 0.0154  0.1120  0.5872\n",
       " 0.0157  0.1114  0.5854\n",
       " 0.0152  0.1140  0.5871\n",
       " 0.0155  0.1132  0.5825\n",
       " 0.0156  0.1138  0.5892\n",
       " 0.0160  0.1145  0.5870\n",
       " 0.0157  0.1118  0.5878\n",
       " 0.0162  0.1143  0.5914\n",
       " 0.0162  0.1137  0.5816\n",
       " 0.0153  0.1088  0.5875\n",
       " 0.0152  0.1120  0.5855\n",
       " 0.0155  0.1090  0.5874\n",
       " 0.0158  0.1125  0.5847\n",
       " 0.0150  0.1123  0.5828\n",
       " 0.0153  0.1127  0.5879\n",
       " 0.0152  0.1117  0.5911\n",
       " 0.0154  0.1114  0.5870\n",
       " 0.0150  0.1105  0.5849\n",
       " 0.0157  0.1135  0.5856\n",
       " 0.0156  0.1111  0.5941\n",
       " 0.0156  0.1112  0.5871\n",
       " 0.0149  0.1117  0.5909\n",
       " 0.0154  0.1109  0.5869\n",
       " 0.0156  0.1090  0.5898\n",
       " 0.0159  0.1125  0.5839\n",
       " 0.0160  0.1128  0.5968\n",
       " 0.0154  0.1115  0.5843\n",
       " 0.0153  0.1107  0.5874\n",
       " 0.0155  0.1137  0.5853\n",
       "[torch.FloatTensor of size 48x3]"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output2[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def primary_loss(y_true, y_pred):\n",
    "#     # 3 separate loss calculations based on if note is played or not\n",
    "#     played = y_true[:, :, :, 0]\n",
    "#     bce_note = losses.binary_crossentropy(y_true[:, :, :, 0], y_pred[:, :, :, 0])\n",
    "#     bce_replay = losses.binary_crossentropy(y_true[:, :, :, 1], tf.multiply(played, y_pred[:, :, :, 1]) + tf.multiply(1 - played, y_true[:, :, :, 1]))\n",
    "#     mse = losses.mean_squared_error(y_true[:, :, :, 2], tf.multiply(played, y_pred[:, :, :, 2]) + tf.multiply(1 - played, y_true[:, :, :, 2]))\n",
    "#     return bce_note + bce_replay + mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion_bce_play = nn.BCELoss()  \n",
    "criterion_bce_replay = nn.BCELoss() \n",
    "criterion_mse = nn.MSELoss()  \n",
    "\n",
    "def compute_loss(y_pred, y_true):\n",
    "    \n",
    "    played = y_true[:, :, :, 0]\n",
    "    \n",
    "    bce_note = criterion_bce_play(y_pred[:, :, :, 0], y_true[:, :, :, 0])\n",
    "\n",
    "    replay = played*y_pred[:, :, :, 1] + (1 - played)*y_true[:, :, :, 1]\n",
    "    \n",
    "    bce_replay = criterion_bce_replay(replay, y_true[:, :, :, 1])\n",
    "    \n",
    "    volume = played*y_pred[:, :, :, 2] + (1 - played)*y_true[:, :, :, 2]\n",
    "    mse = criterion_mse(volume, y_true[:, :, :, 2] )\n",
    "    \n",
    "    return bce_note + bce_replay + mse\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Variable containing:\n",
       " 0.7402\n",
       "[torch.FloatTensor of size 1]"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compute_loss(output, chosen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator = Generator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 128, 48, 3)"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_tr = train_data[0][:-1]\n",
    "X_te = train_data[0][-1:]\n",
    "y_tr = train_labels[0][:-1]\n",
    "y_te = train_labels[0][-1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((9, 128, 48, 3), (1, 128, 48, 3))"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_tr.shape, X_te.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_tr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import time\n",
    "from IPython import display\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3 of 3 took 73.395s\n",
      "current train loss: 0.11898569266001384\n",
      "current val loss: 0.20192551612854004\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1841742940>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished!\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "from torch import optim\n",
    "\n",
    "n_epochs = 3\n",
    "batchsize = 3\n",
    "optimizer = optim.Adam(generator.parameters())\n",
    "n_train_batches = math.ceil(len(X_tr)/batchsize)\n",
    "n_validation_batches = math.ceil(len(X_te)/batchsize)\n",
    "\n",
    "epoch_history = {'train_loss':[], 'val_loss':[]}\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    \n",
    "    start_time = time.time()\n",
    "    \n",
    "    train_loss = 0\n",
    "    generator.train(True)    \n",
    "    for X, y in tqdm(iterate_minibatches(X_tr, y_tr, batchsize)):\n",
    "         \n",
    "        optimizer.zero_grad()\n",
    "                     \n",
    "        pred = generator(X, y)\n",
    "        loss = compute_loss(pred, y)        \n",
    "        loss.backward()\n",
    "                     \n",
    "        optimizer.step()\n",
    "        \n",
    "        train_loss += loss.cpu().data.numpy()[0]\n",
    "        \n",
    "    train_loss /= n_train_batches\n",
    "    epoch_history['train_loss'].append(train_loss)\n",
    "#     print('train_loss', train_loss)\n",
    "    \n",
    "    generator.train(False)\n",
    "    val_loss = 0\n",
    "    for X, y in tqdm(iterate_minibatches(X_te, y_te, batchsize)):\n",
    "        pred = generator(X, y)\n",
    "        loss = compute_loss(pred, y) \n",
    "\n",
    "        val_loss += loss.cpu().data.numpy()[0]\n",
    "           \n",
    "    val_loss /= n_validation_batches\n",
    "    epoch_history['val_loss'].append(val_loss)\n",
    "#     print('val_loss', val_loss)\n",
    "    \n",
    "    # Visualize\n",
    "    display.clear_output(wait=True)\n",
    "    plt.figure(figsize=(16, 6))\n",
    "    # Then we print the results for this epoch:\n",
    "    print(\"Epoch {} of {} took {:.3f}s\".format(\n",
    "        epoch + 1, n_epochs, time.time() - start_time)) \n",
    "    print('current train loss: {}'.format(epoch_history['train_loss'][-1]))\n",
    "    print('current val loss: {}'.format(epoch_history['val_loss'][-1]))\n",
    "       \n",
    "    plt.title(\"losses\")\n",
    "    plt.xlabel(\"#epoch\")\n",
    "    plt.ylabel(\"loss\")\n",
    "    plt.plot(epoch_history['train_loss'], 'b', label = 'train_loss')\n",
    "    plt.plot(epoch_history['val_loss'], 'g', label = 'val_loss')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    \n",
    "print(\"Finished!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(time_axis(\n",
       "   (time_lstm): LSTM(3, 256, batch_first=True, dropout=0.1)\n",
       "   (dropout): Dropout(p=0.2, inplace)\n",
       " ), note_axis(\n",
       "   (note_lstm): LSTM(259, 128, num_layers=2, batch_first=True, dropout=0.1)\n",
       "   (dropout): Dropout(p=0.2, inplace)\n",
       "   (logits): Linear(in_features=128, out_features=3)\n",
       " ))"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generator.time_ax, generator.note_ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Generator(\n",
       "  (time_ax): time_axis(\n",
       "    (time_lstm): LSTM(3, 256, batch_first=True, dropout=0.1)\n",
       "    (dropout): Dropout(p=0.2, inplace)\n",
       "  )\n",
       "  (note_ax): note_axis(\n",
       "    (note_lstm): LSTM(259, 128, num_layers=2, batch_first=True, dropout=0.1)\n",
       "    (dropout): Dropout(p=0.2, inplace)\n",
       "    (logits): Linear(in_features=128, out_features=3)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generator.train(False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(generator.state_dict(), os.path.join(OUT_DIR, 'model_canonical'))\n",
    "the_model = Generator()\n",
    "the_model.load_state_dict(torch.load(os.path.join(OUT_DIR, 'model_canonical')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:An unexpected error occurred while tokenizing input\n",
      "The following traceback may be corrupted or invalid\n",
      "The error message is: ('EOF in multi-line string', (1, 4))\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating with no styles:\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'Generator' object is not iterable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-152-a078aad3febf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mwrite_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'output/canonical_test'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgenerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mthe_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Documents/project_dnn2018/generate.py\u001b[0m in \u001b[0;36mwrite_file\u001b[0;34m(name, results)\u001b[0m\n\u001b[1;32m    130\u001b[0m     \"\"\"\n\u001b[1;32m    131\u001b[0m     \u001b[0mTakes\u001b[0m \u001b[0ma\u001b[0m \u001b[0mlist\u001b[0m \u001b[0mof\u001b[0m \u001b[0mall\u001b[0m \u001b[0mnotes\u001b[0m \u001b[0mgenerated\u001b[0m \u001b[0mper\u001b[0m \u001b[0mtrack\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mwrites\u001b[0m \u001b[0mit\u001b[0m \u001b[0mto\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 132\u001b[0;31m     \"\"\"\n\u001b[0m\u001b[1;32m    133\u001b[0m     \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    134\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/project_dnn2018/generate.py\u001b[0m in \u001b[0;36mgenerate\u001b[0;34m(models, num_bars, Attention)\u001b[0m\n\u001b[1;32m     96\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Generating with no styles:'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 98\u001b[0;31m \u001b[0;31m#     models.train(False)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     99\u001b[0m     \u001b[0mtime_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnote_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime_ax\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnote_ax\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m     \u001b[0mgenerations\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mMusicGeneration\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'Generator' object is not iterable"
     ]
    }
   ],
   "source": [
    "write_file('output/canonical_test', generate(the_model, 4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Canonical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "MASK = False\n",
    "self_attention = False\n",
    "attention_in_note = False\n",
    "models = build_models()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training\n",
      "Train on 9 samples, validate on 1 samples\n",
      "Epoch 1/2\n",
      "9/9 [==============================] - 15s 2s/step - loss: 1.1476 - val_loss: 1.8936\n",
      "Epoch 2/2\n",
      "9/9 [==============================] - 11s 1s/step - loss: 0.9959 - val_loss: 1.8699\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1c4b257630>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cbs = [\n",
    "    ModelCheckpoint(os.path.join(OUT_DIR, 'model_canonical.h5'), monitor='loss', save_best_only=True, save_weights_only=True),\n",
    "    EarlyStopping(monitor='loss', patience=5),\n",
    "    #TensorBoard(log_dir='out/logs', histogram_freq=1)\n",
    "]\n",
    "\n",
    "print('Training')\n",
    "models[0].fit(train_data, train_labels, validation_split=0.05,\n",
    "              epochs=2, callbacks=cbs, batch_size=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/64 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating with no styles:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 64/64 [00:55<00:00,  1.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing file out/samples/output/canonical_test_0.mid\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "models = build_models()\n",
    "models[0].load_weights(os.path.join(OUT_DIR, 'model_canonical.h5'))\n",
    "write_file('output/canonical_test', generate(models, 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Music file out/samples/output/canonical_test_0.mid loaded!\n"
     ]
    }
   ],
   "source": [
    "midi_file = 'out/samples/output/canonical_test_0.mid'\n",
    "play_music(midi_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing keras function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "fpath = os.path.join(SAMPLES_DIR, 'encode_decoded_song' + '_' + str(i) + '.mid')\n",
    "pattern = midi.read_midifile('data/Bach1/Toccata & Fuga in F-Dur, BWV 540.mid')\n",
    "result = midi_decode(pattern)\n",
    "mf = midi_encode(unclamp_midi(clamp_midi(result)))\n",
    "midi.write_midifile(fpath, mf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[[1. 1. 1. 1.]\n",
      "   [1. 1. 1. 1.]]\n",
      "\n",
      "  [[1. 0. 0. 0.]\n",
      "   [0. 1. 0. 0.]]]]\n",
      "A (1, 2, 2, 4)\n",
      "time_steps 2\n",
      "A [[[1. 1. 1. 1.]\n",
      "  [1. 0. 0. 0.]]]\n",
      "x0 (1, 2, 1, 4)\n",
      "x0 [[[[1. 1. 0. 0.]]\n",
      "\n",
      "  [[1. 0. 0. 0.]]]]\n",
      "x1 (1, 2, 1, 4)\n",
      "x1  [[[[1. 1. 1. 1.]]\n",
      "\n",
      "  [[0. 1. 0. 0.]]]]\n",
      "x (1, 2, 2, 4)\n",
      "x  [[[[1. 1. 0. 0.]\n",
      "   [1. 1. 1. 1.]]\n",
      "\n",
      "  [[1. 0. 0. 0.]\n",
      "   [0. 1. 0. 0.]]]]\n"
     ]
    }
   ],
   "source": [
    "A = np.array([[np.ones((2,4)), np.eye(4)[:2]]])\n",
    "A = K.variable(A)\n",
    "print(K.eval(A))\n",
    "print('A', A.shape)\n",
    "# x = Dense(4, kernel_initializer='Ones')(A)\\\n",
    "#print('slice x', K.eval(A[:, :, :-1, :]))\n",
    "\n",
    "time_steps = int(A.get_shape()[2])\n",
    "note_dim = int(A.get_shape()[1])\n",
    "\n",
    "print('time_steps', time_steps)\n",
    "print('A', K.eval(A[:, :, 0, :]))\n",
    "\n",
    "time_mask = []\n",
    "for i in range(time_steps):\n",
    "    time_mask.append(Lambda(lambda x: tf.pad(x[:, :, i:i+1, 0:(i+1)*note_dim], \n",
    "        [[0, 0], [0, 0],[0, 0],  [0, note_dim*time_steps-(i+1)*note_dim]]))(A))\n",
    "# x = Lambda(lambda x: tf.pad(x[:, :, :-1, :], \n",
    "#                         [[0, 0], [0, 0], [1, 0], [0, 0]]))(A)\n",
    "\n",
    "\n",
    "print('x0', time_mask[0].shape)\n",
    "print('x0', K.eval(time_mask[0]))\n",
    "\n",
    "print('x1', time_mask[1].shape)\n",
    "print('x1 ', K.eval(time_mask[1]))\n",
    "\n",
    "x = Concatenate(axis=2)(time_mask)\n",
    "\n",
    "print('x', x.shape)\n",
    "print('x ', K.eval(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# models[0].save_weights(os.path.join(OUT_DIR, 'raw_model.h5'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# models = build_models()\n",
    "# models[0].load_weights(MODEL_FILE)\n",
    "# write_file('output2', generate(models, 4, styles))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# import tensorflow as tf\n",
    "# from keras.layers import Input, LSTM, Dense, Dropout, Lambda, Reshape, Permute\n",
    "# from keras.layers import TimeDistributed, RepeatVector, Conv1D, Activation\n",
    "# from keras.layers import Embedding, Flatten, dot, concatenate \n",
    "# from keras.layers.merge import Concatenate, Add, Multiply\n",
    "# from keras.models import Model\n",
    "# import keras.backend as K\n",
    "# from keras import losses\n",
    "\n",
    "# from util import *\n",
    "# from constants import *\n",
    "\n",
    "# from keras.utils import multi_gpu_model\n",
    "\n",
    "# def primary_loss(y_true, y_pred):\n",
    "#     # 3 separate loss calculations based on if note is played or not\n",
    "#     played = y_true[:, :, :, 0]\n",
    "#     harmony = K.sum(K.reshape(played,(-1,128,12,4)), axis = -1)\n",
    "#     bce_note = losses.binary_crossentropy(y_true[:, :, :, 0], y_pred[:, :, :, 0])\n",
    "#     bce_replay = losses.binary_crossentropy(y_true[:, :, :, 1], tf.multiply(played, y_pred[:, :, :, 1]) + tf.multiply(1 - played, y_true[:, :, :, 1]))\n",
    "#     mse = losses.mean_squared_error(y_true[:, :, :, 2], tf.multiply(played, y_pred[:, :, :, 2]) + tf.multiply(1 - played, y_true[:, :, :, 2]))\n",
    "#     return bce_note + bce_replay + mse\n",
    "\n",
    "# def pitch_pos_in_f(time_steps):\n",
    "#     \"\"\"\n",
    "#     Returns a constant containing pitch position of each note\n",
    "#     \"\"\"\n",
    "#     def f(x):\n",
    "#         note_ranges = tf.range(NUM_NOTES, dtype='float32') / NUM_NOTES\n",
    "#         repeated_ranges = tf.tile(note_ranges, [tf.shape(x)[0] * time_steps])\n",
    "#         return tf.reshape(repeated_ranges, [tf.shape(x)[0], time_steps, NUM_NOTES, 1])\n",
    "#     return f\n",
    "\n",
    "# def pitch_class_in_f(time_steps):\n",
    "#     \"\"\"\n",
    "#     Returns a constant containing pitch class of each note\n",
    "#     \"\"\"\n",
    "#     def f(x):\n",
    "#         pitch_class_matrix = np.array([one_hot(n % OCTAVE, OCTAVE) for n in range(NUM_NOTES)])\n",
    "#         pitch_class_matrix = tf.constant(pitch_class_matrix, dtype='float32')\n",
    "#         pitch_class_matrix = tf.reshape(pitch_class_matrix, [1, 1, NUM_NOTES, OCTAVE])\n",
    "#         return tf.tile(pitch_class_matrix, [tf.shape(x)[0], time_steps, 1, 1])\n",
    "#     return f\n",
    "\n",
    "# def pitch_bins_f(time_steps):\n",
    "#     def f(x):\n",
    "#         bins = tf.reduce_sum([x[:, :, i::OCTAVE, 0] for i in range(OCTAVE)], axis=3)\n",
    "#         bins = tf.tile(bins, [NUM_OCTAVES, 1, 1])\n",
    "#         bins = tf.reshape(bins, [tf.shape(x)[0], time_steps, NUM_NOTES, 1])\n",
    "#         return bins\n",
    "#     return f\n",
    "\n",
    "# def time_axis(dropout):\n",
    "#     def f(notes, beat):\n",
    "#         time_steps = int(notes.get_shape()[1])\n",
    "\n",
    "#         # TODO: Experiment with when to apply conv\n",
    "#         note_octave = TimeDistributed(Conv1D(OCTAVE_UNITS, 2 * OCTAVE, padding='same'))(notes)\n",
    "#         note_octave = Activation('tanh')(note_octave)\n",
    "#         note_octave = Dropout(dropout)(note_octave)\n",
    "\n",
    "#         # Create features for every single note.\n",
    "#         note_features = Concatenate()([\n",
    "#             Lambda(pitch_pos_in_f(time_steps))(notes),\n",
    "#             Lambda(pitch_class_in_f(time_steps))(notes),\n",
    "#             Lambda(pitch_bins_f(time_steps))(notes),\n",
    "#             note_octave,\n",
    "#             TimeDistributed(RepeatVector(NUM_NOTES))(beat)\n",
    "#         ])\n",
    "\n",
    "#         x = note_features\n",
    "#         # [batch, notes, time, features]\n",
    "#         x = Permute((2, 1, 3))(x)\n",
    "\n",
    "#         # Apply LSTMs\n",
    "#         for l in range(TIME_AXIS_LAYERS):\n",
    "\n",
    "#             x = TimeDistributed(LSTM(TIME_AXIS_UNITS, return_sequences=True))(x)\n",
    "#             x = Dropout(dropout)(x)\n",
    "\n",
    "#         # [batch, time, notes, features]\n",
    "#         return Permute((2, 1, 3))(x)\n",
    "#     return f\n",
    "\n",
    "# def note_axis(dropout):\n",
    "#     lstm_layer_cache = {}\n",
    "#     note_dense = Dense(2, activation='sigmoid', name='note_dense')\n",
    "#     volume_dense = Dense(1, name='volume_dense')\n",
    "\n",
    "#     def f(x, chosen):\n",
    "#         time_steps = int(x.get_shape()[1])\n",
    "\n",
    "#         # Shift target one note to the left.\n",
    "#         shift_chosen = Lambda(lambda x: tf.pad(x[:, :, :-1, :], [[0, 0], [0, 0], [1, 0], [0, 0]]))(chosen)\n",
    "\n",
    "#         # [batch, time, notes, features + 1]\n",
    "#         x = Concatenate(axis=3)([x, shift_chosen])\n",
    "\n",
    "\n",
    "#         for l in range(NOTE_AXIS_LAYERS):\n",
    "#             if l not in lstm_layer_cache:\n",
    "#                 lstm_layer_cache[l] = LSTM(NOTE_AXIS_UNITS, return_sequences=True)\n",
    "\n",
    "#             x = TimeDistributed(lstm_layer_cache[l])(x)\n",
    "#             x = Dropout(dropout)(x)\n",
    "            \n",
    "#         #print('x', x.shape)  \n",
    "#         #print('nx', note_dense(x).shape)\n",
    "        \n",
    "#         return Concatenate()([note_dense(x), volume_dense(x)])\n",
    "#     return f\n",
    "\n",
    "# def build_models(time_steps=SEQ_LEN, input_dropout=0.2, dropout=0.5):\n",
    "#     notes_in = Input((time_steps, NUM_NOTES, NOTE_UNITS))\n",
    "#     beat_in = Input((time_steps, NOTES_PER_BAR))\n",
    "#     # Target input for conditioning\n",
    "#     chosen_in = Input((time_steps, NUM_NOTES, NOTE_UNITS))\n",
    "\n",
    "#     # Dropout inputs\n",
    "#     notes = Dropout(input_dropout)(notes_in)\n",
    "#     beat = Dropout(input_dropout)(beat_in)\n",
    "#     chosen = Dropout(input_dropout)(chosen_in)\n",
    "\n",
    "#     \"\"\" Time axis \"\"\"\n",
    "#     time_out = time_axis(dropout)(notes, beat)\n",
    "\n",
    "#     \"\"\" Note Axis & Prediction Layer \"\"\"\n",
    "#     naxis = note_axis(dropout)\n",
    "#     notes_out = naxis(time_out, chosen)\n",
    "\n",
    "#     model = Model([notes_in, chosen_in, beat_in], [notes_out])\n",
    "\n",
    "#     if len(K.tensorflow_backend._get_available_gpus())>=2:\n",
    "#         model = multi_gpu_model(model)\n",
    "\n",
    "#     model.compile(optimizer='nadam', loss=[primary_loss])\n",
    "\n",
    "#     \"\"\" Generation Models \"\"\"\n",
    "#     time_model = Model([notes_in, beat_in], [time_out])\n",
    "\n",
    "#     note_features = Input((1, NUM_NOTES, TIME_AXIS_UNITS), name='note_features')\n",
    "#     chosen_gen_in = Input((1, NUM_NOTES, NOTE_UNITS), name='chosen_gen_in')\n",
    "#     style_gen_in = Input((1, NUM_STYLES), name='style_in')\n",
    "\n",
    "#     # Dropout inputs\n",
    "#     chosen_gen = Dropout(input_dropout)(chosen_gen_in)\n",
    "    \n",
    "#     note_gen_out = naxis(note_features, chosen_gen)\n",
    "    \n",
    "#     note_model = Model([note_features, chosen_gen_in], note_gen_out)\n",
    "\n",
    "#     return model, time_model, note_model\n",
    "\n",
    "\n",
    "# def build_models_with_attention(time_steps=SEQ_LEN, input_dropout=0.2, dropout=0.5):\n",
    "#     notes_in = Input((time_steps, NUM_NOTES, NOTE_UNITS))\n",
    "#     beat_in = Input((time_steps, NOTES_PER_BAR))\n",
    "#     # Target input for conditioning\n",
    "#     chosen_in = Input((time_steps, NUM_NOTES, NOTE_UNITS))\n",
    "\n",
    "#     # Dropout inputs\n",
    "#     notes = Dropout(input_dropout)(notes_in)\n",
    "#     beat = Dropout(input_dropout)(beat_in)\n",
    "#     chosen = Dropout(input_dropout)(chosen_in)\n",
    "\n",
    "#     \"\"\" Time axis \"\"\"\n",
    "#     time_out = time_axis(dropout)(notes, beat)\n",
    "#     #print('time_out', time_out.shape)\n",
    "\n",
    "#     \"\"\" Note Axis & Prediction Layer \"\"\"\n",
    "#     naxis = note_axis_attention(dropout)\n",
    "#     notes_out = naxis(time_out)\n",
    "    \n",
    "#     model = Model([notes_in, chosen_in, beat_in], [notes_out])\n",
    "\n",
    "#     if len(K.tensorflow_backend._get_available_gpus())>=2:\n",
    "#         model = multi_gpu_model(model)\n",
    "\n",
    "#     model.compile(optimizer='nadam', loss=[primary_loss])\n",
    "    \n",
    "#     \"\"\" Generation Models \"\"\"\n",
    "#     time_model = Model([notes_in, beat_in], [time_out])\n",
    "\n",
    "#     note_features = Input((1, NUM_NOTES, TIME_AXIS_UNITS), name='note_features')\n",
    "#     chosen_gen_in = Input((1, NUM_NOTES, NOTE_UNITS), name='chosen_gen_in')\n",
    "   \n",
    "#     # Dropout inputs\n",
    "#     chosen_gen = Dropout(input_dropout)(chosen_gen_in)\n",
    "    \n",
    "#     #print('NUM_NOTES', NUM_NOTES)\n",
    "#     note_gen_out = naxis(note_features)\n",
    "    \n",
    "#     note_model = Model([note_features, chosen_gen_in], note_gen_out)\n",
    "\n",
    "#     return model, time_model, note_model\n",
    "\n",
    "# def note_axis_attention(dropout):\n",
    "#     note_dense_att = Dense(2, activation='sigmoid', name='note_dense_att')\n",
    "#     volume_dense_att = Dense(1, name='volume_dense_att')\n",
    "\n",
    "#     def f(x):\n",
    "#         x = attention_layer(x, x, True)\n",
    "#         #print('x_att', x.shape)\n",
    "#         x = Dropout(dropout)(x)\n",
    "#         #print('x_drop', x.get_shape)\n",
    "\n",
    "#         v = volume_dense_att(x)\n",
    "        \n",
    "#         #print('the end')\n",
    "#         #print('dense_vol', v.shape)\n",
    "  \n",
    "#         return Concatenate(axis=-1)([note_dense_att(x), volume_dense_att(x)])\n",
    "    \n",
    "#     return f\n",
    "\n",
    "# def OneHeadAttention(a_drop, q_drop, drop_ratio=0.5):\n",
    "        \n",
    "#     a_proj = Dense(PROJECTION_DIM, use_bias=False, kernel_initializer='glorot_normal')(a_drop)\n",
    "#     q_proj = Dense(PROJECTION_DIM, use_bias=False, kernel_initializer='glorot_normal')(q_drop)\n",
    "#     v_proj = Dense(PROJECTION_DIM, use_bias=False, kernel_initializer='glorot_normal')(a_drop)\n",
    "    \n",
    "#     a_proj = Dropout(drop_ratio)(a_proj)\n",
    "#     q_proj = Dropout(drop_ratio)(q_proj)\n",
    "#     v_proj = Dropout(drop_ratio)(v_proj)\n",
    "#     #print('a_proj', a_proj.shape)\n",
    "    \n",
    "#     #n = Dense(2)(v_proj)\n",
    "#     #print('dense_note', n.shape)\n",
    " \n",
    "    \n",
    "#     att_input = Lambda(lambda x: tf.matmul(x[0],x[1], transpose_b=True))([q_proj, a_proj])\n",
    "#     #print('att_input', att_input.shape)\n",
    "\n",
    "\n",
    "#     att_weights = Activation('softmax')(att_input)\n",
    "#     v_new = Lambda(lambda x: tf.matmul(x[0],x[1]))([att_weights, v_proj])\n",
    "#     #tf.matmul(att_weights, v_proj)\n",
    "#     #print('v_new', v_new.get_shape)\n",
    "     \n",
    "#     v_new = Multiply()([q_proj, v_new])\n",
    "    \n",
    "#     return v_new\n",
    "\n",
    "# def MultyHeadAttention(a_drop, q_drop):\n",
    "\n",
    "#     Attention_heads = []\n",
    "#     for i in range(N_HEADS):\n",
    "#         Attention_heads.append(OneHeadAttention(a_drop, q_drop))\n",
    "        \n",
    "#     BigHead = concatenate(Attention_heads, axis=-1)\n",
    "#     #print('BigHead', BigHead.shape)   \n",
    "\n",
    "#     attention_output = Dense(DENSE_SIZE, use_bias=False)(BigHead)\n",
    "#     #print('attention_output', attention_output.shape)\n",
    "\n",
    "           \n",
    "#     return attention_output\n",
    "    \n",
    "# def attention_layer(a_drop, q_drop, FF):\n",
    "    \n",
    "#     #print('a_drop', a_drop.shape)\n",
    "#     res = MultyHeadAttention(a_drop, q_drop)\n",
    "#     #print('res', res.shape)\n",
    "        \n",
    "#     att = Add()([a_drop, res])\n",
    "#     #att = normalize()(att)    \n",
    " \n",
    "#     #Feed Forward\n",
    "#     if FF:\n",
    "#         att_ff = Dense(DENSE_SIZE*4, activation = 'relu')(att)\n",
    "#         att_ff = Dense(DENSE_SIZE)(att_ff)   \n",
    "#         att_ff = Dropout(0.1)(att_ff)\n",
    "#         att_add = Add()([att, att_ff])\n",
    "#         #att = normalize()(att_add) \n",
    "    \n",
    "#     return att\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compute_beat(3, 16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "128"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SEQ_LEN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = deque([np.zeros((2, 3)) for _ in range(2)], maxlen=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "deque([array([[0., 0., 0.],\n",
       "              [0., 0., 0.]]), array([[0., 0., 0.],\n",
       "              [0., 0., 0.]])])"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "d.append(np.ones((2,3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "deque([array([[1., 1., 1.],\n",
       "              [1., 1., 1.]]), array([[1., 1., 1.],\n",
       "              [1., 1., 1.]])])"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NOTES_PER_BAR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# for i, result in enumerate(generate(models, 4, styles)):\n",
    "# #     print(i)\n",
    "# #     print(np.array(result).shape)\n",
    "# #     print(unclamp_midi(result).shape)\n",
    "# #     print(midi_encode(unclamp_midi(result)))\n",
    "#     break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = MusicGeneration(styles[0])\n",
    "a = g.build_time_inputs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tuple"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(128, 48, 3)\n",
      "(128, 16)\n",
      "(128, 1)\n"
     ]
    }
   ],
   "source": [
    "for i in a:\n",
    "    print(i.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(a[0]==0).any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(a[1]==0).any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 128, 48, 3)\n",
      "(1, 128, 16)\n",
      "(1, 128, 1)\n"
     ]
    }
   ],
   "source": [
    "for i in process_inputs([a]):\n",
    "    print(i.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 1, 48, 256)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models[1].predict(process_inputs([a]))[:, -1:, :].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 48, 256)"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "note_features = models[1].predict(process_inputs([a]))[:, -1:, :]\n",
    "note_features[0, : ,: , :].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 48, 256)\n",
      "(1, 48, 3)\n",
      "(1, 1)\n"
     ]
    }
   ],
   "source": [
    "b = g.build_note_inputs(note_features[0, : ,: , :])\n",
    "for i in b:\n",
    "    print(i.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 1, 48, 256)\n",
      "(1, 1, 48, 3)\n",
      "(1, 1, 1)\n"
     ]
    }
   ],
   "source": [
    "for i in process_inputs([b]):\n",
    "    print(i.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 1, 48, 3)"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pr = np.array(models[2].predict(process_inputs([b])))\n",
    "pr.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "pr2 = pr[0][-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.0836291"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pr2[2, -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "prob = apply_temperature(pr2[2, :-1], g.temperature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.49578953, 0.4675863 ], dtype=float32)"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "g.choose(pr[0][-1], 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
