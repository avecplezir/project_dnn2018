{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import torch,torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "import numpy as np\n",
    "from model import Generator, iterate_minibatches, compute_loss, train\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "OCTAVE_NUM = 4\n",
    "NOTE_NUM = 12\n",
    "TIME_SCALE = 128\n",
    "\n",
    "\n",
    "class LSTM_discriminator(nn.Module):\n",
    "    def __init__(self,hidden_size = 1000,last_dim = 3):\n",
    "        super(self.__class__, self).__init__()\n",
    "        self.last_dim = last_dim\n",
    "        self.hidden_size = hidden_size\n",
    "        self.note_lstm = nn.LSTM(input_size = OCTAVE_NUM*last_dim,hidden_size = hidden_size)\n",
    "        self.time_lstm = nn.LSTM(input_size = hidden_size,hidden_size = hidden_size)\n",
    "        self.dense = nn.Linear(hidden_size,1)\n",
    "\n",
    "    def forward(self,data):\n",
    "        # data.size() =  (batch_size, TIME_SCALE, NOTE_NUM*OCTAVE_NUM, last_dim)\n",
    "        # octave_data.size() =  (batch_size, TIME_SCALE, NOTE_NUM,OCTAVE_NUM*last_dim)\n",
    "        batch_size,_,_,_ = data.size()\n",
    "        octave_data = data.view(batch_size,TIME_SCALE,NOTE_NUM,OCTAVE_NUM,self.last_dim)\\\n",
    "                          .view(batch_size,TIME_SCALE,NOTE_NUM,OCTAVE_NUM*self.last_dim)\n",
    "            \n",
    "        # note_lstm_input.size() = (NOTE_NUM, batch_size*TIME_SCALE,OCTAVE_NUM*last_dim)\n",
    "        note_lstm_input = octave_data.view(batch_size*TIME_SCALE,NOTE_NUM,OCTAVE_NUM*self.last_dim)\\\n",
    "                                     .transpose(0,1)\n",
    "        # note_lstm_output.size() = (NOTE_NUM,batch_size*TIME_SCALE,hidden_size)\n",
    "        note_lstm_output, _ = self.note_lstm(note_lstm_input)\n",
    "        # time_lstm_input.size() = (TIME_SCALE,batch_size,hidden_size)\n",
    "        time_lstm_input = note_lstm_output[-1].view(batch_size,TIME_SCALE,self.hidden_size)\\\n",
    "                                          .transpose(0,1)\\\n",
    "        # time_lstm_output.size() = (TIME_SCALE,batch_size,1000)\n",
    "        time_lstm_output, _  = self.time_lstm(time_lstm_input)\n",
    "        # dense_input.size() = (batch_size,1000)\n",
    "        dense_input = time_lstm_output[-1]\n",
    "        # dense_output.size() = (batch_size,1)\n",
    "        dense_output = self.dense(dense_input)\n",
    "        probs = F.sigmoid(dense_output)\n",
    "        return probs\n",
    "        \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# device = torch.device(\"cuda:4\" if torch.cuda.is_available() else \"cpu\")\n",
    "# # device = torch.device(\"cpu\")\n",
    "# discriminator = LSTM_discriminator(hidden_size=10).to(device)\n",
    "# np_data = np.random.randn(10,TIME_SCALE,NOTE_NUM*OCTAVE_NUM,3)\n",
    "# data = torch.FloatTensor(np_data).to(device)\n",
    "# discriminator(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTM_baseline(nn.Module):\n",
    "    def __init__(self,hidden_size = 1000):\n",
    "        super(self.__class__, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.note_lstm = nn.LSTM(input_size = OCTAVE_NUM*3,hidden_size = hidden_size)\n",
    "        self.time_lstm = nn.LSTM(input_size = hidden_size,hidden_size = hidden_size)\n",
    "        self.dense = nn.Linear(hidden_size,1)\n",
    "\n",
    "    def forward(self,data,_):\n",
    "        # data.size() =  (batch_size, TIME_SCALE, NOTE_NUM*OCTAVE_NUM, 3)\n",
    "        # octave_data.size() =  (batch_size, TIME_SCALE, NOTE_NUM,OCTAVE_NUM*3)\n",
    "        batch_size,_,_,_ = data.size()\n",
    "        octave_data = data.view(batch_size,TIME_SCALE,NOTE_NUM,OCTAVE_NUM,3)\\\n",
    "                          .view(batch_size,TIME_SCALE,NOTE_NUM,OCTAVE_NUM*3)\n",
    "            \n",
    "        # note_lstm_input.size() = (NOTE_NUM, batch_size*TIME_SCALE,OCTAVE_NUM*3)\n",
    "        note_lstm_input = octave_data.view(batch_size*TIME_SCALE,NOTE_NUM,OCTAVE_NUM*3)\\\n",
    "                                     .transpose(0,1)\n",
    "        # note_lstm_output.size() = (NOTE_NUM,batch_size*TIME_SCALE,hidden_size)\n",
    "        note_lstm_output, _ = self.note_lstm(note_lstm_input)\n",
    "        # time_lstm_input.size() = (TIME_SCALE,batch_size,hidden_size)\n",
    "        time_lstm_input = note_lstm_output[-1].view(batch_size,TIME_SCALE,self.hidden_size)\\\n",
    "                                          .transpose(0,1)\\\n",
    "        # time_lstm_output.size() = (TIME_SCALE,batch_size,1000)\n",
    "        time_lstm_output, _  = self.time_lstm(time_lstm_input)\n",
    "        # dense_input.size() = (batch_size,1000)\n",
    "        dense_input = time_lstm_output[-1]\n",
    "        # dense_output.size() = (batch_size,1)\n",
    "        dense_output = self.dense(dense_input)\n",
    "        probs = F.sigmoid(dense_output)\n",
    "        return probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# discriminator = LSTM_baseline(hidden_size=1000).to(device)\n",
    "# np_data = np.random.randn(10,TIME_SCALE,NOTE_NUM*OCTAVE_NUM,3)\n",
    "# data = torch.FloatTensor(np_data).to(device)\n",
    "# discriminator(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BasicGenerator(nn.Module):\n",
    "    def __init__(self,hidden_size = 1000):\n",
    "        super(self.__class__, self).__init__()\n",
    "        self.dense_in = nn.Linear(TIME_SCALE*NOTE_NUM*OCTAVE_NUM*3,hidden_size)\n",
    "        self.dense_out = nn.Linear(hidden_size,TIME_SCALE*NOTE_NUM*OCTAVE_NUM*3)\n",
    "\n",
    "    def forward(self,data,_):\n",
    "        batch_size,_,_,_ = data.size()\n",
    "        data = data.view(batch_size,-1)\n",
    "        hid_data = self.dense_in(data)\n",
    "        out_data = self.dense_out(hid_data)\n",
    "        output = F.sigmoid(out_data.view(batch_size, TIME_SCALE, NOTE_NUM*OCTAVE_NUM, 3))\n",
    "        return output\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BasicDiscriminator(nn.Module):\n",
    "    def __init__(self,hidden_size = 1000, last_dim = 3):\n",
    "        super(self.__class__, self).__init__()\n",
    "        self.dense_in = nn.Linear(TIME_SCALE*NOTE_NUM*OCTAVE_NUM*last_dim,hidden_size)\n",
    "        self.dense_out = nn.Linear(hidden_size,1)\n",
    "\n",
    "    def forward(self,data):\n",
    "        batch_size,_,_,_ = data.size()\n",
    "        data = data.view(batch_size,-1)\n",
    "        hid_data = self.dense_in(data)\n",
    "        out_data = self.dense_out(hid_data)\n",
    "        output = F.sigmoid(out_data)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion_bce_play = nn.BCELoss()  \n",
    "criterion_bce_replay = nn.BCELoss() \n",
    "criterion_mse = nn.MSELoss()  \n",
    "\n",
    "def compute_loss(y_pred, y_true):\n",
    "    \n",
    "    played = y_true[:, :, :, 0]\n",
    "    \n",
    "    bce_note = criterion_bce_play(y_pred[:, :, :, 0], y_true[:, :, :, 0])\n",
    "\n",
    "    replay = played*y_pred[:, :, :, 1] + (1 - played)*y_true[:, :, :, 1]\n",
    "    \n",
    "    bce_replay = criterion_bce_replay(replay, y_true[:, :, :, 1])\n",
    "    \n",
    "    #volume = played*y_pred[:, :, :, 2] + (1 - played)*y_true[:, :, :, 2]\n",
    "    #mse = criterion_mse(volume, y_true[:, :, :, 2] )\n",
    "    \n",
    "    return bce_note + bce_replay# + mse\n",
    "\n",
    "def g_loss(p_fake,sound,in_probs,baseline_pred,y_true,eps = 1e-8):\n",
    "\n",
    "    gen_confidence = sound[:,:,:,:2]*in_probs[:,:,:,:2]\\\n",
    "            +(1-sound[:,:,:,:2])*(1-in_probs[:,:,:,:2])\n",
    "\n",
    "    print('p_fake: ',p_fake.mean().cpu().data.numpy(),'probs: ',gen_confidence.mean().cpu().data.numpy())\n",
    "    return -((gen_confidence+eps).log().sum(dim =-1).sum(dim =-1).sum(dim =-1)*(p_fake-baseline_pred)).mean()\n",
    "def d_loss(p_fake, p_true,eps = 1e-8):\n",
    "\n",
    "    return -(1-p_fake+eps).log().mean()-(p_true+eps).log().mean()\n",
    "    \n",
    "def bl_loss(bl_pred,real_reward):\n",
    "    return (bl_pred-real_reward).pow(2).mean()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.utils.data\n",
    "\n",
    "def sample_sound(data_gen):\n",
    "    size = data_gen.size()\n",
    "    rand = torch.rand(*size).cuda()\n",
    "    sample = (rand<data_gen).type(torch.FloatTensor).cuda()\n",
    "    sample[:,:,:,2] = 1\n",
    "    return sample\n",
    " \n",
    "import torch.utils.data\n",
    "\n",
    "    \n",
    "\n",
    "def train_GAN(generator,discriminator,baseline,X_loader,num_epochs = 3,g_lr = 0.001, d_lr = 0.001,bl_lr = 0.001):\n",
    "    generator.train()\n",
    "    discriminator.train()\n",
    "    generator.train()\n",
    "    g_optimizer = torch.optim.Adam(generator.parameters(),     lr=g_lr,weight_decay = 0)#, betas=(0.5, 0.999))\n",
    "    d_optimizer = torch.optim.Adam(discriminator.parameters(), lr=d_lr,weight_decay = 0)#, betas=(0.5, 0.999))\n",
    "    bl_optimizer = torch.optim.Adam(baseline.parameters(), lr=bl_lr)\n",
    "    \n",
    "    d_losses = []\n",
    "    g_losses = []\n",
    "    bl_losses = []\n",
    "    for epoch in range(num_epochs):\n",
    "        for i, [x_batch,ch_batch] in enumerate(X_loader):\n",
    "            x_batch = x_batch.cuda()\n",
    "            ch_batch = ch_batch.cuda()\n",
    "            x_batch[:,:,:,2] = 1\n",
    "            ch_batch[:,:,:,2] = 1\n",
    "            \n",
    "            # Optimize D\n",
    "\n",
    "            data_gen = generator(x_batch,ch_batch)\n",
    "            sound = sample_sound(data_gen).data\n",
    "#             sound[:,:,:,1] = sound[:,:,:,1]*sound[:,:,:,0]\n",
    "            #concat_sound = torch.cat([x_batch[:,1:TIME_SCALE//2+1,:,:],sound[:,TIME_SCALE//2:,:,:]],dim = 1)\n",
    "            false_example = torch.cat([sound,x_batch],dim = -1)\n",
    "            true_example = torch.cat([ch_batch,x_batch],dim = -1)\n",
    "            loss = d_loss(discriminator(false_example), discriminator(true_example))\n",
    "            d_optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "#             print(loss.grad)\n",
    "            d_optimizer.step()\n",
    "            d_losses.append(loss.data.cpu().numpy())\n",
    "        \n",
    "            # Optimize BL\n",
    "            data_gen = generator(x_batch,ch_batch)\n",
    "            sound = sample_sound(data_gen).data\n",
    "#             sound[:,:,:,1] = sound[:,:,:,1]*sound[:,:,:,0]\n",
    "            false_example = torch.cat([sound,x_batch],dim = -1)\n",
    "            loss = bl_loss(baseline(x_batch,ch_batch),discriminator(false_example))\n",
    "            bl_optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            bl_optimizer.step()\n",
    "            bl_losses.append(loss.data.cpu().numpy())\n",
    "            \n",
    "#             # Optimize G\n",
    "            if i%2==0:\n",
    "                data_gen = generator(x_batch,ch_batch)\n",
    "                sound = sample_sound(data_gen).data\n",
    "    #             sound[:,:,:,1] = sound[:,:,:,1]*sound[:,:,:,0]\n",
    "                #concat_sound = torch.cat([x_batch[:,1:TIME_SCALE//2+1,:,:],sound[:,TIME_SCALE//2:,:,:]],dim = 1)\n",
    "\n",
    "                false_example = torch.cat([sound,x_batch],dim = -1)\n",
    "                true_example = torch.cat([ch_batch,x_batch],dim = -1)\n",
    "                handle = np.random.randint(0,2)\n",
    "                if handle == 0:\n",
    "                    loss = g_loss(discriminator(false_example),sound,data_gen,baseline(x_batch,ch_batch),ch_batch)#,sound.data,data_gen)\n",
    "                else:\n",
    "                    loss = g_loss(discriminator(true_example).cuda(),ch_batch,data_gen,baseline(x_batch,ch_batch),ch_batch)#,sound.data,data_gen)\n",
    "                g_optimizer.zero_grad()\n",
    "                loss += compute_loss(data_gen,ch_batch)\n",
    "                loss.backward()\n",
    "    #             print(loss.grad)\n",
    "                g_optimizer.step()\n",
    "                g_losses.append(loss.data.cpu().numpy())\n",
    "    return generator,discriminator,baseline,np.array(g_losses),np.array(d_losses),np.array(bl_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((81, 128, 48, 3), (81, 128, 48, 3))"
      ]
     },
     "execution_count": 226,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dataset import load_all\n",
    "from constants import *\n",
    "\n",
    "styles= [['data/Bach1']]\n",
    "train_data, train_labels = load_all(styles, BATCH_SIZE, TIME_SCALE)\n",
    "X_tr = train_data[0]\n",
    "y_tr = train_labels[0]\n",
    "# X_te = train_data[0][N:2*N]\n",
    "train_data[0].shape,y_tr.shape\n",
    "#y_te = train_labels[0][-1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_loader = torch.utils.data.DataLoader(\\\n",
    "            torch.utils.data.TensorDataset(\\\n",
    "            *(torch.FloatTensor(X_tr),\n",
    "            torch.FloatTensor(y_tr))),\\\n",
    "            batch_size=16,shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "with torch.cuda.device(GPU):\n",
    "    torch.cuda.empty_cache()\n",
    "    gc.collect() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p_fake:  0.50329024 probs:  0.9402609\n",
      "p_fake:  1.0 probs:  0.94563\n",
      "p_fake:  1.0 probs:  0.93579894\n",
      "p_fake:  0.5872172 probs:  0.9011283\n",
      "p_fake:  0.43306604 probs:  0.86784786\n",
      "p_fake:  0.50421786 probs:  0.8442467\n",
      "p_fake:  0.5247569 probs:  0.8284126\n",
      "p_fake:  1.0 probs:  0.84970784\n",
      "p_fake:  0.5001404 probs:  0.8858357\n",
      "p_fake:  1.0 probs:  0.92977977\n",
      "p_fake:  0.5002968 probs:  0.944524\n",
      "p_fake:  0.49942654 probs:  0.95672494\n",
      "p_fake:  0.4995026 probs:  0.96533155\n",
      "p_fake:  0.50042063 probs:  0.970443\n",
      "p_fake:  1.0 probs:  0.9556015\n",
      "p_fake:  0.49951348 probs:  0.97500944\n",
      "p_fake:  0.4998057 probs:  0.9757797\n",
      "p_fake:  0.50050384 probs:  0.97622985\n",
      "p_fake:  1.0 probs:  0.9593873\n",
      "p_fake:  0.49968463 probs:  0.9748698\n",
      "p_fake:  1.0 probs:  0.9581735\n",
      "p_fake:  1.0 probs:  0.9527878\n",
      "p_fake:  0.49976793 probs:  0.9633131\n",
      "p_fake:  1.0 probs:  0.95010716\n",
      "p_fake:  0.4999589 probs:  0.952662\n",
      "p_fake:  1.0 probs:  0.945901\n",
      "p_fake:  0.50020725 probs:  0.9412864\n",
      "p_fake:  0.4999445 probs:  0.93535566\n",
      "p_fake:  0.49989122 probs:  0.9303894\n",
      "p_fake:  1.0 probs:  0.9346823\n",
      "p_fake:  0.49966604 probs:  0.92410284\n",
      "p_fake:  1.0 probs:  0.9312814\n",
      "p_fake:  1.0 probs:  0.9349223\n",
      "p_fake:  1.0 probs:  0.9338855\n",
      "p_fake:  0.50030845 probs:  0.9332655\n",
      "p_fake:  1.0 probs:  0.941608\n",
      "p_fake:  0.5011095 probs:  0.9402754\n",
      "p_fake:  0.49929005 probs:  0.9431837\n",
      "p_fake:  0.49950093 probs:  0.945373\n",
      "p_fake:  0.5011542 probs:  0.94895315\n",
      "p_fake:  1.0 probs:  0.9412289\n",
      "p_fake:  0.4877254 probs:  0.9501414\n",
      "p_fake:  0.506337 probs:  0.9493644\n",
      "p_fake:  1.0 probs:  0.94895625\n",
      "p_fake:  0.5034503 probs:  0.9473877\n",
      "p_fake:  0.49776888 probs:  0.9467371\n",
      "p_fake:  0.49635696 probs:  0.9457801\n",
      "p_fake:  1.0 probs:  0.93976396\n",
      "p_fake:  1.0 probs:  0.9488638\n",
      "p_fake:  0.5127813 probs:  0.94332737\n",
      "p_fake:  0.48629656 probs:  0.94312114\n",
      "p_fake:  1.0 probs:  0.9423504\n",
      "p_fake:  1.0 probs:  0.94327766\n",
      "p_fake:  0.50885344 probs:  0.94328785\n",
      "p_fake:  0.48310262 probs:  0.94340175\n",
      "p_fake:  1.0 probs:  0.94115466\n",
      "p_fake:  0.5187014 probs:  0.9427435\n",
      "p_fake:  0.49134034 probs:  0.94245905\n",
      "p_fake:  1.0 probs:  0.944714\n",
      "p_fake:  1.0 probs:  0.94460726\n",
      "p_fake:  1.0 probs:  0.94197226\n",
      "p_fake:  1.0 probs:  0.9454074\n",
      "p_fake:  1.0 probs:  0.94455314\n",
      "p_fake:  0.505783 probs:  0.9461024\n",
      "p_fake:  0.4787187 probs:  0.9460426\n",
      "p_fake:  0.512826 probs:  0.94647485\n",
      "p_fake:  0.47020146 probs:  0.94708437\n",
      "p_fake:  1.0 probs:  0.94735193\n",
      "p_fake:  1.0 probs:  0.94749755\n",
      "p_fake:  0.51318216 probs:  0.9484627\n",
      "p_fake:  1.0 probs:  0.94520825\n",
      "p_fake:  1.0 probs:  0.9479687\n",
      "p_fake:  0.4259934 probs:  0.94565696\n",
      "p_fake:  1.0 probs:  0.9434812\n",
      "p_fake:  1.0 probs:  0.94630307\n",
      "p_fake:  1.0 probs:  0.9476982\n",
      "p_fake:  0.39636448 probs:  0.9446378\n",
      "p_fake:  0.6239984 probs:  0.9451196\n",
      "p_fake:  1.0 probs:  0.94491655\n",
      "p_fake:  1.0 probs:  0.9458184\n",
      "p_fake:  0.4120791 probs:  0.9469132\n",
      "p_fake:  0.36391273 probs:  0.9476802\n",
      "p_fake:  1.0 probs:  0.94245833\n",
      "p_fake:  0.515315 probs:  0.94599986\n",
      "p_fake:  0.47267556 probs:  0.9437959\n",
      "p_fake:  0.50908667 probs:  0.9428678\n",
      "p_fake:  0.5093119 probs:  0.94174886\n",
      "p_fake:  1.0 probs:  0.94366574\n",
      "p_fake:  1.0 probs:  0.94631934\n",
      "p_fake:  0.50415933 probs:  0.9468753\n",
      "p_fake:  1.0 probs:  0.951469\n",
      "p_fake:  1.0 probs:  0.9539907\n",
      "p_fake:  0.48378617 probs:  0.9561793\n",
      "p_fake:  1.0 probs:  0.9494327\n",
      "p_fake:  1.0 probs:  0.9430496\n",
      "p_fake:  1.0 probs:  0.9414608\n",
      "p_fake:  0.48740372 probs:  0.9317345\n",
      "p_fake:  1.0 probs:  0.9346597\n",
      "p_fake:  0.5011572 probs:  0.9284263\n",
      "p_fake:  1.0 probs:  0.93241787\n",
      "p_fake:  0.49226862 probs:  0.93212056\n",
      "p_fake:  1.0 probs:  0.9371405\n",
      "p_fake:  0.45444337 probs:  0.93807465\n",
      "p_fake:  1.0 probs:  0.94747907\n",
      "p_fake:  0.4422062 probs:  0.94749504\n",
      "p_fake:  1.0 probs:  0.94688964\n",
      "p_fake:  0.45898196 probs:  0.953825\n",
      "p_fake:  0.6816636 probs:  0.9552137\n",
      "p_fake:  0.6116553 probs:  0.9560818\n",
      "p_fake:  0.40571898 probs:  0.9571812\n",
      "p_fake:  1.0 probs:  0.9507316\n",
      "p_fake:  0.5172329 probs:  0.95440227\n",
      "p_fake:  1.0 probs:  0.94980615\n",
      "p_fake:  1.0 probs:  0.9472429\n",
      "p_fake:  0.4770149 probs:  0.94228655\n",
      "p_fake:  1.0 probs:  0.94183403\n",
      "p_fake:  0.51807064 probs:  0.93916637\n",
      "p_fake:  1.0 probs:  0.9387029\n",
      "p_fake:  1.0 probs:  0.9429441\n",
      "p_fake:  0.4963829 probs:  0.9415919\n",
      "p_fake:  0.4898459 probs:  0.9437769\n",
      "p_fake:  1.0 probs:  0.9472806\n",
      "p_fake:  0.4920236 probs:  0.9497485\n",
      "p_fake:  0.4724367 probs:  0.9518399\n",
      "p_fake:  1.0 probs:  0.953814\n",
      "p_fake:  0.4820176 probs:  0.95722985\n",
      "p_fake:  0.40439937 probs:  0.9583566\n",
      "p_fake:  1.0 probs:  0.95104665\n",
      "p_fake:  1.0 probs:  0.94867104\n",
      "p_fake:  1.0 probs:  0.9447854\n",
      "p_fake:  1.0 probs:  0.94121724\n",
      "p_fake:  1.0 probs:  0.93843204\n",
      "p_fake:  1.0 probs:  0.9421327\n",
      "p_fake:  1.0 probs:  0.94327354\n",
      "p_fake:  1.0 probs:  0.94568115\n",
      "p_fake:  1.0 probs:  0.9497123\n",
      "p_fake:  1.0 probs:  0.95082664\n",
      "p_fake:  1.0 probs:  0.94472003\n",
      "p_fake:  0.56935143 probs:  0.94240475\n",
      "p_fake:  1.0 probs:  0.9427658\n",
      "p_fake:  1.0 probs:  0.94266915\n",
      "p_fake:  1.0 probs:  0.94738466\n",
      "p_fake:  0.5245755 probs:  0.94929576\n",
      "p_fake:  0.5257824 probs:  0.95674807\n",
      "p_fake:  0.5106865 probs:  0.9639533\n",
      "p_fake:  1.0 probs:  0.9549082\n",
      "p_fake:  0.43923005 probs:  0.96341753\n",
      "p_fake:  1.0 probs:  0.95000815\n",
      "p_fake:  0.4135183 probs:  0.95149684\n",
      "p_fake:  1.0 probs:  0.94375587\n",
      "p_fake:  1.0 probs:  0.9443012\n",
      "p_fake:  1.0 probs:  0.9379015\n",
      "p_fake:  1.0 probs:  0.94299\n",
      "p_fake:  1.0 probs:  0.9441076\n",
      "p_fake:  1.0 probs:  0.9510372\n",
      "p_fake:  1.0 probs:  0.9538477\n",
      "p_fake:  0.4462742 probs:  0.96129006\n",
      "p_fake:  0.51081866 probs:  0.9663818\n",
      "p_fake:  0.34116614 probs:  0.9706275\n",
      "p_fake:  1.0 probs:  0.9630785\n",
      "p_fake:  0.11212692 probs:  0.96934336\n",
      "p_fake:  1.0 probs:  0.95220375\n",
      "p_fake:  0.38662645 probs:  0.9536872\n",
      "p_fake:  0.6636943 probs:  0.9408272\n",
      "p_fake:  0.70962125 probs:  0.9316574\n",
      "p_fake:  1.0 probs:  0.9339545\n",
      "p_fake:  1.0 probs:  0.93878525\n",
      "p_fake:  1.0 probs:  0.9379528\n",
      "p_fake:  1.0 probs:  0.948632\n",
      "p_fake:  1.0 probs:  0.9528981\n",
      "p_fake:  0.44438636 probs:  0.95916647\n",
      "p_fake:  1.0 probs:  0.9496166\n",
      "p_fake:  1.0 probs:  0.95709187\n",
      "p_fake:  1.0 probs:  0.9586816\n",
      "p_fake:  0.5466126 probs:  0.96166974\n",
      "p_fake:  0.5392173 probs:  0.95831746\n",
      "p_fake:  1.0 probs:  0.9460438\n",
      "p_fake:  0.50023645 probs:  0.9493821\n",
      "p_fake:  0.48365277 probs:  0.94435143\n",
      "p_fake:  0.4744126 probs:  0.9360531\n",
      "p_fake:  0.47538376 probs:  0.935314\n",
      "p_fake:  0.48465702 probs:  0.93125844\n",
      "p_fake:  0.49484545 probs:  0.9285922\n",
      "p_fake:  0.5060437 probs:  0.924685\n",
      "p_fake:  1.0 probs:  0.9304834\n",
      "p_fake:  0.5156434 probs:  0.9309869\n",
      "p_fake:  1.0 probs:  0.942322\n",
      "p_fake:  0.50638014 probs:  0.94600564\n",
      "p_fake:  1.0 probs:  0.9480588\n",
      "p_fake:  0.4939894 probs:  0.95249414\n",
      "p_fake:  1.0 probs:  0.95032567\n",
      "p_fake:  1.0 probs:  0.95616156\n",
      "p_fake:  0.49488065 probs:  0.95553166\n",
      "p_fake:  1.0 probs:  0.94828826\n",
      "p_fake:  1.0 probs:  0.9525061\n",
      "p_fake:  1.0 probs:  0.94810367\n",
      "p_fake:  1.0 probs:  0.9503028\n",
      "p_fake:  1.0 probs:  0.94877404\n",
      "p_fake:  1.0 probs:  0.94413495\n",
      "p_fake:  1.0 probs:  0.9489007\n",
      "p_fake:  1.0 probs:  0.9471579\n",
      "p_fake:  1.0 probs:  0.9542076\n",
      "p_fake:  0.49751338 probs:  0.95347613\n",
      "p_fake:  1.0 probs:  0.9507177\n",
      "p_fake:  1.0 probs:  0.9565781\n",
      "p_fake:  1.0 probs:  0.9545495\n",
      "p_fake:  1.0 probs:  0.94970006\n",
      "p_fake:  0.5015822 probs:  0.9501376\n",
      "p_fake:  1.0 probs:  0.94573945\n",
      "p_fake:  1.0 probs:  0.9491196\n",
      "p_fake:  1.0 probs:  0.94824576\n",
      "p_fake:  0.49933627 probs:  0.9458852\n",
      "p_fake:  0.4990262 probs:  0.95396495\n",
      "p_fake:  1.0 probs:  0.9561751\n",
      "p_fake:  0.49983317 probs:  0.95950395\n",
      "p_fake:  0.50009227 probs:  0.9601044\n",
      "p_fake:  1.0 probs:  0.95476776\n",
      "p_fake:  1.0 probs:  0.95918006\n",
      "p_fake:  0.5002661 probs:  0.9536047\n",
      "p_fake:  0.5000851 probs:  0.9487011\n",
      "p_fake:  1.0 probs:  0.95032597\n",
      "p_fake:  0.4998807 probs:  0.9496698\n",
      "p_fake:  0.49987423 probs:  0.9555299\n",
      "p_fake:  0.4999255 probs:  0.9517265\n",
      "p_fake:  1.0 probs:  0.9536217\n",
      "p_fake:  1.0 probs:  0.95413804\n",
      "p_fake:  1.0 probs:  0.95285016\n",
      "p_fake:  1.0 probs:  0.95289654\n",
      "p_fake:  1.0 probs:  0.95057553\n",
      "p_fake:  1.0 probs:  0.9525338\n",
      "p_fake:  0.4997552 probs:  0.95592767\n",
      "p_fake:  1.0 probs:  0.9543276\n",
      "p_fake:  1.0 probs:  0.9569759\n",
      "p_fake:  1.0 probs:  0.95675117\n",
      "p_fake:  1.0 probs:  0.9641909\n",
      "p_fake:  1.0 probs:  0.9596606\n",
      "p_fake:  1.0 probs:  0.9557217\n",
      "p_fake:  1.0 probs:  0.9558985\n",
      "p_fake:  0.5004451 probs:  0.96090966\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p_fake:  1.0 probs:  0.95631117\n",
      "p_fake:  0.50008816 probs:  0.95563126\n",
      "p_fake:  0.4999362 probs:  0.9481778\n",
      "p_fake:  0.49974918 probs:  0.93873304\n",
      "p_fake:  0.49989516 probs:  0.9352295\n",
      "p_fake:  1.0 probs:  0.9397111\n",
      "p_fake:  1.0 probs:  0.9458429\n",
      "p_fake:  1.0 probs:  0.9542532\n",
      "p_fake:  0.50044453 probs:  0.9647329\n",
      "p_fake:  1.0 probs:  0.9651577\n",
      "p_fake:  1.0 probs:  0.9595656\n",
      "p_fake:  1.0 probs:  0.95792323\n",
      "p_fake:  1.0 probs:  0.95155543\n",
      "p_fake:  0.49960157 probs:  0.94240063\n",
      "p_fake:  1.0 probs:  0.95149523\n",
      "p_fake:  0.49999687 probs:  0.94050074\n",
      "p_fake:  1.0 probs:  0.94830686\n",
      "p_fake:  0.5001538 probs:  0.952949\n",
      "p_fake:  0.50046515 probs:  0.9554233\n",
      "p_fake:  0.5002716 probs:  0.9597979\n",
      "p_fake:  0.5001514 probs:  0.9648451\n",
      "p_fake:  1.0 probs:  0.9625602\n",
      "p_fake:  0.4997891 probs:  0.9667348\n",
      "p_fake:  1.0 probs:  0.96316975\n",
      "p_fake:  1.0 probs:  0.9636057\n",
      "p_fake:  1.0 probs:  0.96261954\n",
      "p_fake:  0.4998052 probs:  0.9555359\n",
      "p_fake:  0.49995708 probs:  0.95475817\n",
      "p_fake:  0.50033456 probs:  0.9479475\n",
      "p_fake:  1.0 probs:  0.953598\n",
      "p_fake:  1.0 probs:  0.960308\n",
      "p_fake:  1.0 probs:  0.95898014\n",
      "p_fake:  0.49984214 probs:  0.9695781\n",
      "p_fake:  0.49949232 probs:  0.97373325\n",
      "p_fake:  0.49938768 probs:  0.97630614\n",
      "p_fake:  1.0 probs:  0.96747476\n",
      "p_fake:  1.0 probs:  0.96312934\n",
      "p_fake:  1.0 probs:  0.95946217\n",
      "p_fake:  0.4999535 probs:  0.95221204\n",
      "p_fake:  1.0 probs:  0.9471361\n",
      "p_fake:  0.50040495 probs:  0.93586856\n",
      "p_fake:  1.0 probs:  0.943434\n",
      "p_fake:  0.50020516 probs:  0.9281273\n",
      "p_fake:  0.49950024 probs:  0.9281023\n",
      "p_fake:  0.4989642 probs:  0.9305641\n",
      "p_fake:  1.0 probs:  0.945313\n",
      "p_fake:  1.0 probs:  0.9478896\n",
      "p_fake:  1.0 probs:  0.9506676\n",
      "p_fake:  0.49919188 probs:  0.95362633\n",
      "p_fake:  1.0 probs:  0.96103764\n",
      "p_fake:  0.4951216 probs:  0.9637041\n",
      "p_fake:  1.0 probs:  0.9608758\n",
      "p_fake:  0.49535972 probs:  0.9701884\n",
      "p_fake:  1.0 probs:  0.9637117\n",
      "p_fake:  1.0 probs:  0.961829\n",
      "p_fake:  0.5086508 probs:  0.96677256\n",
      "p_fake:  0.4968194 probs:  0.9666922\n",
      "p_fake:  1.0 probs:  0.96494436\n",
      "p_fake:  1.0 probs:  0.9618915\n",
      "p_fake:  1.0 probs:  0.9641824\n",
      "p_fake:  0.5101905 probs:  0.96109444\n",
      "p_fake:  0.50886357 probs:  0.9626549\n",
      "p_fake:  1.0 probs:  0.960104\n",
      "p_fake:  1.0 probs:  0.9631214\n",
      "p_fake:  0.48556355 probs:  0.9623868\n",
      "p_fake:  0.48677883 probs:  0.9615934\n",
      "p_fake:  1.0 probs:  0.95943385\n",
      "p_fake:  1.0 probs:  0.9588244\n",
      "p_fake:  1.0 probs:  0.9611787\n",
      "p_fake:  0.49994284 probs:  0.9592386\n",
      "p_fake:  0.48985687 probs:  0.9580943\n",
      "p_fake:  0.48246682 probs:  0.95723206\n",
      "p_fake:  0.48603234 probs:  0.95375824\n",
      "p_fake:  0.49706513 probs:  0.9540179\n",
      "p_fake:  1.0 probs:  0.95604366\n",
      "p_fake:  0.5165265 probs:  0.9505723\n",
      "p_fake:  1.0 probs:  0.95790005\n",
      "p_fake:  1.0 probs:  0.9569176\n",
      "p_fake:  0.4936454 probs:  0.95745564\n",
      "p_fake:  0.48512316 probs:  0.9611675\n",
      "p_fake:  1.0 probs:  0.95419306\n",
      "p_fake:  0.4942164 probs:  0.9614118\n",
      "p_fake:  0.5054743 probs:  0.95970535\n",
      "p_fake:  0.508945 probs:  0.9573252\n",
      "p_fake:  1.0 probs:  0.95795083\n",
      "p_fake:  0.5052261 probs:  0.9570047\n",
      "p_fake:  1.0 probs:  0.95995426\n",
      "p_fake:  1.0 probs:  0.95773864\n",
      "p_fake:  0.49438858 probs:  0.9587323\n",
      "p_fake:  0.49219522 probs:  0.956546\n",
      "p_fake:  0.49439487 probs:  0.9558143\n",
      "p_fake:  1.0 probs:  0.95766276\n",
      "p_fake:  1.0 probs:  0.9562486\n",
      "p_fake:  1.0 probs:  0.9627631\n",
      "p_fake:  0.5050063 probs:  0.96336913\n",
      "p_fake:  0.502447 probs:  0.9626803\n",
      "p_fake:  0.49949583 probs:  0.9634552\n",
      "p_fake:  1.0 probs:  0.9559748\n",
      "p_fake:  0.4964259 probs:  0.9628938\n",
      "p_fake:  0.49722275 probs:  0.9622454\n",
      "p_fake:  0.49892738 probs:  0.9608732\n",
      "p_fake:  1.0 probs:  0.9619767\n",
      "p_fake:  1.0 probs:  0.95798725\n",
      "p_fake:  0.501266 probs:  0.95464164\n",
      "p_fake:  1.0 probs:  0.9609631\n",
      "p_fake:  0.49972704 probs:  0.95967036\n",
      "p_fake:  0.49947944 probs:  0.9559465\n",
      "p_fake:  1.0 probs:  0.95549345\n",
      "p_fake:  0.50017375 probs:  0.9568836\n",
      "p_fake:  1.0 probs:  0.9606745\n",
      "p_fake:  0.4996902 probs:  0.9602888\n",
      "p_fake:  1.0 probs:  0.95802027\n",
      "p_fake:  0.49801144 probs:  0.9574831\n",
      "p_fake:  0.49803406 probs:  0.9565675\n",
      "p_fake:  0.49869105 probs:  0.96045345\n",
      "p_fake:  0.49778712 probs:  0.9545893\n",
      "p_fake:  0.4984325 probs:  0.9546933\n",
      "p_fake:  1.0 probs:  0.9601512\n",
      "p_fake:  0.50155836 probs:  0.9562401\n",
      "p_fake:  1.0 probs:  0.95657706\n",
      "p_fake:  1.0 probs:  0.9547005\n",
      "p_fake:  0.5003013 probs:  0.9642566\n",
      "p_fake:  0.5004673 probs:  0.96021694\n",
      "p_fake:  0.50104046 probs:  0.9585783\n",
      "p_fake:  1.0 probs:  0.9630112\n",
      "p_fake:  0.4989553 probs:  0.9561774\n",
      "p_fake:  1.0 probs:  0.9641745\n",
      "p_fake:  0.49833313 probs:  0.96086884\n",
      "p_fake:  0.4991192 probs:  0.96280193\n",
      "p_fake:  0.4996732 probs:  0.9640662\n",
      "p_fake:  0.5001853 probs:  0.9650424\n",
      "p_fake:  1.0 probs:  0.9617495\n",
      "p_fake:  0.5005628 probs:  0.9634889\n",
      "p_fake:  1.0 probs:  0.95773435\n",
      "p_fake:  1.0 probs:  0.95906645\n",
      "p_fake:  0.49773064 probs:  0.95892715\n",
      "p_fake:  0.4990681 probs:  0.9533794\n",
      "p_fake:  1.0 probs:  0.9557288\n",
      "p_fake:  1.0 probs:  0.95576805\n",
      "p_fake:  1.0 probs:  0.9602735\n",
      "p_fake:  1.0 probs:  0.9629152\n",
      "p_fake:  0.5001118 probs:  0.96036816\n",
      "p_fake:  0.4999214 probs:  0.96614033\n",
      "p_fake:  0.49985987 probs:  0.9696273\n",
      "p_fake:  1.0 probs:  0.96214646\n",
      "p_fake:  1.0 probs:  0.96146274\n",
      "p_fake:  1.0 probs:  0.95958734\n",
      "p_fake:  0.49960482 probs:  0.9494335\n",
      "p_fake:  0.49969026 probs:  0.9487769\n",
      "p_fake:  1.0 probs:  0.9484374\n",
      "p_fake:  1.0 probs:  0.9535106\n",
      "p_fake:  0.50011706 probs:  0.95798033\n",
      "p_fake:  1.0 probs:  0.9573965\n",
      "p_fake:  1.0 probs:  0.9582181\n",
      "p_fake:  1.0 probs:  0.96445376\n",
      "p_fake:  0.5007441 probs:  0.9617615\n",
      "p_fake:  0.500401 probs:  0.96019316\n",
      "p_fake:  1.0 probs:  0.95432544\n",
      "p_fake:  1.0 probs:  0.9596949\n",
      "p_fake:  1.0 probs:  0.9603525\n",
      "p_fake:  0.49846447 probs:  0.96268326\n",
      "p_fake:  0.49859494 probs:  0.96456224\n",
      "p_fake:  1.0 probs:  0.9646547\n",
      "p_fake:  0.5016214 probs:  0.9622758\n",
      "p_fake:  0.50218934 probs:  0.96505696\n",
      "p_fake:  0.5006427 probs:  0.96462584\n",
      "p_fake:  1.0 probs:  0.96273756\n",
      "p_fake:  1.0 probs:  0.9601238\n",
      "p_fake:  1.0 probs:  0.9595242\n",
      "p_fake:  1.0 probs:  0.9596289\n",
      "p_fake:  1.0 probs:  0.9591043\n",
      "p_fake:  1.0 probs:  0.95716363\n",
      "p_fake:  0.5012023 probs:  0.9588788\n",
      "p_fake:  1.0 probs:  0.9625335\n",
      "p_fake:  0.49979642 probs:  0.96464044\n",
      "p_fake:  1.0 probs:  0.9699541\n",
      "p_fake:  1.0 probs:  0.9545463\n",
      "p_fake:  0.49857846 probs:  0.95926565\n",
      "p_fake:  1.0 probs:  0.9621644\n",
      "p_fake:  0.5004047 probs:  0.95947266\n",
      "p_fake:  0.5003583 probs:  0.962737\n",
      "p_fake:  1.0 probs:  0.95613027\n",
      "p_fake:  1.0 probs:  0.96311694\n",
      "p_fake:  1.0 probs:  0.9683247\n",
      "p_fake:  0.49858648 probs:  0.9631055\n",
      "p_fake:  1.0 probs:  0.9691158\n",
      "p_fake:  1.0 probs:  0.9601155\n",
      "p_fake:  0.4996712 probs:  0.95684105\n",
      "p_fake:  0.5042871 probs:  0.9561519\n",
      "p_fake:  0.5046513 probs:  0.94819236\n",
      "p_fake:  1.0 probs:  0.9550536\n",
      "p_fake:  0.5020036 probs:  0.94929856\n",
      "p_fake:  1.0 probs:  0.9632134\n",
      "p_fake:  1.0 probs:  0.9644796\n",
      "p_fake:  1.0 probs:  0.9632893\n",
      "p_fake:  0.49791998 probs:  0.9680994\n",
      "p_fake:  0.4999073 probs:  0.96842045\n",
      "p_fake:  1.0 probs:  0.9561174\n",
      "p_fake:  1.0 probs:  0.96205753\n",
      "p_fake:  1.0 probs:  0.9600614\n",
      "p_fake:  0.50023854 probs:  0.9559982\n",
      "p_fake:  1.0 probs:  0.95833963\n",
      "p_fake:  1.0 probs:  0.9623301\n",
      "p_fake:  0.4986846 probs:  0.9626017\n",
      "p_fake:  1.0 probs:  0.958062\n",
      "p_fake:  1.0 probs:  0.9649903\n",
      "p_fake:  1.0 probs:  0.96344066\n",
      "p_fake:  1.0 probs:  0.96278566\n",
      "p_fake:  1.0 probs:  0.9610149\n",
      "p_fake:  0.49934444 probs:  0.95335585\n",
      "p_fake:  1.0 probs:  0.9659949\n",
      "p_fake:  0.49847928 probs:  0.95829636\n",
      "p_fake:  0.4993268 probs:  0.96349\n",
      "p_fake:  0.5000877 probs:  0.9655309\n",
      "p_fake:  1.0 probs:  0.9617651\n",
      "p_fake:  1.0 probs:  0.95644814\n",
      "p_fake:  1.0 probs:  0.9581444\n",
      "p_fake:  0.49921152 probs:  0.9553554\n",
      "p_fake:  1.0 probs:  0.9576922\n",
      "p_fake:  1.0 probs:  0.95801497\n",
      "p_fake:  1.0 probs:  0.95751095\n",
      "p_fake:  0.5014984 probs:  0.9644708\n",
      "p_fake:  1.0 probs:  0.96509427\n",
      "p_fake:  1.0 probs:  0.96255136\n",
      "p_fake:  1.0 probs:  0.9621739\n",
      "p_fake:  1.0 probs:  0.9564052\n",
      "p_fake:  0.49929404 probs:  0.95962924\n",
      "p_fake:  0.49746555 probs:  0.9483772\n",
      "p_fake:  0.49784172 probs:  0.94915634\n",
      "p_fake:  1.0 probs:  0.956218\n",
      "p_fake:  1.0 probs:  0.9571088\n",
      "p_fake:  0.4998981 probs:  0.968935\n",
      "p_fake:  1.0 probs:  0.9632237\n",
      "p_fake:  0.50495446 probs:  0.9730684\n",
      "p_fake:  0.50386614 probs:  0.97085756\n",
      "p_fake:  1.0 probs:  0.9712015\n",
      "p_fake:  1.0 probs:  0.96267325\n",
      "p_fake:  0.49352062 probs:  0.96414995\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p_fake:  0.5013625 probs:  0.95535636\n",
      "p_fake:  0.50606817 probs:  0.948149\n",
      "p_fake:  1.0 probs:  0.95262694\n",
      "p_fake:  1.0 probs:  0.95311284\n",
      "p_fake:  1.0 probs:  0.954732\n",
      "p_fake:  1.0 probs:  0.95993423\n",
      "p_fake:  1.0 probs:  0.9632519\n",
      "p_fake:  0.5038761 probs:  0.9659712\n",
      "p_fake:  1.0 probs:  0.96666527\n",
      "p_fake:  0.49934816 probs:  0.96927094\n",
      "p_fake:  0.49721026 probs:  0.9703856\n",
      "p_fake:  1.0 probs:  0.96287805\n",
      "p_fake:  0.49789098 probs:  0.9662652\n",
      "p_fake:  0.49913225 probs:  0.96920854\n",
      "p_fake:  0.501631 probs:  0.9667136\n",
      "p_fake:  1.0 probs:  0.96199924\n",
      "p_fake:  1.0 probs:  0.9624586\n",
      "p_fake:  0.4990562 probs:  0.95725375\n",
      "p_fake:  0.4984588 probs:  0.9590509\n",
      "p_fake:  1.0 probs:  0.9641934\n",
      "p_fake:  0.5020389 probs:  0.95915604\n",
      "p_fake:  0.5043524 probs:  0.95662117\n",
      "p_fake:  1.0 probs:  0.9560497\n",
      "p_fake:  1.0 probs:  0.9594713\n",
      "p_fake:  1.0 probs:  0.9612048\n",
      "p_fake:  0.4964246 probs:  0.96033216\n",
      "p_fake:  1.0 probs:  0.9609193\n",
      "p_fake:  1.0 probs:  0.9663052\n",
      "p_fake:  1.0 probs:  0.95863086\n",
      "p_fake:  0.5024962 probs:  0.9622529\n",
      "p_fake:  0.501238 probs:  0.95801836\n",
      "p_fake:  0.49977195 probs:  0.9507292\n",
      "p_fake:  0.49886456 probs:  0.95851564\n",
      "p_fake:  0.49864495 probs:  0.9480333\n",
      "p_fake:  1.0 probs:  0.9501968\n",
      "p_fake:  1.0 probs:  0.961925\n",
      "p_fake:  0.50074846 probs:  0.96076936\n",
      "p_fake:  0.5009079 probs:  0.9617755\n",
      "p_fake:  1.0 probs:  0.9677043\n",
      "p_fake:  0.49971488 probs:  0.96575475\n",
      "p_fake:  1.0 probs:  0.9634393\n",
      "p_fake:  0.4993493 probs:  0.97037363\n",
      "p_fake:  1.0 probs:  0.96204656\n",
      "p_fake:  1.0 probs:  0.9726675\n",
      "p_fake:  0.50048876 probs:  0.96456623\n",
      "p_fake:  1.0 probs:  0.96062773\n",
      "p_fake:  1.0 probs:  0.95463204\n",
      "p_fake:  1.0 probs:  0.9568468\n",
      "p_fake:  0.49890774 probs:  0.96150154\n",
      "p_fake:  1.0 probs:  0.9568282\n",
      "p_fake:  1.0 probs:  0.9520707\n",
      "p_fake:  0.50068176 probs:  0.95618844\n",
      "p_fake:  0.49916437 probs:  0.9572575\n",
      "p_fake:  0.5010117 probs:  0.9579486\n",
      "p_fake:  0.5008088 probs:  0.9569493\n",
      "p_fake:  1.0 probs:  0.9582595\n",
      "p_fake:  0.49725372 probs:  0.954596\n",
      "p_fake:  1.0 probs:  0.9562633\n",
      "p_fake:  1.0 probs:  0.9574322\n",
      "p_fake:  1.0 probs:  0.96486765\n",
      "p_fake:  1.0 probs:  0.9582927\n",
      "p_fake:  0.49858937 probs:  0.9560581\n",
      "p_fake:  0.49698138 probs:  0.9583478\n",
      "p_fake:  1.0 probs:  0.96250015\n",
      "p_fake:  0.5018777 probs:  0.9628237\n",
      "p_fake:  1.0 probs:  0.9667899\n",
      "p_fake:  1.0 probs:  0.95690674\n",
      "p_fake:  1.0 probs:  0.9596694\n",
      "p_fake:  0.5073162 probs:  0.957648\n",
      "p_fake:  0.50811154 probs:  0.96916175\n",
      "p_fake:  1.0 probs:  0.96493214\n",
      "p_fake:  0.50577813 probs:  0.9593856\n",
      "p_fake:  1.0 probs:  0.96123856\n",
      "p_fake:  1.0 probs:  0.9676118\n",
      "p_fake:  1.0 probs:  0.9601109\n",
      "p_fake:  1.0 probs:  0.9638776\n",
      "p_fake:  1.0 probs:  0.9648604\n",
      "p_fake:  1.0 probs:  0.9559433\n",
      "p_fake:  1.0 probs:  0.9591532\n",
      "p_fake:  1.0 probs:  0.9628846\n",
      "p_fake:  0.50469714 probs:  0.9633894\n",
      "p_fake:  1.0 probs:  0.95840764\n",
      "p_fake:  0.49581885 probs:  0.9562796\n",
      "p_fake:  1.0 probs:  0.9559128\n",
      "p_fake:  0.4989311 probs:  0.9604227\n",
      "p_fake:  1.0 probs:  0.95493084\n",
      "p_fake:  0.5042246 probs:  0.9595868\n",
      "p_fake:  1.0 probs:  0.9622795\n",
      "p_fake:  1.0 probs:  0.95884585\n",
      "p_fake:  0.49758267 probs:  0.9641979\n",
      "p_fake:  0.49808472 probs:  0.96126896\n",
      "p_fake:  0.4980243 probs:  0.9654097\n",
      "p_fake:  0.49969676 probs:  0.96569425\n",
      "p_fake:  0.4973566 probs:  0.96807104\n",
      "p_fake:  0.48928243 probs:  0.96173066\n",
      "p_fake:  1.0 probs:  0.9618394\n",
      "p_fake:  1.0 probs:  0.96692723\n",
      "p_fake:  0.5085401 probs:  0.96372193\n",
      "p_fake:  0.51593447 probs:  0.9536467\n",
      "p_fake:  0.5072569 probs:  0.9638631\n",
      "p_fake:  0.49630803 probs:  0.95035076\n",
      "p_fake:  1.0 probs:  0.9538638\n",
      "p_fake:  0.4940282 probs:  0.95040894\n",
      "p_fake:  0.500863 probs:  0.9541902\n",
      "p_fake:  1.0 probs:  0.9605732\n",
      "p_fake:  0.50626606 probs:  0.9617602\n",
      "p_fake:  0.5019928 probs:  0.96681476\n",
      "p_fake:  1.0 probs:  0.9642572\n",
      "p_fake:  1.0 probs:  0.95953375\n",
      "p_fake:  1.0 probs:  0.9597428\n",
      "p_fake:  0.5006135 probs:  0.9566824\n",
      "p_fake:  0.5030495 probs:  0.9486672\n",
      "p_fake:  1.0 probs:  0.9475357\n",
      "p_fake:  1.0 probs:  0.9546625\n",
      "p_fake:  1.0 probs:  0.9515161\n",
      "p_fake:  0.4978286 probs:  0.95293385\n",
      "p_fake:  1.0 probs:  0.95905685\n",
      "p_fake:  1.0 probs:  0.9630711\n",
      "p_fake:  0.50164783 probs:  0.9659942\n",
      "p_fake:  0.50147885 probs:  0.971972\n",
      "p_fake:  0.5004002 probs:  0.9694054\n",
      "p_fake:  1.0 probs:  0.9676812\n",
      "p_fake:  0.49878442 probs:  0.96890813\n",
      "p_fake:  0.49941093 probs:  0.9670561\n",
      "p_fake:  1.0 probs:  0.9609038\n",
      "p_fake:  0.50087404 probs:  0.9666474\n",
      "p_fake:  1.0 probs:  0.96207756\n",
      "p_fake:  0.49993187 probs:  0.96523374\n",
      "p_fake:  0.4996028 probs:  0.95880026\n",
      "p_fake:  1.0 probs:  0.95872664\n",
      "p_fake:  1.0 probs:  0.9610303\n",
      "p_fake:  1.0 probs:  0.95633507\n",
      "p_fake:  1.0 probs:  0.9529908\n",
      "p_fake:  1.0 probs:  0.9591941\n",
      "p_fake:  0.49988002 probs:  0.9574149\n",
      "p_fake:  0.49988157 probs:  0.95885295\n",
      "p_fake:  1.0 probs:  0.95768696\n",
      "p_fake:  0.50014895 probs:  0.9582711\n",
      "p_fake:  1.0 probs:  0.9604023\n",
      "p_fake:  0.5002482 probs:  0.96124774\n",
      "p_fake:  0.4999922 probs:  0.9579301\n",
      "p_fake:  1.0 probs:  0.9638602\n",
      "p_fake:  1.0 probs:  0.9623823\n",
      "p_fake:  0.49990082 probs:  0.9603154\n",
      "p_fake:  1.0 probs:  0.9637013\n",
      "p_fake:  1.0 probs:  0.9631562\n",
      "p_fake:  1.0 probs:  0.9627963\n",
      "p_fake:  1.0 probs:  0.9635475\n",
      "p_fake:  1.0 probs:  0.9542415\n",
      "p_fake:  0.50001657 probs:  0.95888203\n",
      "p_fake:  0.5001643 probs:  0.9587991\n",
      "p_fake:  1.0 probs:  0.9593789\n",
      "p_fake:  0.4999582 probs:  0.95338273\n",
      "p_fake:  0.49980024 probs:  0.95542455\n",
      "p_fake:  0.4998943 probs:  0.95688343\n",
      "p_fake:  0.49981833 probs:  0.9593177\n",
      "p_fake:  0.5000663 probs:  0.959369\n",
      "p_fake:  0.50014055 probs:  0.9627035\n",
      "p_fake:  0.49996036 probs:  0.9629963\n",
      "p_fake:  0.5004151 probs:  0.9633467\n",
      "p_fake:  0.49984646 probs:  0.96164966\n",
      "p_fake:  1.0 probs:  0.9582308\n",
      "p_fake:  0.49994862 probs:  0.95813745\n",
      "p_fake:  1.0 probs:  0.9627854\n",
      "p_fake:  0.50024605 probs:  0.9654333\n",
      "p_fake:  1.0 probs:  0.9612486\n",
      "p_fake:  0.5006648 probs:  0.96443623\n",
      "p_fake:  0.500366 probs:  0.95745355\n",
      "p_fake:  1.0 probs:  0.96165067\n",
      "p_fake:  0.49961036 probs:  0.9605324\n",
      "p_fake:  1.0 probs:  0.9634754\n",
      "p_fake:  0.49979255 probs:  0.96430135\n",
      "p_fake:  0.5002864 probs:  0.96074104\n",
      "p_fake:  0.5000989 probs:  0.95756406\n",
      "p_fake:  1.0 probs:  0.9570777\n",
      "p_fake:  0.49840462 probs:  0.9652714\n",
      "p_fake:  1.0 probs:  0.96039987\n",
      "p_fake:  0.5012332 probs:  0.95774204\n",
      "p_fake:  1.0 probs:  0.96107477\n",
      "p_fake:  1.0 probs:  0.95673966\n",
      "p_fake:  0.50114226 probs:  0.96394485\n",
      "p_fake:  0.5017773 probs:  0.96297693\n",
      "p_fake:  1.0 probs:  0.9608538\n",
      "p_fake:  1.0 probs:  0.96037155\n",
      "p_fake:  0.49733263 probs:  0.9592178\n",
      "p_fake:  1.0 probs:  0.9572313\n",
      "p_fake:  1.0 probs:  0.9585511\n",
      "p_fake:  0.5023238 probs:  0.9621958\n",
      "p_fake:  1.0 probs:  0.96389157\n",
      "p_fake:  1.0 probs:  0.9650143\n",
      "p_fake:  0.4979655 probs:  0.9668088\n",
      "p_fake:  1.0 probs:  0.9606556\n",
      "p_fake:  1.0 probs:  0.96085334\n",
      "p_fake:  1.0 probs:  0.9548144\n",
      "p_fake:  1.0 probs:  0.955394\n",
      "p_fake:  1.0 probs:  0.96006155\n",
      "p_fake:  1.0 probs:  0.9543796\n",
      "p_fake:  0.49471813 probs:  0.9686301\n",
      "p_fake:  0.4971143 probs:  0.9675801\n",
      "p_fake:  1.0 probs:  0.9588382\n",
      "p_fake:  1.0 probs:  0.9624029\n",
      "p_fake:  1.0 probs:  0.9557703\n",
      "p_fake:  1.0 probs:  0.9675357\n",
      "p_fake:  1.0 probs:  0.9555917\n",
      "p_fake:  0.49749485 probs:  0.9558061\n",
      "p_fake:  0.51097333 probs:  0.95642656\n",
      "p_fake:  1.0 probs:  0.9659931\n",
      "p_fake:  0.4939992 probs:  0.9637742\n",
      "p_fake:  0.488046 probs:  0.96480304\n",
      "p_fake:  0.47684056 probs:  0.9615813\n",
      "p_fake:  1.0 probs:  0.9635906\n",
      "p_fake:  1.0 probs:  0.9577272\n",
      "p_fake:  1.0 probs:  0.9615776\n",
      "p_fake:  1.0 probs:  0.9579634\n",
      "p_fake:  0.49480712 probs:  0.9555201\n",
      "p_fake:  1.0 probs:  0.96187663\n",
      "p_fake:  1.0 probs:  0.96022886\n",
      "p_fake:  0.5003483 probs:  0.9626186\n",
      "p_fake:  1.0 probs:  0.95953315\n",
      "p_fake:  0.48778337 probs:  0.96758336\n",
      "p_fake:  0.47761872 probs:  0.95700073\n",
      "p_fake:  0.4919278 probs:  0.957305\n",
      "p_fake:  1.0 probs:  0.961529\n",
      "p_fake:  1.0 probs:  0.960224\n",
      "p_fake:  0.47923616 probs:  0.96982527\n",
      "p_fake:  1.0 probs:  0.9599862\n",
      "p_fake:  0.5487735 probs:  0.9629529\n",
      "p_fake:  1.0 probs:  0.96311116\n",
      "p_fake:  1.0 probs:  0.9590772\n",
      "p_fake:  1.0 probs:  0.95962554\n",
      "p_fake:  1.0 probs:  0.9616854\n",
      "p_fake:  0.514473 probs:  0.9588193\n",
      "p_fake:  1.0 probs:  0.9652943\n",
      "p_fake:  0.49222803 probs:  0.9626525\n",
      "p_fake:  1.0 probs:  0.96533984\n",
      "p_fake:  0.5046913 probs:  0.9678426\n",
      "p_fake:  0.5145717 probs:  0.96683604\n",
      "p_fake:  1.0 probs:  0.96138877\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p_fake:  1.0 probs:  0.958327\n",
      "p_fake:  1.0 probs:  0.9614571\n",
      "p_fake:  1.0 probs:  0.95864445\n",
      "p_fake:  0.47031027 probs:  0.95665336\n",
      "p_fake:  1.0 probs:  0.9644969\n",
      "p_fake:  0.4794934 probs:  0.96352226\n",
      "p_fake:  1.0 probs:  0.9634586\n",
      "p_fake:  1.0 probs:  0.95952296\n",
      "p_fake:  0.5368211 probs:  0.9570187\n",
      "p_fake:  0.5146213 probs:  0.9661047\n",
      "p_fake:  1.0 probs:  0.95916885\n",
      "p_fake:  1.0 probs:  0.9633171\n",
      "p_fake:  0.5363889 probs:  0.9603002\n",
      "p_fake:  0.4474278 probs:  0.95664066\n",
      "p_fake:  1.0 probs:  0.9633004\n",
      "p_fake:  1.0 probs:  0.9628683\n",
      "p_fake:  0.5344343 probs:  0.9663837\n",
      "p_fake:  1.0 probs:  0.9560194\n",
      "p_fake:  1.0 probs:  0.9659961\n",
      "p_fake:  0.33211362 probs:  0.96337867\n",
      "p_fake:  1.0 probs:  0.9630482\n",
      "p_fake:  1.0 probs:  0.96197087\n",
      "p_fake:  1.0 probs:  0.96394557\n",
      "p_fake:  1.0 probs:  0.964464\n",
      "p_fake:  1.0 probs:  0.96167785\n",
      "p_fake:  0.47272095 probs:  0.9571852\n",
      "p_fake:  1.0 probs:  0.96461076\n",
      "p_fake:  1.0 probs:  0.95868975\n",
      "p_fake:  0.4784901 probs:  0.96379906\n",
      "p_fake:  0.51554966 probs:  0.96630925\n",
      "p_fake:  1.0 probs:  0.9635737\n",
      "p_fake:  0.53636163 probs:  0.96348816\n",
      "p_fake:  1.0 probs:  0.96013194\n",
      "p_fake:  0.4940957 probs:  0.96223164\n",
      "p_fake:  1.0 probs:  0.96234137\n",
      "p_fake:  1.0 probs:  0.9567247\n",
      "p_fake:  0.48583904 probs:  0.9619377\n",
      "p_fake:  1.0 probs:  0.9571783\n",
      "p_fake:  1.0 probs:  0.9645343\n",
      "p_fake:  1.0 probs:  0.9617493\n",
      "p_fake:  1.0 probs:  0.9594991\n",
      "p_fake:  1.0 probs:  0.9513903\n",
      "p_fake:  0.48824334 probs:  0.95954615\n",
      "p_fake:  0.5013768 probs:  0.9604397\n",
      "p_fake:  0.50383514 probs:  0.95915765\n",
      "p_fake:  1.0 probs:  0.9580675\n",
      "p_fake:  0.4996146 probs:  0.9578075\n",
      "p_fake:  1.0 probs:  0.96643263\n",
      "p_fake:  1.0 probs:  0.96439743\n",
      "p_fake:  1.0 probs:  0.959132\n",
      "p_fake:  1.0 probs:  0.9698369\n",
      "p_fake:  1.0 probs:  0.95974636\n",
      "p_fake:  0.4973635 probs:  0.956502\n",
      "p_fake:  1.0 probs:  0.9625208\n",
      "p_fake:  1.0 probs:  0.9584083\n",
      "p_fake:  0.50248516 probs:  0.9637626\n",
      "p_fake:  0.50191844 probs:  0.9630266\n",
      "p_fake:  1.0 probs:  0.9649865\n",
      "p_fake:  0.49886197 probs:  0.95884556\n",
      "p_fake:  0.49817467 probs:  0.9619525\n",
      "p_fake:  1.0 probs:  0.95741326\n",
      "p_fake:  0.49949577 probs:  0.958612\n",
      "p_fake:  0.5006677 probs:  0.95542836\n",
      "p_fake:  0.501131 probs:  0.95454997\n",
      "p_fake:  0.50097394 probs:  0.9586986\n",
      "p_fake:  0.50015473 probs:  0.9606711\n",
      "p_fake:  1.0 probs:  0.96016866\n",
      "p_fake:  1.0 probs:  0.9611396\n",
      "p_fake:  1.0 probs:  0.95597917\n",
      "p_fake:  0.49631697 probs:  0.96341723\n",
      "p_fake:  0.4988594 probs:  0.96813196\n",
      "p_fake:  0.5010095 probs:  0.96462196\n",
      "p_fake:  1.0 probs:  0.9625106\n",
      "p_fake:  1.0 probs:  0.9639411\n",
      "p_fake:  0.48162058 probs:  0.96533877\n",
      "p_fake:  1.0 probs:  0.9595635\n",
      "p_fake:  1.0 probs:  0.9613243\n",
      "p_fake:  1.0 probs:  0.95854336\n",
      "p_fake:  1.0 probs:  0.9602874\n",
      "p_fake:  1.0 probs:  0.961793\n",
      "p_fake:  1.0 probs:  0.959506\n",
      "p_fake:  0.46777368 probs:  0.963921\n",
      "p_fake:  0.5082763 probs:  0.95675176\n",
      "p_fake:  0.527632 probs:  0.95652395\n",
      "p_fake:  0.4507251 probs:  0.9575262\n",
      "p_fake:  1.0 probs:  0.9602039\n",
      "p_fake:  0.5004085 probs:  0.95842665\n",
      "p_fake:  1.0 probs:  0.96289223\n",
      "p_fake:  1.0 probs:  0.9615257\n",
      "p_fake:  1.0 probs:  0.96352965\n",
      "p_fake:  1.0 probs:  0.9625047\n",
      "p_fake:  0.59130764 probs:  0.9612921\n",
      "p_fake:  1.0 probs:  0.9671746\n",
      "p_fake:  1.0 probs:  0.9698786\n",
      "p_fake:  0.4425715 probs:  0.96118623\n",
      "p_fake:  0.45858806 probs:  0.9588179\n",
      "p_fake:  1.0 probs:  0.9564457\n",
      "p_fake:  1.0 probs:  0.96385956\n",
      "p_fake:  1.0 probs:  0.9624979\n",
      "p_fake:  0.51126266 probs:  0.96513534\n",
      "p_fake:  1.0 probs:  0.9661184\n",
      "p_fake:  1.0 probs:  0.9639396\n",
      "p_fake:  1.0 probs:  0.96598274\n",
      "p_fake:  0.49719554 probs:  0.9670382\n",
      "p_fake:  0.5039011 probs:  0.9611259\n",
      "p_fake:  0.50821286 probs:  0.96122617\n",
      "p_fake:  1.0 probs:  0.9584442\n",
      "p_fake:  0.49939877 probs:  0.96406144\n",
      "p_fake:  1.0 probs:  0.96033174\n",
      "p_fake:  1.0 probs:  0.9629716\n",
      "p_fake:  1.0 probs:  0.9575116\n",
      "p_fake:  1.0 probs:  0.9563615\n",
      "p_fake:  0.5017186 probs:  0.9610205\n",
      "p_fake:  0.5078966 probs:  0.96152145\n",
      "p_fake:  0.49838877 probs:  0.9633406\n",
      "p_fake:  1.0 probs:  0.9602771\n",
      "p_fake:  1.0 probs:  0.96083903\n",
      "p_fake:  1.0 probs:  0.9581011\n",
      "p_fake:  0.4314226 probs:  0.9546814\n",
      "p_fake:  0.5552689 probs:  0.9496725\n",
      "p_fake:  0.49997714 probs:  0.95474726\n",
      "p_fake:  0.50523597 probs:  0.9594841\n",
      "p_fake:  1.0 probs:  0.9554315\n",
      "p_fake:  1.0 probs:  0.9653818\n",
      "p_fake:  1.0 probs:  0.96085215\n",
      "p_fake:  0.47837654 probs:  0.97022265\n",
      "p_fake:  1.0 probs:  0.962322\n",
      "p_fake:  0.52606183 probs:  0.97050613\n",
      "p_fake:  1.0 probs:  0.9649406\n",
      "p_fake:  1.0 probs:  0.9638374\n",
      "p_fake:  0.5192314 probs:  0.9615357\n",
      "p_fake:  0.53109574 probs:  0.95567423\n",
      "p_fake:  1.0 probs:  0.9522755\n",
      "p_fake:  0.4852471 probs:  0.9611683\n",
      "p_fake:  1.0 probs:  0.9563566\n",
      "p_fake:  1.0 probs:  0.95713305\n",
      "p_fake:  1.0 probs:  0.9642219\n",
      "p_fake:  0.4903077 probs:  0.96287984\n",
      "p_fake:  1.0 probs:  0.9662978\n",
      "p_fake:  1.0 probs:  0.96234506\n",
      "p_fake:  0.49526036 probs:  0.96685404\n",
      "p_fake:  1.0 probs:  0.96714336\n",
      "p_fake:  1.0 probs:  0.9688731\n",
      "p_fake:  0.53770673 probs:  0.95634514\n",
      "p_fake:  1.0 probs:  0.9576604\n",
      "p_fake:  1.0 probs:  0.9632489\n",
      "p_fake:  1.0 probs:  0.9590058\n",
      "p_fake:  1.0 probs:  0.9665273\n",
      "p_fake:  0.43404385 probs:  0.9608105\n",
      "p_fake:  1.0 probs:  0.9625272\n",
      "p_fake:  0.46749976 probs:  0.96423584\n",
      "p_fake:  1.0 probs:  0.9608446\n",
      "p_fake:  0.5209016 probs:  0.9650298\n",
      "p_fake:  0.31214696 probs:  0.9635046\n",
      "p_fake:  0.43039143 probs:  0.96214527\n",
      "p_fake:  1.0 probs:  0.95661426\n",
      "p_fake:  1.0 probs:  0.96439934\n",
      "p_fake:  1.0 probs:  0.96015185\n",
      "p_fake:  0.32113492 probs:  0.960098\n",
      "p_fake:  1.0 probs:  0.9628704\n",
      "p_fake:  1.0 probs:  0.95947653\n",
      "p_fake:  1.0 probs:  0.95825744\n",
      "p_fake:  1.0 probs:  0.96466476\n",
      "p_fake:  1.0 probs:  0.96074134\n",
      "p_fake:  0.36917946 probs:  0.9604097\n",
      "p_fake:  0.38400435 probs:  0.9612374\n",
      "p_fake:  0.5788071 probs:  0.9655187\n",
      "p_fake:  0.15600601 probs:  0.9585629\n",
      "p_fake:  1.0 probs:  0.95935136\n",
      "p_fake:  1.0 probs:  0.9601975\n",
      "p_fake:  1.0 probs:  0.9628944\n",
      "p_fake:  0.4835934 probs:  0.9672072\n",
      "p_fake:  1.0 probs:  0.96031123\n",
      "p_fake:  1.0 probs:  0.9596173\n",
      "p_fake:  1.0 probs:  0.9645238\n",
      "p_fake:  1.0 probs:  0.95798707\n",
      "p_fake:  0.18162741 probs:  0.9572734\n",
      "p_fake:  0.3376997 probs:  0.9530378\n",
      "p_fake:  0.18918805 probs:  0.9509217\n",
      "p_fake:  1.0 probs:  0.9665243\n",
      "p_fake:  1.0 probs:  0.959394\n",
      "p_fake:  1.0 probs:  0.9607265\n",
      "p_fake:  0.1562468 probs:  0.9598716\n",
      "p_fake:  1.0 probs:  0.9683294\n",
      "p_fake:  0.19774401 probs:  0.96291786\n",
      "p_fake:  1.0 probs:  0.96260744\n",
      "p_fake:  0.23050228 probs:  0.96180373\n",
      "p_fake:  1.0 probs:  0.9655807\n",
      "p_fake:  0.3540474 probs:  0.9633846\n",
      "p_fake:  1.0 probs:  0.9583406\n",
      "p_fake:  1.0 probs:  0.96124357\n",
      "p_fake:  0.17697762 probs:  0.9594671\n",
      "p_fake:  1.0 probs:  0.96369624\n",
      "p_fake:  1.0 probs:  0.95884484\n",
      "p_fake:  1.0 probs:  0.9606933\n",
      "p_fake:  0.2293833 probs:  0.9615075\n",
      "p_fake:  0.29463664 probs:  0.96964884\n",
      "p_fake:  0.17493957 probs:  0.96119684\n",
      "p_fake:  0.4905279 probs:  0.9665212\n",
      "p_fake:  0.39926097 probs:  0.96436095\n",
      "p_fake:  0.14165255 probs:  0.9633283\n",
      "p_fake:  0.18971895 probs:  0.96489716\n",
      "p_fake:  0.4018885 probs:  0.96329576\n",
      "p_fake:  0.32008317 probs:  0.9701275\n",
      "p_fake:  1.0 probs:  0.96830565\n",
      "p_fake:  1.0 probs:  0.95769805\n",
      "p_fake:  1.0 probs:  0.96286505\n",
      "p_fake:  0.24742272 probs:  0.95485646\n",
      "p_fake:  0.44887802 probs:  0.9582421\n",
      "p_fake:  0.3872072 probs:  0.9599537\n",
      "p_fake:  0.20795181 probs:  0.95361733\n",
      "p_fake:  1.0 probs:  0.9561915\n",
      "p_fake:  1.0 probs:  0.95639396\n",
      "p_fake:  1.0 probs:  0.96979904\n",
      "p_fake:  0.19251092 probs:  0.96896344\n",
      "p_fake:  0.57956326 probs:  0.978883\n",
      "p_fake:  0.3641579 probs:  0.971603\n",
      "p_fake:  0.4051624 probs:  0.9699969\n",
      "p_fake:  0.3924011 probs:  0.9768128\n",
      "p_fake:  1.0 probs:  0.97187066\n",
      "p_fake:  0.59194195 probs:  0.9777069\n",
      "p_fake:  0.45445922 probs:  0.9689365\n",
      "p_fake:  0.42484045 probs:  0.9623659\n",
      "p_fake:  1.0 probs:  0.9575674\n",
      "p_fake:  0.24997687 probs:  0.95289946\n",
      "p_fake:  0.28949663 probs:  0.94914335\n",
      "p_fake:  0.36680457 probs:  0.94998974\n",
      "p_fake:  1.0 probs:  0.95096445\n",
      "p_fake:  0.17812112 probs:  0.9475176\n",
      "p_fake:  1.0 probs:  0.95890397\n",
      "p_fake:  1.0 probs:  0.95691156\n",
      "p_fake:  1.0 probs:  0.96200323\n",
      "p_fake:  0.07237378 probs:  0.95951533\n",
      "p_fake:  0.17270595 probs:  0.9670012\n",
      "p_fake:  0.67448616 probs:  0.96954507\n",
      "p_fake:  0.22366944 probs:  0.9709072\n",
      "p_fake:  1.0 probs:  0.96674013\n",
      "p_fake:  0.35433602 probs:  0.96820515\n",
      "p_fake:  0.20022586 probs:  0.9655221\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p_fake:  1.0 probs:  0.9674194\n",
      "p_fake:  0.20870277 probs:  0.96108294\n",
      "p_fake:  0.21700472 probs:  0.9596698\n",
      "p_fake:  0.124774516 probs:  0.95564705\n",
      "p_fake:  0.16451548 probs:  0.95132023\n",
      "p_fake:  0.22780545 probs:  0.9495106\n",
      "p_fake:  1.0 probs:  0.9545961\n",
      "p_fake:  1.0 probs:  0.9630353\n",
      "p_fake:  0.40742064 probs:  0.959686\n",
      "p_fake:  0.6027678 probs:  0.96778744\n",
      "p_fake:  1.0 probs:  0.96700245\n",
      "p_fake:  1.0 probs:  0.96886975\n",
      "p_fake:  0.1159464 probs:  0.9698475\n",
      "p_fake:  0.2587717 probs:  0.96550703\n",
      "p_fake:  0.58957154 probs:  0.96744055\n",
      "p_fake:  1.0 probs:  0.9589786\n",
      "p_fake:  1.0 probs:  0.9576362\n",
      "p_fake:  1.0 probs:  0.96061724\n",
      "p_fake:  1.0 probs:  0.9644912\n",
      "p_fake:  0.3861859 probs:  0.95882577\n",
      "p_fake:  0.28675038 probs:  0.96037906\n",
      "p_fake:  1.0 probs:  0.9623673\n",
      "p_fake:  1.0 probs:  0.9621697\n",
      "p_fake:  1.0 probs:  0.96067715\n",
      "p_fake:  1.0 probs:  0.96269196\n",
      "p_fake:  0.12342189 probs:  0.955981\n",
      "p_fake:  0.13615237 probs:  0.95712703\n",
      "p_fake:  0.18494067 probs:  0.9563894\n",
      "p_fake:  0.16078918 probs:  0.95705837\n",
      "p_fake:  1.0 probs:  0.9556544\n",
      "p_fake:  0.13950713 probs:  0.9532071\n",
      "p_fake:  0.24729146 probs:  0.96478266\n",
      "p_fake:  0.14344664 probs:  0.95857924\n",
      "p_fake:  1.0 probs:  0.9616883\n",
      "p_fake:  0.33278942 probs:  0.9642537\n",
      "p_fake:  1.0 probs:  0.9677684\n",
      "p_fake:  1.0 probs:  0.9642622\n",
      "p_fake:  0.14018573 probs:  0.9619367\n",
      "p_fake:  1.0 probs:  0.9593572\n",
      "p_fake:  1.0 probs:  0.9603606\n",
      "p_fake:  1.0 probs:  0.9573145\n",
      "p_fake:  0.16914275 probs:  0.9585033\n",
      "p_fake:  0.13512726 probs:  0.9603849\n",
      "p_fake:  1.0 probs:  0.9631288\n",
      "p_fake:  1.0 probs:  0.9563803\n",
      "p_fake:  1.0 probs:  0.96354216\n",
      "p_fake:  1.0 probs:  0.96107316\n",
      "p_fake:  0.29332855 probs:  0.95971376\n",
      "p_fake:  0.2915025 probs:  0.9562296\n",
      "p_fake:  1.0 probs:  0.9597955\n",
      "p_fake:  0.18545648 probs:  0.95607215\n",
      "p_fake:  1.0 probs:  0.9640427\n",
      "p_fake:  0.27544647 probs:  0.96859264\n",
      "p_fake:  1.0 probs:  0.9608793\n",
      "p_fake:  1.0 probs:  0.95892525\n",
      "p_fake:  0.088227876 probs:  0.96043134\n",
      "p_fake:  1.0 probs:  0.9660216\n",
      "p_fake:  1.0 probs:  0.96622115\n",
      "p_fake:  1.0 probs:  0.95726293\n",
      "p_fake:  1.0 probs:  0.96223515\n",
      "p_fake:  0.17929319 probs:  0.9597376\n",
      "p_fake:  0.07935268 probs:  0.9595671\n",
      "p_fake:  1.0 probs:  0.96053267\n",
      "p_fake:  1.0 probs:  0.96195817\n",
      "p_fake:  1.0 probs:  0.9623129\n",
      "p_fake:  1.0 probs:  0.963336\n",
      "p_fake:  1.0 probs:  0.95991546\n",
      "p_fake:  1.0 probs:  0.96220976\n",
      "p_fake:  0.29807174 probs:  0.96140283\n",
      "p_fake:  0.10473478 probs:  0.9593187\n",
      "p_fake:  0.25617465 probs:  0.9592418\n",
      "p_fake:  1.0 probs:  0.965213\n",
      "p_fake:  1.0 probs:  0.9632419\n",
      "p_fake:  1.0 probs:  0.9644172\n",
      "p_fake:  0.13862832 probs:  0.964997\n",
      "p_fake:  1.0 probs:  0.96119314\n",
      "p_fake:  0.20708796 probs:  0.9678983\n",
      "p_fake:  0.289058 probs:  0.96878743\n",
      "p_fake:  0.20492126 probs:  0.9641486\n",
      "p_fake:  0.17009486 probs:  0.96233195\n",
      "p_fake:  0.22747439 probs:  0.96353346\n",
      "p_fake:  1.0 probs:  0.9595881\n",
      "p_fake:  0.269377 probs:  0.96124214\n",
      "p_fake:  0.28536755 probs:  0.964477\n",
      "p_fake:  1.0 probs:  0.9620114\n",
      "p_fake:  0.20469141 probs:  0.9679487\n",
      "p_fake:  0.10949527 probs:  0.9622852\n",
      "p_fake:  0.18034942 probs:  0.96105504\n",
      "p_fake:  0.28964496 probs:  0.9635063\n",
      "p_fake:  1.0 probs:  0.96315724\n",
      "p_fake:  1.0 probs:  0.9601693\n",
      "p_fake:  1.0 probs:  0.9600439\n",
      "p_fake:  1.0 probs:  0.9606128\n",
      "p_fake:  1.0 probs:  0.9576041\n",
      "p_fake:  0.16889012 probs:  0.96524495\n",
      "p_fake:  0.21120505 probs:  0.96257216\n",
      "p_fake:  0.39005345 probs:  0.95827675\n",
      "p_fake:  0.122548744 probs:  0.9560227\n",
      "p_fake:  0.0938302 probs:  0.95999914\n",
      "p_fake:  0.035958182 probs:  0.9536167\n",
      "p_fake:  0.11547971 probs:  0.96357775\n",
      "p_fake:  0.07196261 probs:  0.9575069\n",
      "p_fake:  1.0 probs:  0.9538007\n",
      "p_fake:  1.0 probs:  0.95199853\n",
      "p_fake:  1.0 probs:  0.96609235\n",
      "p_fake:  0.07106676 probs:  0.96288687\n",
      "p_fake:  1.0 probs:  0.96449465\n",
      "p_fake:  0.5567694 probs:  0.9652038\n",
      "p_fake:  1.0 probs:  0.9615946\n",
      "p_fake:  1.0 probs:  0.96380234\n",
      "p_fake:  1.0 probs:  0.9681849\n",
      "p_fake:  1.0 probs:  0.9623578\n",
      "p_fake:  1.0 probs:  0.96901864\n",
      "p_fake:  0.3599127 probs:  0.96490765\n",
      "p_fake:  0.1591121 probs:  0.96702784\n",
      "p_fake:  1.0 probs:  0.9608648\n",
      "p_fake:  1.0 probs:  0.96089745\n",
      "p_fake:  0.36987066 probs:  0.96125865\n",
      "p_fake:  1.0 probs:  0.9553318\n",
      "p_fake:  1.0 probs:  0.9543039\n",
      "p_fake:  1.0 probs:  0.95914084\n",
      "p_fake:  1.0 probs:  0.96311384\n",
      "p_fake:  0.183729 probs:  0.9655742\n",
      "p_fake:  0.24084516 probs:  0.9678707\n",
      "p_fake:  1.0 probs:  0.96211964\n",
      "p_fake:  1.0 probs:  0.96421885\n",
      "p_fake:  1.0 probs:  0.96043867\n",
      "p_fake:  1.0 probs:  0.9539365\n",
      "p_fake:  0.12659544 probs:  0.94758886\n",
      "p_fake:  1.0 probs:  0.9500506\n",
      "p_fake:  0.1441869 probs:  0.95319754\n",
      "p_fake:  0.095970966 probs:  0.9517521\n",
      "p_fake:  0.27609554 probs:  0.95760053\n",
      "p_fake:  0.085875854 probs:  0.95105666\n",
      "p_fake:  0.20332396 probs:  0.95848745\n",
      "p_fake:  0.18916355 probs:  0.9605112\n",
      "p_fake:  1.0 probs:  0.9677363\n",
      "p_fake:  1.0 probs:  0.9592009\n",
      "p_fake:  1.0 probs:  0.9606783\n",
      "p_fake:  0.053057425 probs:  0.95892483\n",
      "p_fake:  1.0 probs:  0.9635245\n",
      "p_fake:  1.0 probs:  0.9637696\n",
      "p_fake:  0.17333157 probs:  0.95655745\n",
      "p_fake:  1.0 probs:  0.9641296\n",
      "p_fake:  0.23644124 probs:  0.962456\n",
      "p_fake:  1.0 probs:  0.9621646\n",
      "p_fake:  1.0 probs:  0.95911455\n",
      "p_fake:  0.1521695 probs:  0.9651508\n",
      "p_fake:  0.33015794 probs:  0.97465664\n",
      "p_fake:  1.0 probs:  0.9623098\n",
      "p_fake:  1.0 probs:  0.96888804\n",
      "p_fake:  1.0 probs:  0.96066713\n",
      "p_fake:  1.0 probs:  0.96177983\n",
      "p_fake:  1.0 probs:  0.95897174\n",
      "p_fake:  0.15538359 probs:  0.96107596\n",
      "p_fake:  0.16166876 probs:  0.95790917\n",
      "p_fake:  1.0 probs:  0.9597612\n",
      "p_fake:  1.0 probs:  0.95882607\n",
      "p_fake:  1.0 probs:  0.9690652\n",
      "p_fake:  0.516632 probs:  0.96721005\n",
      "p_fake:  0.5246796 probs:  0.9682618\n",
      "p_fake:  0.15543434 probs:  0.97369546\n",
      "p_fake:  1.0 probs:  0.96221924\n",
      "p_fake:  0.24086526 probs:  0.9714153\n",
      "p_fake:  1.0 probs:  0.9629255\n",
      "p_fake:  0.16778013 probs:  0.9631856\n",
      "p_fake:  1.0 probs:  0.9570062\n",
      "p_fake:  0.056913313 probs:  0.95310086\n",
      "p_fake:  0.21055067 probs:  0.9530317\n",
      "p_fake:  1.0 probs:  0.95411825\n",
      "p_fake:  0.21743874 probs:  0.9519567\n",
      "p_fake:  1.0 probs:  0.96302676\n",
      "p_fake:  1.0 probs:  0.96170574\n",
      "p_fake:  0.0900175 probs:  0.96631813\n",
      "p_fake:  1.0 probs:  0.9640336\n",
      "p_fake:  1.0 probs:  0.96661896\n",
      "p_fake:  0.23538417 probs:  0.9691615\n",
      "p_fake:  1.0 probs:  0.96648914\n",
      "p_fake:  1.0 probs:  0.9683346\n",
      "p_fake:  1.0 probs:  0.95737386\n",
      "p_fake:  1.0 probs:  0.96485394\n",
      "p_fake:  0.17653914 probs:  0.9569283\n",
      "p_fake:  1.0 probs:  0.96748906\n",
      "p_fake:  1.0 probs:  0.96416926\n",
      "p_fake:  0.04852172 probs:  0.96433467\n",
      "p_fake:  1.0 probs:  0.96939665\n",
      "p_fake:  0.0478345 probs:  0.9665065\n",
      "p_fake:  0.12621221 probs:  0.9604544\n",
      "p_fake:  0.22101149 probs:  0.964588\n",
      "p_fake:  1.0 probs:  0.9657867\n",
      "p_fake:  0.07323882 probs:  0.963666\n",
      "p_fake:  0.30762854 probs:  0.9648084\n",
      "p_fake:  0.46572876 probs:  0.964031\n",
      "p_fake:  1.0 probs:  0.9646268\n",
      "p_fake:  0.14357853 probs:  0.9579482\n",
      "p_fake:  0.15205161 probs:  0.9646768\n",
      "p_fake:  0.023492748 probs:  0.9604462\n",
      "p_fake:  0.022620432 probs:  0.9598978\n",
      "p_fake:  0.41117865 probs:  0.9613134\n",
      "p_fake:  0.41292638 probs:  0.96408206\n",
      "p_fake:  0.0969788 probs:  0.9606518\n",
      "p_fake:  1.0 probs:  0.956536\n",
      "p_fake:  1.0 probs:  0.9578642\n",
      "p_fake:  1.0 probs:  0.9576683\n",
      "p_fake:  0.14198878 probs:  0.957987\n",
      "p_fake:  1.0 probs:  0.96168876\n",
      "p_fake:  1.0 probs:  0.96000695\n",
      "p_fake:  0.21601337 probs:  0.964547\n",
      "p_fake:  1.0 probs:  0.95500946\n",
      "p_fake:  0.17135409 probs:  0.959528\n",
      "p_fake:  0.08571291 probs:  0.9595497\n",
      "p_fake:  1.0 probs:  0.9674368\n",
      "p_fake:  0.14409249 probs:  0.9620649\n",
      "p_fake:  1.0 probs:  0.9604204\n",
      "p_fake:  1.0 probs:  0.96087956\n",
      "p_fake:  0.07125327 probs:  0.9629012\n",
      "p_fake:  1.0 probs:  0.9585464\n",
      "p_fake:  1.0 probs:  0.9638273\n",
      "p_fake:  0.18866006 probs:  0.9613857\n",
      "p_fake:  0.118178114 probs:  0.9622285\n",
      "p_fake:  0.310502 probs:  0.96561044\n",
      "p_fake:  0.08189173 probs:  0.96212953\n",
      "p_fake:  1.0 probs:  0.96151227\n",
      "p_fake:  0.17403144 probs:  0.9610898\n",
      "p_fake:  1.0 probs:  0.96195936\n",
      "p_fake:  0.20132926 probs:  0.9594221\n",
      "p_fake:  0.16727462 probs:  0.96041375\n",
      "p_fake:  1.0 probs:  0.968671\n",
      "p_fake:  0.12053126 probs:  0.9622945\n",
      "p_fake:  0.124002114 probs:  0.9664557\n",
      "p_fake:  1.0 probs:  0.96352977\n",
      "p_fake:  1.0 probs:  0.9570713\n",
      "p_fake:  1.0 probs:  0.96266407\n",
      "p_fake:  0.03135321 probs:  0.95879763\n",
      "p_fake:  1.0 probs:  0.9588699\n",
      "p_fake:  0.16571602 probs:  0.9631761\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p_fake:  0.08201542 probs:  0.9557516\n",
      "p_fake:  1.0 probs:  0.95987135\n",
      "p_fake:  1.0 probs:  0.95871687\n",
      "p_fake:  1.0 probs:  0.960227\n",
      "p_fake:  1.0 probs:  0.96020955\n",
      "p_fake:  0.20204486 probs:  0.96791106\n",
      "p_fake:  1.0 probs:  0.95943874\n",
      "p_fake:  0.07783362 probs:  0.962243\n",
      "p_fake:  0.07887547 probs:  0.96091276\n",
      "p_fake:  1.0 probs:  0.95983905\n",
      "p_fake:  0.20061512 probs:  0.9645068\n",
      "p_fake:  1.0 probs:  0.966943\n",
      "p_fake:  0.14012812 probs:  0.96251374\n",
      "p_fake:  0.11844156 probs:  0.95687675\n",
      "p_fake:  1.0 probs:  0.9655109\n",
      "p_fake:  1.0 probs:  0.95989084\n",
      "p_fake:  1.0 probs:  0.9590568\n",
      "p_fake:  0.1812376 probs:  0.95981556\n",
      "p_fake:  1.0 probs:  0.9524057\n",
      "p_fake:  1.0 probs:  0.9593325\n",
      "p_fake:  1.0 probs:  0.95939183\n",
      "p_fake:  1.0 probs:  0.9619481\n",
      "p_fake:  1.0 probs:  0.9614272\n",
      "p_fake:  0.092997745 probs:  0.9616344\n",
      "p_fake:  1.0 probs:  0.96174246\n",
      "p_fake:  1.0 probs:  0.968659\n",
      "p_fake:  0.109792136 probs:  0.9625507\n",
      "p_fake:  0.053113714 probs:  0.9570138\n",
      "p_fake:  1.0 probs:  0.95867366\n",
      "p_fake:  0.11710408 probs:  0.9572962\n",
      "p_fake:  1.0 probs:  0.96481186\n",
      "p_fake:  0.12373596 probs:  0.96274686\n",
      "p_fake:  1.0 probs:  0.95561963\n",
      "p_fake:  0.26246983 probs:  0.95923215\n",
      "p_fake:  0.07502085 probs:  0.95619106\n",
      "p_fake:  1.0 probs:  0.9641912\n",
      "p_fake:  0.052741494 probs:  0.9598878\n",
      "p_fake:  0.08033984 probs:  0.95259804\n",
      "p_fake:  1.0 probs:  0.96105367\n",
      "p_fake:  1.0 probs:  0.96321774\n",
      "p_fake:  0.2109806 probs:  0.9668881\n",
      "p_fake:  1.0 probs:  0.9691395\n",
      "p_fake:  1.0 probs:  0.9643829\n",
      "p_fake:  0.27653334 probs:  0.9662661\n",
      "p_fake:  0.07312537 probs:  0.95979786\n",
      "p_fake:  0.093316026 probs:  0.96296924\n",
      "p_fake:  1.0 probs:  0.9586089\n",
      "p_fake:  0.1571149 probs:  0.9662698\n",
      "p_fake:  1.0 probs:  0.95582753\n",
      "p_fake:  0.10851469 probs:  0.9612116\n",
      "p_fake:  0.14986753 probs:  0.96257687\n",
      "p_fake:  1.0 probs:  0.96592885\n",
      "p_fake:  0.1988881 probs:  0.96691275\n",
      "p_fake:  1.0 probs:  0.9622192\n",
      "p_fake:  0.14618675 probs:  0.95802575\n",
      "p_fake:  0.10877735 probs:  0.953527\n",
      "p_fake:  0.026565932 probs:  0.95596665\n",
      "p_fake:  1.0 probs:  0.95725584\n",
      "p_fake:  1.0 probs:  0.9603872\n",
      "p_fake:  0.0139673855 probs:  0.9553817\n",
      "p_fake:  1.0 probs:  0.9660878\n",
      "p_fake:  0.12901287 probs:  0.9647451\n",
      "p_fake:  1.0 probs:  0.97161436\n",
      "p_fake:  1.0 probs:  0.96477145\n",
      "p_fake:  1.0 probs:  0.9627266\n",
      "p_fake:  0.17309266 probs:  0.9660695\n",
      "p_fake:  0.16395043 probs:  0.9579794\n",
      "p_fake:  1.0 probs:  0.9602931\n",
      "p_fake:  1.0 probs:  0.95603853\n",
      "p_fake:  0.16729458 probs:  0.96549416\n",
      "p_fake:  0.0862454 probs:  0.9683421\n",
      "p_fake:  1.0 probs:  0.967406\n",
      "p_fake:  1.0 probs:  0.96571916\n",
      "p_fake:  1.0 probs:  0.96016353\n",
      "p_fake:  0.1930205 probs:  0.9620385\n",
      "p_fake:  0.07689105 probs:  0.95311\n",
      "p_fake:  1.0 probs:  0.9525017\n",
      "p_fake:  1.0 probs:  0.95326823\n",
      "p_fake:  0.108011045 probs:  0.95780486\n",
      "p_fake:  0.20597124 probs:  0.96676093\n",
      "p_fake:  1.0 probs:  0.9654842\n",
      "p_fake:  0.29539388 probs:  0.9768335\n",
      "p_fake:  1.0 probs:  0.9652925\n",
      "p_fake:  0.07497792 probs:  0.9678773\n",
      "p_fake:  1.0 probs:  0.9661031\n",
      "p_fake:  1.0 probs:  0.96701413\n",
      "p_fake:  1.0 probs:  0.95966405\n",
      "p_fake:  0.25310034 probs:  0.95762855\n",
      "p_fake:  0.11767958 probs:  0.9514951\n",
      "p_fake:  0.017242473 probs:  0.94951415\n",
      "p_fake:  0.022801219 probs:  0.9471459\n",
      "p_fake:  0.016555872 probs:  0.9467049\n",
      "p_fake:  1.0 probs:  0.952764\n",
      "p_fake:  0.07609047 probs:  0.9515156\n",
      "p_fake:  0.014564605 probs:  0.95320505\n",
      "p_fake:  0.019173488 probs:  0.9601557\n",
      "p_fake:  0.09955629 probs:  0.96002865\n",
      "p_fake:  1.0 probs:  0.9658162\n",
      "p_fake:  1.0 probs:  0.9618538\n",
      "p_fake:  1.0 probs:  0.9621313\n",
      "p_fake:  0.08262549 probs:  0.96138\n",
      "p_fake:  0.20210697 probs:  0.96206236\n",
      "p_fake:  1.0 probs:  0.9580874\n",
      "p_fake:  0.1604987 probs:  0.9623924\n",
      "p_fake:  0.01514142 probs:  0.9540852\n",
      "p_fake:  1.0 probs:  0.9618806\n",
      "p_fake:  1.0 probs:  0.9653869\n",
      "p_fake:  1.0 probs:  0.9664677\n",
      "p_fake:  0.02728269 probs:  0.96250033\n",
      "p_fake:  1.0 probs:  0.9623795\n",
      "p_fake:  0.11390248 probs:  0.96580076\n",
      "p_fake:  0.29187322 probs:  0.96507335\n",
      "p_fake:  1.0 probs:  0.9610455\n",
      "p_fake:  1.0 probs:  0.9621505\n",
      "p_fake:  1.0 probs:  0.9621344\n",
      "p_fake:  0.014052902 probs:  0.9590543\n",
      "p_fake:  1.0 probs:  0.9640891\n",
      "p_fake:  1.0 probs:  0.95608634\n",
      "p_fake:  0.05365568 probs:  0.954614\n",
      "p_fake:  0.23111542 probs:  0.9653864\n",
      "p_fake:  1.0 probs:  0.9616461\n",
      "p_fake:  1.0 probs:  0.96523696\n",
      "p_fake:  0.03857885 probs:  0.9602256\n",
      "p_fake:  0.098263636 probs:  0.9651041\n",
      "p_fake:  1.0 probs:  0.96277577\n",
      "p_fake:  1.0 probs:  0.96101326\n",
      "p_fake:  1.0 probs:  0.96040034\n",
      "p_fake:  0.13649498 probs:  0.9612076\n",
      "p_fake:  1.0 probs:  0.9581904\n",
      "p_fake:  1.0 probs:  0.95901805\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-30-0c8868b985a8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mbaseline\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLSTM_baseline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m300\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0;31m#discriminator = BasicDiscriminator(last_dim=6).cuda()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m     \u001b[0mgenerator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdiscriminator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbaseline\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mg_losses\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0md_losses\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbl_losses\u001b[0m \u001b[0;34m=\u001b[0m                    \u001b[0mtrain_GAN\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgenerator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdiscriminator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbaseline\u001b[0m\u001b[0;34m,\u001b[0m                            \u001b[0mX_loader\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnum_epochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mg_lr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m1e-3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0md_lr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m1e-2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbl_lr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m1e-4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-29-d15f6898449d>\u001b[0m in \u001b[0;36mtrain_GAN\u001b[0;34m(generator, discriminator, baseline, X_loader, num_epochs, g_lr, d_lr, bl_lr)\u001b[0m\n\u001b[1;32m     75\u001b[0m     \u001b[0;31m#             print(loss.grad)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m                 \u001b[0mg_optimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 77\u001b[0;31m                 \u001b[0mg_losses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     78\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mgenerator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdiscriminator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbaseline\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mg_losses\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md_losses\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbl_losses\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "GPU = 2\n",
    "with torch.cuda.device(GPU):\n",
    "    # device = torch.device(\"cuda:6\" if torch.cuda.is_available() else \"cpu\")\n",
    "    #device = torch.device(\"cpu\")\n",
    "    generator = Generator().cuda()\n",
    "    # generator.load_state_dict(torch.load(os.path.join(OUT_DIR, 'model_canonical')))\n",
    "    generator.load_state_dict(torch.load(os.path.join(OUT_DIR, 'model_canonical')))\n",
    "    discriminator = LSTM_discriminator(hidden_size=300,last_dim=6).cuda()\n",
    "#     # generator = BasicGenerator().cuda()\n",
    "    baseline = LSTM_baseline(hidden_size=300).cuda()\n",
    "    #discriminator = BasicDiscriminator(last_dim=6).cuda()\n",
    "    generator,discriminator,baseline,g_losses,d_losses,bl_losses =\\\n",
    "                    train_GAN(generator,discriminator,baseline,\\\n",
    "                            X_loader,num_epochs = 100, g_lr = 1*1e-3,d_lr=1*1e-2, bl_lr = 1*1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD8CAYAAACMwORRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvhp/UCwAAIABJREFUeJzt3Xd8VFXaB/DfkxACCFKj0jSAKJ2AwYYF24plZVfxFXVVbLys8rrqvqvhXUVwdQV1LQiri4WirlJkEQxFem9JCDWU0ENLSEhCSE+e94+5k0yfOzN35pZ5vp9PPpm5c+feZ+7MPHPuOeeeQ8wMIYQQ1hKjdwBCCCG0J8ldCCEsSJK7EEJYkCR3IYSwIEnuQghhQZLchRDCgiS5CyGEBUlyF0IIC5LkLoQQFtRArx23adOGExMT9dq9EEKYUnp6+llmTvC3nm7JPTExEWlpaXrtXgghTImIjqpZT6plhBDCgiS5CyGEBUlyF0IIC9Ktzt2Tqqoq5OTkoLy8XO9QRIQ0atQIHTp0QFxcnN6hCGEphkruOTk5aNasGRITE0FEeocjwoyZkZ+fj5ycHHTq1EnvcISwFENVy5SXl6N169aS2KMEEaF169ZypiZEGBgquQOQxB5l5P0WIjwMl9yFEOHxc+YJFJdX6R2GiBBJ7i5iY2ORlJSEnj17om/fvvjHP/6B2tpaAEBaWhpeeumlkPfxxRdfYMaMGQE958Ybbwx6f9OmTcPJkyeDfj4AjB07Fh9++GFI2xD62Xf6PP70YyZem71D71BEhBiqQdUIGjdujMzMTABAbm4uHnvsMRQXF2PcuHFITk5GcnJySNuvrq7GyJEjA37ehg0bgt7ntGnT0KtXL7Rr1071c2pqahAbGxv0PoWxlFZWAwBOFUv7RrSQkrsPl1xyCaZMmYJJkyaBmbFq1Srcf//9AIDVq1cjKSkJSUlJ6NevH86fPw8AmDBhAnr37o2+ffsiJSUFADBo0CC8/PLLSE5OxqeffupUCh40aBBeeeUVJCcno3v37ti6dSsefPBBdO3aFW+88UZdLE2bNgUArFq1CoMGDcLQoUPRrVs3PP7442BmAMDbb7+NAQMGoFevXhgxYgSYGXPmzEFaWhoef/xxJCUloaysDMuXL0e/fv3Qu3dvPPPMM6ioqABgGxLi9ddfR//+/TF79myvxyUzMxPXX389+vTpg9///vc4d+4cAGDixIno0aMH+vTpg2HDhvk8TkKI8DJsyX3cgt3Yc7JY0232aHcx3vptz4Ce07lzZ9TU1CA3N9dp+YcffojJkydj4MCBKCkpQaNGjbBo0SL8/PPP2Lx5M5o0aYKCgoK69SsrK+vG0hk7dqzTtho2bIi0tDR8+umnGDJkCNLT09GqVSt06dIFr7zyClq3bu20/rZt27B79260a9cOAwcOxPr163HTTTdh1KhRGDNmDADgiSeewC+//IKhQ4di0qRJ+PDDD5GcnIzy8nIMHz4cy5cvx1VXXYUnn3wSn3/+OV5++WUAQOvWrZGRkeHzmDz55JP47LPPcOutt2LMmDEYN24cPvnkE4wfPx6HDx9GfHw8CgsLvR4nIUT4Sck9SAMHDsSrr76KiRMnorCwEA0aNMCyZcvw9NNPo0mTJgCAVq1a1a3/yCOPeN3WAw88AADo3bs3evbsibZt2yI+Ph6dO3fG8ePH3da/9tpr0aFDB8TExCApKQlHjhwBAKxcuRLXXXcdevfujRUrVmD37t1uz923bx86deqEq666CgDw1FNPYc2aNariBICioiIUFhbi1ltvdXt+nz598Pjjj+O7775DgwYNvB4nIUT4GfabFmgJO1wOHTqE2NhYXHLJJcjKyqpbnpKSgvvuuw8LFy7EwIEDsWTJEp/bueiii7w+Fh8fDwCIiYmpu22/X11d7XV9wNYAXF1djfLycrzwwgtIS0tDx44dMXbs2KD6j/uK05/U1FSsWbMGCxYswLvvvoudO3d6PE7dunULeh9CCHWk5O5DXl4eRo4ciVGjRrn1xz548CB69+6N119/HQMGDMDevXtx1113YerUqSgtLQUAp2qZcLMn8jZt2qCkpARz5sype6xZs2Z1dd1XX301jhw5guzsbADAt99+W1cKV6N58+Zo2bIl1q5d6/T82tpaHD9+HLfddhsmTJiAoqIilJSUeDxOQkdK+4ywPsOW3PVSVlaGpKQkVFVVoUGDBnjiiSfw6quvuq33ySefYOXKlYiJiUHPnj1xzz33ID4+HpmZmUhOTkbDhg1x77334u9//3tE4m7RogWef/559OrVC5dddhkGDBhQ99jw4cMxcuRING7cGBs3bsTUqVPx8MMPo7q6GgMGDAi498706dMxcuRIlJaWonPnzpg6dSpqamrwhz/8AUVFRWBmvPTSS2jRogXefPNNt+MkIk8uFos+xDr9kicnJ7PrZB1ZWVno3r27LvEI/cj7Hn6Zxwvxu8nr0bdDc/w86ia9wxEhIKJ0ZvbbJ1uqZYQQwoIkuQshhAX5Te5E1IiIthDRdiLaTUTjPKwznIjyiChT+Xsu2ID0qiYS+pD3W4jwUNOgWgHgdmYuIaI4AOuIaBEzb3JZbyYzjwolmEaNGiE/P1+G/Y0S9vHc5cImIbTnN7mzrWhVotyNU/7CUtzq0KEDcnJykJeXF47NCwOyz8QkIkPOk6KHqq6QRBQLIB3AlQAmM/NmD6s9RES3ANgP4BVmdr+00o+4uDiZkUeIMJDz4OijqkGVmWuYOQlABwDXElEvl1UWAEhk5j4AlgKY7mk7RDSCiNKIKE1K50IIET4B9ZZh5kIAKwEMdlmez8wVyt2vAFzj5flTmDmZmZMTEhKCiVcIIYQKanrLJBBRC+V2YwB3Adjrsk5bh7sPAMiCEEII3aipc28LYLpS7x4DYBYz/0JEbwNIY+b5AF4iogcAVAMoADA8XAELIYTwT01vmR0A+nlYPsbh9mgAo7UNTQghRLDkClUhoohcMxY9JLkLEQXkmsDoI8ldCCEsSJK7EEJYkCR3IYSwIEnuISivqkFtrbRQCSGMR5J7kGprGd3eXIy35u/WOxQhVGMZOixqSHIPUo3Sp+yHLcd0jkQI/0iGDos6ktyFEMKCJLkLIYQFSXIXQggLkuQuhBAWJMldCCEsSJK7EFFEBg6LHpLcgyRfEmEmMnBY9JHkHiL50gghjEiSuxBCWJCaOVQbEdEWItpORLuJaJyHdeKJaCYRZRPRZiJKDEew3izPOoNZaccjuUshhDA0NXOoVgC4nZlLiCgOwDoiWsTMmxzWeRbAOWa+koiGAZgA4JEwxOvRs9PTAAD/ldwxUrusI3XvQggj8ltyZ5sS5W6c8uea0oYAmK7cngPgDiJr10Zb+9UJIcxOVZ07EcUSUSaAXABLmXmzyyrtARwHAGauBlAEoLWWgQohhFBPVXJn5hpmTgLQAcC1RNQrmJ0R0QgiSiOitLy8vGA2IYQQQoWAesswcyGAlQAGuzx0AkBHACCiBgCaA8j38PwpzJzMzMkJCQnBRWwQUtcuhDAyNb1lEoiohXK7MYC7AOx1WW0+gKeU20MBrGCOjvQnde9CCCNS01umLYDpRBQL24/BLGb+hYjeBpDGzPMBfA3gWyLKBlAAYFjYIhZCCOGX3+TOzDsA9POwfIzD7XIAD2sbmhBCiGDJFapCRJHoqCwVgCR3IYSwJEnuQghhQZLcQySnuUIII5LkLoQQFiTJPUTSz10IYUSS3IWIIlKLGD0kuQsRBeQMM/pIchdCCAuS5C6EEBYkyV0IISxIknuQWJqmhBAGJsk9RARpqRJCGI8kdyGiSJRMsyAgyT1kUj0jzEDOMKOPJHchhLAgSe5CCGFBauZQ7UhEK4loDxHtJqI/eVhnEBEVEVGm8jfG07aEEEJEhpo5VKsB/JmZM4ioGYB0IlrKzHtc1lvLzPdrH6IQQohA+S25M/MpZs5Qbp8HkAWgfbgD86eiugbLs87otn/pdCCEMLKA6tyJKBG2ybI3e3j4BiLaTkSLiKinBrH59N7CvXh2ehrSjxaEe1c+SS8EIYQRqamWAQAQUVMAPwF4mZmLXR7OAHAFM5cQ0b0A5gHo6mEbIwCMAIDLL7886KAB4Gj+BQBAUVlVSNsRIhrIqJDRR1XJnYjiYEvs3zPzXNfHmbmYmUuU2wsBxBFRGw/rTWHmZGZOTkhICDF0+zY12YwQQliKmt4yBOBrAFnM/JGXdS5T1gMRXatsN1/LQD3sE4AkdyGE8ERNtcxAAE8A2ElEmcqy/wNwOQAw8xcAhgL4IxFVAygDMIzDeJ1z7vlyrNibG67NCyGE6flN7sy8DvDdasjMkwBM0ioof/6TcaJ+35HaqRBCmIhcoRoiGVtGmIlUY0YP0yd3GeVOCP+kt0z0MX1y15tjP/fElFSMmJGmYzRCCGFj+uRutHL7r3v0u2pWCCHsTJ/chRBCuDNlcpf6QyGE8M2Uyd2xDVXaU4Oz52Qxyqtq6u6Pnb8bj07ZpGNEQggtmTK5i9Dkl1Tg3olr8dqcHXXLpm04go2HwnpRsRAigkyZ3IvLHQcLk6J7oEorbSX2jGPndI5ECBEupkzu5VW1eodgieogK7wGIYRnpkzuju2puicoadwVQhiQKZO73vnciaGCEcK4DuaV4LnpaaiorvG/sgiZKZO7I8mtQpjDm/N2YVnWGaQdkbaeSDBdcq+uqcXX6w7rHYapyXUC0UsGuosepkvueSUVTvd1r3M3uOLyKpRWVnt8TAZdix4y12/0MV1ydyUlEd/6jP0VA8evcFpGUnQXwvJMn9yFf+dKZRJxIaKN6ZK7UWoSrHDGYP5XIITwRs0E2R2JaCUR7SGi3UT0Jw/rEBFNJKJsItpBRP3DE667sfP3RGpXdV7+cVv9HK4mrOEwYchCiACpmSC7GsCfmTmDiJoBSCeipczsmFXvAdBV+bsOwOfK/7A769LAGgnzMk9iXubJiO9XCCHU8ltyZ+ZTzJyh3D4PIAtAe5fVhgCYwTabALQgoraaRyuECIlRqjVF+AVU505EiQD6Adjs8lB7AMcd7ufA/QcARDSCiNKIKC0vLy+wSEXAqmrqx+CZvDIbBRcqdYxG6Ek6SEUf1cmdiJoC+AnAy8xcHMzOmHkKMyczc3JCQkIwm5BGwAC8m5pVd/uDJfuQ8tMOp8elFCeEdalK7kQUB1ti/56Z53pY5QSAjg73OyjLrC/MCbK8qgZFZcF1Zdxw8KzT/TJlcg4pxQlhfWp6yxCArwFkMfNHXlabD+BJpdfM9QCKmPmUhnFGrfsmrkXfcb+6Lf/L7O244b3lAW3L9eIlBmPYlI342y+R73EkopecMUaGmt4yAwE8AWAnEWUqy/4PwOUAwMxfAFgI4F4A2QBKATytfagGFeZS8MG8Cx6Xz07P8ftc1y8R1f2vD3rToQJsOlQQbHhCqCZnjJHlN7kz8zr4SWFsG6TkRa2C8rOvSOzGkuTLJUT0MN0VqlqYv/0k0o9qNOwoA3+etR2bHOYfHT13J/J16H/vyvVn0DW3y+9k9JG3PHpEZXJ/6YdteOjzDZpsq4YZP2Xk4PGv6nuH/rDlGK55Z5km2w+F61mOvc5dSvDRR97y6BOVyT1auZXcdYlCCBEJpkvuUpWgnlu1jJLdpRQnhPWZLrnrYfvxQos05NrSulleyeGzF5CYkors3PN6hyKE6Uhy92PtgTwMmbwe0zYc0TuUkJmtrv2X7bbB2eZtk0HahAiUJZP7gTPn8ZuPV6NIg0kqjhWUAgD2n/FdejRk3nQposdItUzUs8YZqFBDzUVMhuLvs1lTy7jr4zUAgNUH8vBA33Yh7c9+wY99vx/9us8lHuN+WVwjO1tSiZvfX4HrOrW2PW7c0IXGzHbWJkJnuuTuz/ebj9bd1iLx2r8U9k1NXJEd8jb1Yu/bf7zA/9WtQghzs1y1zLkL2s4Xai/weJtWz8iFXyOfVahh7uiF0Jflkrvj6acWuc215O7Kvtycp73GTp/mPrbCGyvMP2wGpkvu/j4YMQ6JwD7ErRqFpZ4nsiCV3QcpzM2Ur8/Z4fPxvy/MwsKdzgNxHskvDWdIESO53RrC/R0RzkyX3P1xHNZ29Nydqp6TfrQASW8vxaKd7qMU+yu5R8rMtOM+H5+y5hBe+D4joG3q/ZqEEOFjweQe+HO2Hy8CAGw+7D70rf3HoqqmFqPn+i49R0pFtf8zkrzz+g9cFio5fdeeHNHoYbneMsGc+tk/8L5+GNZln/U9B2kEzjhPFpahXYvGGP7N1rplzOx0tpKYkoobu7RG47jY8AcUKVLprgE5htHGdCV3f1UJtT5WuFBRjWqHSaPrt2l7juMPw9frDmPq+sP439nbAUCzyaVfn7MDf1G2GahXZtrmStnoMLzwHA+Tdmw4mI/le3P9bi/fw2sqr6pBWaX6tgohhDFZruT+wZJ9Xh/r+dYS3Ne7rdtyT70ywjX1nL3u/IOH+wb8XE/VRpnHC/FwckcPawdnwLvLcL68GkfG36fZNoMlbQJCBE/NHKrfEFEuEe3y8vggIioiokzlb4z2YWon1UOjqb1uV05cgfPl1XqHUKeuukzXKIQwJzXVMtMADPazzlpmTlL+3g49rMiylxBjYoJPI+FIQF+tPeR/v2HKfIfPep67VQ9S5S5E4Pwmd2ZeA8AwMyiH40x9zYE8APomkZpaxr9WH3Sq734nNUu3eG77cJVu+xZChE6rBtUbiGg7ES0iop7eViKiEUSURkRpeXl5Qe2opta9QVQNXyXR9dm2BsqsU8GPG15RHVxcdvO2ncB7i/bik2X7fa53wM/olEIIAWiT3DMAXMHMfQF8BmCetxWZeQozJzNzckJCQlA7+3LNYa+Plfu4IjXzuP8JsdfsD+4HRwsXKm113aV+eqpsOWKYk6jwkxZVIYIWcnJn5mJmLlFuLwQQR0RtQo7Mi9PF5V4f6/bmYrdl2bkl2JlThFdmBtf9MFKqa5RGXalfrlPfoCoHxUqs+pudfrTAUN2IQ07uRHQZKVfRENG1yjbzfT8rlP0Ftv6dH63GbyetC08wGvpbqq3r5U8e+q37Eg2JT37wrMHK7+OpojI89PlGvPaTMa5iB1T0cyeiHwAMAtCGiHIAvAUgDgCY+QsAQwH8kYiqAZQBGMZmH2s2wrYeKagrzXRs1QQAcLzA86Bf0ZDMhTCbCxW2atU9J4t0jqSe3+TOzI/6eXwSgEmaReSHlqktMSXVbdmstOOa7ePbTUcRHxsDEJBTUOo00YenfQPA3tPnMWPjEYz5ebfHx//vP+oGQxNCRDfLXaEaqtf8DK0biDfnebzuyy9vid0TInUDiZmRnP+FgRzTqGG65K7lZ3PCQ70RGxNTN34MAKx7/TbU1gK3fLAy5O2ve/02ALYkVVFdgzs/WuP3OX+5+2r8vl973Dh+her9PD8jPegYjUyuHNaOleu7hWemS+5aemTA5QDglNw7tGyi2fZdt+VtvBbHKppj+aVo16IxXhjUBf9cddDvPmZsPOp3HbOTxCSMzohnmaYbFXL3yWK9QwirSmXUytcGd9M5EiGEmZkuuYdzEgq9xkAfc3+PuttGKqRWeRgeOZKMWBoSwhMjnl2aLrmHU/uWjXXZ7zM3ddJlv/7c+dFqvUMA4Dx1ohBCHUsl971/8zd4pW+xkkScHLXIBNtCRCNLJfdGHqpVVvz5Vix95Ra0b+G/VH53r8vCEVZAasJQF/Fg//ZBP/dUUZmGkQRGamW0J8c0PIxYhWip5O5J54Sm6HppM/zpzq5e17k2sRUA4MYurSMVllfVtdp/Spo3jgv6uTe8p75LptYC/cKcKCxDYkoqVus4ABwAbDh4FscMdtYj56SRYaQqRMsnd7uh/Tt4fcw+72qsw2QdW/96JzLH3BX2uNxiCUNy16tUcbKwDAfzSkLejtrvS/pR28ifs5WpDPXy2JebNblOwqoMWMjVjJFGXoma5O5rliV7VYjjKgnN4tGiScNwh+XG1wTfZnPj+BW44x/GaJQNh5vfX4HRc40zUJTQj4EK7HWiJrm72pBye91te2k5Rsd3qHObiwAAXRKaar7t+Djrvs2Ld53GuAXqh2vQ0vGCMvywRd+zBCG8se633ocv/tAf7RwaWO0JNZS66VDd2eNSAMDFYYhhaP8OePWuqzTfrhGM/C4dU9cfUbXuqaIyjPp3hs9JXYyitLIaRWVVeochVDLiCXdUJvfBvdo63X/3973x3bPXoXMYSs1qNWlo6+kT30D7t6RjqyZ46Q7vDcpa23woH0WloSem+rFl1J1R+avvfCc1C7/sOIWle86EHFu43fL+KvQd96vm2zVSnbAVGalB1XJjy7x4WxdMXul/TBZHjRvG4qauYZs8SpWRt3ZBDBEev+4KXeMIVXlVDR6Zsgn9Lm8R+saUPBTo98XfF2xuRg5+27ddkEFFxtkSba/ENlLSMU4k1ma55N6mabzeIQSlUVxs2ErXNWHogeONvUF4bwiTjYeLPams3KdvV0lhXUY6M7JctcyTNyR6fWzj6NuR/sadkQtGB55KzA1ipaxkdMcLSpGYkor52086LY/kD7MInoFOjOr4Te5E9A0R5RKRx5knyGYiEWUT0Q4i6q99mOrF+ujy2LZ5Y7Q2aclerRE3d3ZbFt8gtAHRwtH3Xg2t92qkqglXe07ZRjtd4JLcP11+QI9wRIAMVGCvo6bkPg2Ar0Fb7gHQVfkbAeDz0MPy7s8W7fWhlXB8xl7XedJfe0o+X17ldW5ZLXy8dD/+54dtYdt+MHbmFOodggiAkQoQfpM7M68BUOBjlSEAZrDNJgAtiKitj/VD0uKiyF5Y1DnhoojuL1SXNW+k+TZnp+dovk01XOsvh0xej5vf93zl53uLsupue/t6OS4/Weg+Zs6nyw+4lZztQxpsOHhWVczB8lbyM2CBUJiEFnXu7QE4XsmRoyyzhIFd9O1FE6j+l7fEglE34epLm+kdimbshaFDeRe8rvOv1Yfclp0sLMOjUzbV9Rd3LFSpncZwy+F8AMCsrfUf8YU7T4Vt7Jhwl/vkxyJ6RLRBlYhGEFEaEaXl5QXXYyHSJz0PXeN9TBqj6t2hOZ67OTxjxBeVVSExJRWLdp4CYOtW+G7qnrDsK9R6zM9WZGPjoXz8suOk/5UD8ML3GbjnU//z4RqJcSoLrM1qvWVOAOjocL+DsswNM09h5mRmTk5ISNBg1+GX1LEFtvz1Dr3DCFhXDyX3N+7rHvJ2DykDgX2x2nYtwauztuPLtYdD3q4vai9i8sb+fQs1wWXnnq+b7/ZCpdZXuSoXbLkEaaBcoRkLviRD0iK5zwfwpNJr5noARcx8SoPteqSmvSKU8cs90unT2LGVtjNDPeehJ02gvDUYnSwsw3PTt+JChf+kV1PL2HWiKORYXLkmQi3atuzb3JFThEU7Twe9nROFZSipqPa7n1B/yIKVX1IR1uEOvlp7qG7UTiszVYMqEf0AYCOAq4koh4ieJaKRRDRSWWUhgEMAsgF8CeCFsEUbZVqGMCql/fSwb4fmWoXjZHtOEaod5lj9cMk+LMvKxeLd/hPgpBXZuP+zdcg8rq4nyJni8roSsxpupd+65cF/8Q6d9V7f743j6xs4fgWGfr4h4G1EqlxxzTvLkPzO0rBt/53ULJRqfrYjfPF7hSozP+rncQbwomYRaaBP++aYm3EClzTTpk+7XqeRPdtdjB05wZVw62IOY0liToC9aB6dsgkPJLXD7pO213S6qNy5Qs+F/TXsDLKU7/rKAz0SxeVVTgk60EO560QRrmjVBC2VHl57T3u/atcIVRVVNUaIQmjFcleoAsAVyvC5v9eoekaves/mjYMvufdoezG6t70YY+7voVk8Ww4XYMaGI3X3Kx1K7mpsPJSP0XN3OizxfmCX7jmDnHO2Hikh/z4F+QY+O20rZmw8Wnc/0JL/G/N2YcC7y7DtWH11xGtztuPchUqvzwn3Wb0V6/C10mfsEkxdH1r7UXZuCZ6dtlWjiEJjubFlAGDQVQmY9Fg//KaHNnOi6jUUcChf9EZxsVj0p5vdll99aTPsOxPcuC//9a+NTvcX7wquDlrN63p+Rlr9+gGWuU8Vlrvt59NlBzB3m3M7f1llDU4UluHKS5xHA62qqUWDGML246G3C1TXMg6cqZ+NalZaDuIbxOJvv+vltJ7Xfu4aZWMDVQUbVnF5NcYt2IOnB4bW02z53lyNIgqNJUvuRIT7+7RDQ42Gz23cMLTL94PlYySFoPVod7Fm29p4KN/rY6yiooEZGD51CxbuPOW7sVFlpUWGUkLecsT5mjsGMG2De4nsj9+n486PVqPK5Qyk618X4Y15Hkfb0ISnRMteessIESxLJvdw+HRYUsT3GY6eEw8nh6ffvuv0gOVV/qtsKmtqsWpfHl74PgO93loCAOj25iK8/KPvIQAKvFRrOFahAM7Hz9PPw/ps21WnngrH328+5rbMW+JdvOs0ngngVNzXu6rmPS8qq8L58shN5FFeVSMDmJmQ6ZL7RQ31qUnSo4tTOHbZ//KWQT1vlodJpx2T4rxM3xcKOV7u7yuBlVfVum3Ldf3npgdWp+m9ysP381zbFLzFPfK7dKxQTsXVdPG0f5Y2HDyLySuz/a7vqu+4X9F7rPYTeXjT7c3Fuo8vJAJnuuTeumnkJ60G9LnCL7G1cca1eW1O8F/u2lr2eLm/2upk1x+54+fcx4Xx9zxf+1L7I6pmvd9NXu+2zFu10mNfbsYHS/bZ1lFWOVNc7rTO2gNncfP76oZKOJZfGrYRPAPtGSX0Z7rkHk1u73aJ5tvUo7dEH5fp4iJxEnT3x2vqGnyX7D7t8QKdQA/FlsO+xs8Lbpuu0jxc6HO8oP7HzLE6xrGdYsvhAtzywUoZIjjCSiqqcaa43BBdWV2ZLrnrdQWfHlpe1BDtW2h7laraxsngd+C+fV+NpcHIO1+BxJRUnxc27TtzHrnnbVPVbTjoueHX3hOFABSWeu+eaLdCRS8IT5/O8+XOr3/rEfcfCTXvyvKsM07VMY5j+th7Mm0+7L2RW2hv8CdrcN3fl+sdhkemS+7RZn3K7Zpur0mY2yze/Hm333UWKSXql2dmhjUWf+w1GFf+dRHum7hOk216Oit5f/E+p/tVJUVKAAASKklEQVS7TxY73d927JyqLo+ux6u4zP1H0wz92I00uFaocpQqQiMWOU2X3PXqKhbIx/HF27po2rsmHF0ihbMTHsZ314q/i72+XhfchTOpysic4RwTxkimrDmIxJRUVFQbYxgD+0V2RmW65K6XQBqq/nJ3NwxJ0m7wskZx+vSzjzRv1SzBDsGgB7XVho6l11B7YjlWKWlRJs4tLse3m476XKfgQiUSU1LxUwQbWr9QxuwvKVdXzcfMYRt3HwBumuB54hijMF1y16sQq2c/33t6hW1iK1PQus4+rFR+QAc69B5S+5lWs96WwwU4W1KhcouePf9tOt6ctws550q9VqEcVgZS+26z7x8BPf1n2wnc8sHKuusZANvVx499uQlpHto9QmHEiibTJXe93Hhla932/cxNibrtW6jX/c3FqKxWN97OyaL6Lo9qCu7Dp25BsZcSq+PwBgCQ/M4yVTF4Yx/7xneBJvh0tuVwAT5fdVDVuuVVNUF377Sf8e13GG4j51wZNhzMx//O3q5qG2WVNXjx3xluXVRdVai4aC/SzJfcdSq6t22uba+VQMTFmu9tikZlVcHVBccQ+W0IXbXP88xlP2w5huccxuHxJ9DeUv7iCubr+M9VBzFh8V6/65VX1aDbm4sx3sO6O3IKkZiSioN5JR6e6UxN+623M5QFO04idccpt0ZxV6WVzj+8+4Mcv0lLpssa0dQV0q6ry8BWoRqQGNxVqiI8CMF3UXUeZdPXPrT93kSiw8sFpTputoero+dts13FvFJF99RAQ01MSa0fkbRuG7634tpu8puP1+je0G265B6NiAhLXr7F73pqZ24Kd3dIESCXvKtVz50fthzDqzMzsSH7LFYfCHzO4pOF5fh8te/qk3AOy6F22ycLy/Cbj1cj16XqxP70YLpe2i+Aq4tB2cSPW455vE7Bk4ogz+S0YrpvuRFGzfvqyeSAToW1cPVl7nOiuhrcU90Qx9K10lgIztUyAz0M1RAMe6nedahjtf772zSv9fyRsF2ZKMVfav5201HsP1OCWWnHcfVlF6Nt80bo1b55QGcravN/inJMs9+9x//KOn/PVJXciWgwEe0jomwiSvHw+HAiyiOiTOXvOe1DNY4+HcMzdZ0/zRr5/i1WW9LRcthfETrX+lqjCGYS8KqaWiSmpOLjpftVP+dEYZnH0vXTykibhaW26g1vo4Haffjrfjw/Iw33f2a7IM3163CqKPAzovpqGWePTNnk97kjv00PeH9aUjOHaiyAyQDuAdADwKNE5Gl6n5nMnKT8faVxnIaiV73/ptF3YPtbv8Gd3UMbc0avyUeEZ4t2nXYbUz5UnyzznlwP5ZVg8CdrfM4I5Y9rspu04gBGz92JCqW30JdrbX3S//DVZoz6d4bX7aQfLcDA8SswO4T+8t5K3eTw+PztJ3HDeyuwURmK4oif/u91E5Z7qdpxnez7QK57A2rGMfc5go/ll6L32CU4mh/4nLyBUlNyvxZANjMfYuZKAD8CGBLesIzpgb7t8NIdXXWrGroovgGaN47DfyV7nni0Uxt1o0jGGKFuSzh5/Sd1DaNqfbLM+wBi/1x1EHtPn8fSrDNujyWmpOJYgXvi8/aRsS/+8Nf9+GHLMaeECgDrss/ilx2nvMayX+nGmX6kPlkyMxZsdx72uTyE+msGI0NJxlmn6od+6DFmMWZttTXWnvbS1dGxyn2nj4vpHAd382VORg7Ol1djbkZwVWWBUJPc2wNwbK7OUZa5eoiIdhDRHCLyMe1xaPRMSxMf7YdX77oKTeP1barwVj04bEDohz3UswJhbIG0Lfr6rjlu5yullA4E3ibm2BuluqYWNbWM/2w7gf/5wXnClvcWZnmPxcs3wjGW+iRdv25pZQ3GLbCNhTTyO+cqFAZj6Z4zeGWmrT/80j1n8NtJgY8/tGqfrTfPop2nkJiSWneBWSQuetKqt8wCAInM3AfAUgDTPa1ERCOIKI2I0vLyAm+9NwqjDgegts69/xXeu0JOeSJZq3CEAQWS3KsdLh4i2MZSSUxJxYP/XF9XTZFXUoF3Ut0Tb1lVjaqqJvtZJLNtALc7/rEK+SXu1UWnirxfRPSv1YfcliWmpOLLtYfrtm2vSt15otht3Re/z3Ab4oLZeR7fUj/tD95+YIZPtbUb2IdzsDcSR4Ka5H4CgGORsIOyrA4z5zOz/ZrnrwBc42lDzDyFmZOZOTkhISGYeHWZEclqfM3GFCNdaSztRGFZ/cQbARYfVyoXUmUcK8Q5ZTyboy51147tUXMzVNSjK6vbf0f81YUHw/ECV9fkeqGypm4AtpD4OJavzMysG3a6bkTQCFwooCa5bwXQlYg6EVFDAMMAzHdcgYgcBz95AID3cyiN/esJj78jltaxZRO9QxBRhoicEtJ/vHSvdCx7+WtHOFlYpvoiIcdHiSig6p8Ji/di23H3SVB88dTuECxPx8oQ1TLMXA1gFIAlsCXtWcy8m4jeJqIHlNVeIqLdRLQdwEsAhocrYNc39frO+o35ohctujK+9VtPHZ6E8Kym1jn9Ltnt3hgbqKGfb3C7SEitQAu+2zz0XPHF0wTpvgQ69EQkrvBVVefOzAuZ+Spm7sLM7yrLxjDzfOX2aGbuycx9mfk2ZvY/cIRG9KqladjA3Bf3Pj2wk94hCJ2Nmb/Lado+f6ZvOOJ3nUC+jyeLyrHhoG3ExsMOXQM9leKNPr/HjI2BjY4Z9hnRYMLhB4xSI9xdxRWj4bToTzfj2ZskQYvglVfV4qlvtvjsh+7oYJ7/vtm93loSUAz2LoGOJevpGzwlyvpkuPFgPmanu483YyaGKbkbWQOdGgD1Lkh0b3sx3rivO9a+dpvm237xti6ab1MYU8axQp/90ANVVRP6N8PT2DqOyfDFf2e4zUtrNoaoczcapwabwd10GwSrZzt9hiBwRETo2KoJJjzUG18/pV0Xxr/c3U2zbQmhBb0LU1qTkrtH9dl95K2ddYviyRuu0G3frh4ZcDnu6H6p3mEIIVSSOncP7FeHPtC3na593u27jpV+4UKEndZj7+hOSu7urr6sGf71xDV478HeusZxcSPb4FsP9tNuImwhhGdrD5z1v5KJRKKayXTjuQPA3SrHLQ+ndi0aY/6ogbjq0mYhjWgnhBDhYMrkbhR9OrTQOwQholp+CMMW62nPSfcxbrRmumoZIYSwO6XRlISRFokfJUskd72vFm3bvJGu+w/WzBHX6x2CECGZl3nS/0oGVB2BBmJLJPfMMXdh97i7ddv/kKT6RlUzjdlyXefW+G8v3Unff6hPhKMRInocyC0J+z4omJnBtZCcnMxpaZGdZDpcamsZpVU12HuqGNdc0dJUwxJX1dQi7cg5dL20KQCgTdN4ALaZb7q9uVjP0ISwtCPj7wvqeUSUzsx+r1q0RMldbzExhKbxDZCc2MpUiR0A4mJjcEOX1mjTNL4usQO2CUm+GZ6M4Tcm6hecECJoktyFV7d3uxRjH+ipdxhCiCBIchdCCAuS5C782pByu94hCCECJMld+NWuRWNkvT0YvdqHPgOUECIyVCV3IhpMRPuIKJuIUjw8Hk9EM5XHNxNRotaBCn01bhiLBaNuwm/7ttM7FCGECn6TOxHFApgM4B4APQA8SkSunbmfBXCOma8E8DGACVoHKvRHRPjs0X7IHHMXhiRJkhfCyNSU3K8FkM3Mh5i5EsCPAIa4rDMEwHTl9hwAd5DZ+gQK1Vo0aYhPh/XDkfH34cj4+zBn5A16hySEcKFm4LD2ABwnLMwBcJ23dZi5moiKALQGYK1xOoVHyYmtnC7IqKyuRU0t4+1fdqOkogZD+rbDlZc0xa97TuOjpftRXmW79LphbAwqrTZOtxAGEdFRIYloBIARAHD55ZdHctciguxj/bz3oPMQBiNu6YIRt2g/P2tpZTVquX4iFwAoqahGvBJHXKzvE9SSimpknSrGVZc2Q0V1DTYdKsADXtoWCksrcaa4Ap0TLsL67LPo0LIxcosr8NhXm7Hiz7di2oYjuOaKlujZrjnSjxYg42gh0o+dQ3ZuCW67OgHbc4rQMDYG13ZqhfnbfY+L8trgq9Htsmbo17ElmjeOw7GCUmQeL8SstOPYcDAfV1/aDPvOnHd6zp3dL8WyrDNqDpvQ0bgIXD/id/gBIroBwFhmvlu5PxoAmPk9h3WWKOtsJKIGAE4DSGAfG7fS8ANCCBEpWg4/sBVAVyLqREQNAQwDMN9lnfkAnlJuDwWwwldiF0IIEV5+q2WUOvRRAJYAiAXwDTPvJqK3AaQx83wAXwP4loiyARTA9gMghBBCJ6rq3Jl5IYCFLsvGONwuB/CwtqEJIYQIllyhKoQQFiTJXQghLEiSuxBCWJAkdyGEsCBJ7kIIYUG6zaFKRHkAjgb59DYwz9AGZonVLHEC5onVLHEC5onVLHEC4Yv1CmZO8LeSbsk9FESUpuYKLSMwS6xmiRMwT6xmiRMwT6xmiRPQP1aplhFCCAuS5C6EEBZk1uQ+Re8AAmCWWM0SJ2CeWM0SJ2CeWM0SJ6BzrKascxdCCOGbWUvuQgghfDBdcvc3WXeEYjhCRDuJKJOI0pRlrYhoKREdUP63VJYTEU1U4t1BRP0dtvOUsv4BInrK2/4CjO0bIsolol0OyzSLjYiuUV57tvLcoKZT9BLnWCI6oRzXTCK61+Gx0co+9xHR3Q7LPX4elCGqNyvLZyrDVQeFiDoS0Uoi2kNEu4noT8pyQx1XH3Ea7rgSUSMi2kJE25VYx/naPhHFK/ezlccTg30NGsU5jYgOOxzTJGW5bt8pN8xsmj/Yhhw+CKAzgIYAtgPooUMcRwC0cVn2PoAU5XYKgAnK7XsBLAJAAK4HsFlZ3grAIeV/S+V2Sw1iuwVAfwC7whEbgC3KuqQ89x4N4xwL4H89rNtDea/jAXRSPgOxvj4PAGYBGKbc/gLAH0M4pm0B9FduNwOwX4nJUMfVR5yGO67K62yq3I4DsFl5/R63D+AFAF8ot4cBmBnsa9AozmkAhnpYX7fvlOuf2Uruaibr1ovjJOHTAfzOYfkMttkEoAURtQVwN4ClzFzAzOcALAUwONQgmHkNbGPqax6b8tjFzLyJbZ/KGQ7b0iJOb4YA+JGZK5j5MIBs2D4LHj8PSsnndtgma3d9zcHEeoqZM5Tb5wFkwTZvsKGOq484vdHtuCrHpkS5G6f8sY/tOx7rOQDuUOIJ6DVoGKc3un2nXJktuXuarNvXhzdcGMCvRJROtnlhAeBSZj6l3D4N4FLltreYI/latIqtvXLbdbmWRimns9/YqzmCiLM1gEJmrtY6TqU6oB9sJTjDHleXOAEDHlciiiWiTAC5sCW7gz62XxeT8niREk/Yv1+ucTKz/Zi+qxzTj4ko3jVOlfGE7TtltuRuFDcxc38A9wB4kYhucXxQ+QU2ZDckI8cG4HMAXQAkATgF4B/6huOMiJoC+AnAy8xc7PiYkY6rhzgNeVyZuYaZkwB0gK2k3U3nkDxyjZOIegEYDVu8A2CranldxxA9MltyPwGgo8P9DsqyiGLmE8r/XAD/ge2DeUY5xYLyP1dZ3VvMkXwtWsV2QrkdlpiZ+YzyRaoF8CVsxzWYOPNhOx1u4LI8aEQUB1vC/J6Z5yqLDXdcPcVp5OOqxFcIYCWAG3xsvy4m5fHmSjwR+345xDlYqQJjZq4AMBXBH9Pwfae0qLiP1B9s0wIegq3hxN5I0jPCMVwEoJnD7Q2w1ZV/AOfGtfeV2/fBuYFlC9c3sByGrXGlpXK7lUYxJsK5oVKz2ODe+HOvhnG2dbj9Cmx1qQDQE86NZodgazDz+nkAMBvODXMvhBAnwVYX+onLckMdVx9xGu64AkgA0EK53RjAWgD3e9s+gBfh3KA6K9jXoFGcbR2O+ScAxhvhO+UUuxYbieQfbK3R+2Grn/urDvvvrHxQtgPYbY8Btvq/5QAOAFjm8MYRgMlKvDsBJDts6xnYGoCyATytUXw/wHbqXQVb/d2zWsYGIBnALuU5k6BcCKdRnN8qcewAMB/OSemvyj73waE3gbfPg/I+bVHinw0gPoRjehNsVS47AGQqf/ca7bj6iNNwxxVAHwDblJh2ARjja/sAGin3s5XHOwf7GjSKc4VyTHcB+A71PWp0+065/skVqkIIYUFmq3MXQgihgiR3IYSwIEnuQghhQZLchRDCgiS5CyGEBUlyF0IIC5LkLoQQFiTJXQghLOj/Ae5FVYBvvslJAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(g_losses,label = \"Generator loss\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "plt.plot(d_losses,label = \"Discriminator loss\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "plt.plot(bl_losses,label = \"Baseline loss\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|         | 1/64 [00:00<00:06,  9.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating with no styles:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 64/64 [00:07<00:00,  9.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing file out/samples/output/canonical_test_0.mid\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from generate import write_file, generate\n",
    "# import gc\n",
    "# torch.cuda.empty_cache()\n",
    "# gc.collect() \n",
    "with torch.cuda.device(GPU):\n",
    "    write_file('output/canonical_test', generate(generator, 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_GAN(generator,discriminator,baseline,X_loader,num_epochs = 3,g_lr = 0.001, d_lr = 0.001,bl_lr = 0.001):\n",
    "    generator.train()\n",
    "    discriminator.train()\n",
    "    generator.train()\n",
    "    g_optimizer = torch.optim.Adam(generator.parameters(),     lr=g_lr,weight_decay = 0)#, betas=(0.5, 0.999))\n",
    "    d_optimizer = torch.optim.Adam(discriminator.parameters(), lr=d_lr,weight_decay = 0)#, betas=(0.5, 0.999))\n",
    "    bl_optimizer = torch.optim.Adam(baseline.parameters(), lr=bl_lr)\n",
    "    \n",
    "    d_losses = []\n",
    "    g_losses = []\n",
    "    bl_losses = []\n",
    "    for epoch in range(num_epochs):\n",
    "        for i, [x_batch,ch_batch] in enumerate(X_loader):\n",
    "            x_batch = x_batch.cuda()\n",
    "            ch_batch = ch_batch.cuda()\n",
    "            x_batch[:,:,:,2] = 1\n",
    "            ch_batch[:,:,:,2] = 1\n",
    "            \n",
    "            # Optimize D\n",
    "            data_gen = generator(x_batch,ch_batch)\n",
    "            sound = sample_sound(data_gen).data\n",
    "            false_example = sound\n",
    "            true_example = ch_batch\n",
    "            loss = d_loss(discriminator(false_example), discriminator(true_example))\n",
    "            d_optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            d_optimizer.step()\n",
    "            d_losses.append(loss.data.cpu().numpy())\n",
    "        \n",
    "            # Optimize BL\n",
    "            data_gen = generator(x_batch,ch_batch)\n",
    "            sound = sample_sound(data_gen).data\n",
    "            false_example = sound\n",
    "            loss = bl_loss(baseline(x_batch,ch_batch),discriminator(false_example))\n",
    "            bl_optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            bl_optimizer.step()\n",
    "            bl_losses.append(loss.data.cpu().numpy())\n",
    "            \n",
    "            # Optimize G\n",
    "            data_gen = generator(x_batch,ch_batch)\n",
    "            sound = sample_sound(data_gen).data\n",
    "\n",
    "            false_example = sound\n",
    "            true_example = ch_batch\n",
    "            g_optimizer.zero_grad()\n",
    "            loss += compute_loss(data_gen,ch_batch)\n",
    "            loss.backward()\n",
    "            g_optimizer.step()\n",
    "            g_losses.append(loss.data.cpu().numpy())\n",
    "            \n",
    "            if i%2==0:\n",
    "                data_gen = generator(x_batch,ch_batch)\n",
    "                sound = sample_sound(data_gen).data\n",
    "\n",
    "                false_example = sound\n",
    "                true_example = ch_batch\n",
    "                handle = np.random.randint(0,2)\n",
    "                if handle == 0:\n",
    "                    loss = g_loss(discriminator(false_example),sound,data_gen,baseline(x_batch,None),None)#,sound.data,data_gen)\n",
    "                else:\n",
    "                    loss = g_loss(discriminator(true_example),ch_batch,data_gen,baseline(x_batch,None),None)#,sound.data,data_gen)\n",
    "                g_optimizer.zero_grad()\n",
    "                loss += compute_loss(data_gen,ch_batch)\n",
    "                loss.backward()\n",
    "    #             print(loss.grad)\n",
    "                g_optimizer.step()\n",
    "                g_losses.append(loss.data.cpu().numpy())\n",
    "    return generator,discriminator,baseline,np.array(g_losses),np.array(d_losses),np.array(bl_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [],
   "source": [
    "def EB(sound):\n",
    "    play = sound[:,:,:,0]\n",
    "    num_notes = play.sum(dim=-1)\n",
    "    is_empty = (num_notes==0).float()\n",
    "    return is_empty.mean()*100\n",
    "    \n",
    "def UPC(sound):\n",
    "    play = sound[:,:,:,0]\n",
    "    batch_size,time_scale,note_num = play.size()\n",
    "    octave_play = play.view(batch_size,time_scale,12,note_num//12)\n",
    "    pitch_play = octave_play.sum(dim = -1)>0\n",
    "    num_pitches = pitch_play.sum(dim=-1)\n",
    "    return num_pitches.float().mean()\n",
    "\n",
    "def num_notes(play,replay):\n",
    "    play = play*(1-replay)\n",
    "    batch_size,time_scale,note_num = play.size()\n",
    "    shifted_play = torch.zeros(batch_size,time_scale,note_num).cuda()\n",
    "    shifted_play[:,:-1,:] = play[:,1:,:]\n",
    "    cond_change = shifted_play-play\n",
    "    return (cond_change>0).float().sum()\n",
    "\n",
    "def QN(sound, qualified_len = 3):\n",
    "    batch_size,time_scale,note_num,_ = sound.size()\n",
    "    play = sound[:,:,:,0]\n",
    "    replay = sound[:,:,:,1]\n",
    "    shifted_play = torch.zeros(batch_size,time_scale,note_num).cuda()\n",
    "    \n",
    "    shifted_play[:,:time_scale-qualified_len,:] = play[:,qualified_len:,:]\n",
    "    qualified_play = play*shifted_play\n",
    "    \n",
    "    general_num_notes = num_notes(play,replay)\n",
    "    num_qualified_notes = num_notes(qualified_play,replay)\n",
    "    return num_qualified_notes/general_num_notes*100\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(7.4074, device='cuda:0'),\n",
       " tensor(3.3108, device='cuda:0'),\n",
       " tensor(85.6642, device='cuda:0'))"
      ]
     },
     "execution_count": 228,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sound = torch.FloatTensor(X_tr).cuda()\n",
    "EB(sound),UPC(sound),QN(sound)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
